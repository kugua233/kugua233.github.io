<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="Mosbyllc" type="application/atom+xml" />






<meta name="description" content="Sometimes thing have to fall apart to make way for better things.">
<meta property="og:type" content="website">
<meta property="og:title" content="Mosbyllc">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Mosbyllc">
<meta property="og:description" content="Sometimes thing have to fall apart to make way for better things.">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Mosbyllc">
<meta name="twitter:description" content="Sometimes thing have to fall apart to make way for better things.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>Mosbyllc</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mosbyllc</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>

<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/" itemprop="url">Sklearn 与 TensorFlow 机器学习实用指南（三）：回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-14T10:36:11+08:00">
                2018-07-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Sklearn-与-TensorFlow-机器学习实用指南/" itemprop="url" rel="index">
                    <span itemprop="name">Sklearn 与 TensorFlow 机器学习实用指南</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  10,121
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  38
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="线性回归："><a href="#线性回归：" class="headerlink" title="线性回归："></a>线性回归：</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><script type="math/tex; mode=display">
\hat{y} = h _{\theta} (\mathbf{x})= \theta^T  \cdot \mathbf{x} = \theta _{0} + \theta _{1}x _{1}+\theta _{2}x _{2}+\dots+\theta _{n}x _{n}</script><ul>
<li><strong>x</strong> 为每个样例中特征值的向量形式，包括 $x_1$ 到 $x_n$  ，而且$x_0$ 恒为1。<strong>矩阵点乘，相同规模对应相乘</strong>。</li>
</ul>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><script type="math/tex; mode=display">
MSE (\mathbf{X},h _{\theta}) = \frac{1}{m} \sum\limits_{i=1}^m{\left(\theta^T \cdot \mathbf{x}^{(i)}-y^{(i)}\right)}^2</script><h2 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h2><p>一行为一个实例</p>
<script type="math/tex; mode=display">
\left(\begin{matrix}
    1&        x_{1}^{\left(1\right)}&        x_{1}^{\left(2\right)}&        ···&        x_{1}^{\left(n\right)}\\
    1&        x_{2}^{\left(1\right)}&        x_{2}^{\left(2\right)}&        ···&        x_{2}^{\left(n\right)}\\
    ···&        ···&        ···&        &        \\
    1&        x_{m}^{\left(1\right)}&        x_{m}^{\left(2\right)}&        ···&        x_{m}^{\left(n\right)}\\
\end{matrix}\right)</script><p>优化线性回归损失函数的两种方法：1）最小二乘法原理的正态方程 2）梯度下降</p>
<h2 id="正态方程"><a href="#正态方程" class="headerlink" title="正态方程"></a>正态方程</h2><script type="math/tex; mode=display">
\frac{\partial }{\partial \theta}MSE(\theta) = \frac{1}{m}(2X^TX\theta-2X^Ty)</script><script type="math/tex; mode=display">
\hat{\theta} = ({\mathbf{X}}^T\cdot\mathbf{X})^{-1}\cdot{\mathbf{X}}^T\cdot\mathbf{y}</script><p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/01.png" alt=""></p>
<blockquote>
<p>这里的$X^TX$要满足满秩矩阵，然而，现实大多数任务不会满足这个条件。好像只有线性回归能用正态方程求解。优点是一次计算；缺点是矩阵的逆计算慢，尤其是特征数量很多的情况下就更糟糕了，但是一旦你得到了线性回归模型（通过解正态方程或者其他的算法），进行预测是非常快的。</p>
</blockquote>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><h3 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a>批量梯度下降</h3><p><strong>批量梯度下降：使用梯度下降的过程中，你需要计算每一个</strong>θj 下代价函数的梯度<br>代价函数的偏导数: 利用公式2对θj求导，其余 θ看做常数。</p>
<script type="math/tex; mode=display">
\frac{\partial }{\partial \theta_j}MSE(\theta)=\frac{2}{m} \sum\limits_{i=1}^m{\left(\theta^T \cdot \mathbf{x}^{(i)}-y^{(i)}\right)}{x_j}^{(i)}</script><p>更新：</p>
<script type="math/tex; mode=display">
\theta :=\theta_j-\lambda\frac{\partial }{\partial \theta_j}MSE(\theta)</script><p>为了避免单独计算每一个梯度，你也可以使用下面的公式来一起计算它们。梯度向量记为$\nabla_{\theta}MSE(\theta) $ ，其包含了代价函数所有的偏导数(每个模型参数只出现一次)。利用正态方程最后的推导即可）</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/02.jpg" alt=""></p>
<blockquote>
<p><strong>在这个方程中每一步计算时都包含了整个训练集X ，这也是为什么这个算法称为批量梯度下降：</strong>每一次训练过程都使用所有的的训练数据。因此，在大数据集上，其会变得相当的慢（但是我们接下来将会介绍更快的梯度下降算法）。然而，梯度下降的运算规模和特征的数量成正比。训练一个数千数量特征的线性回归模型使用梯度下降要比使用正态方程快的多.</p>
</blockquote>
<p>更新：</p>
<script type="math/tex; mode=display">
\theta^{(next\ step)}=\theta - \eta\nabla_{\theta}MSE(\theta)</script><p>我们来看一下这个算法的应用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">eta = <span class="number">0.03</span></span><br><span class="line">n_iterations = <span class="number">15000</span></span><br><span class="line">m = <span class="number">100</span>    <span class="comment"># 样本数目，</span></span><br><span class="line"></span><br><span class="line">X = <span class="number">2</span> * np.random.rand(<span class="number">100</span>, <span class="number">1</span>)    <span class="comment"># 产生100行1列的0~2的数值</span></span><br><span class="line">y = <span class="number">4</span> + <span class="number">3</span> * X + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># np.c_表示按列操作拼接，np.r_表示按行操作拼接</span></span><br><span class="line">X_b = np.c_[np.ones((<span class="number">100</span>, <span class="number">1</span>)), X]     <span class="comment"># x0 = 1</span></span><br><span class="line">theta = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">    gradients = <span class="number">2</span>/m * X_b.T.dot(X_b.dot(theta) - y)</span><br><span class="line">    theta = theta - eta * gradients    <span class="comment"># 最后输出的是所有系数矩阵</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>theta</span><br><span class="line">array([[<span class="number">4.11509616</span>],[<span class="number">2.87011339</span>]])	<span class="comment"># 理论θ_0=4, θ_3, 由于噪声会有点误差</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>梯度下降的一些要点：</p>
<ul>
<li>应该确保所有的特征有着相近的尺度范围（例如：使用Scikit_Learn的 StandardScaler类）</li>
<li>学习率$\lambda $ 要自适应</li>
</ul>
</blockquote>
<h3 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h3><p>批量梯度下降的最要问题是计算每一步的梯度时都需要使用整个训练集，这导致在规模较大的数据集上，其会变得非常的慢。<strong>与其完全相反的随机梯度下降，在每一步的梯度计算上只随机选取训练集中的一个样例</strong>。</p>
<p><strong>虽然随机性可以很好的跳过局部最优值，但同时它却不能达到最小值。解决这个难题的一个办法是逐渐降低学习率。</strong>开始时，走的每一步较大（这有助于快速前进同时跳过局部最小值），然后变得越来越小，从而使算法到达全局最小值。 <strong>这个过程被称为模拟退火</strong></p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/03.jpg" alt=""></p>
<p>下面的代码使用一个简单的learning schedule来实现<strong>随机梯度下降</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">50</span> </span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">50</span>  <span class="comment">#learning_schedule的超参数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learning_schedule</span><span class="params">(t)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> t0 / (t + t1)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># np.random.randn返回2行1列符合标准正态分布的数；</span></span><br><span class="line"><span class="comment"># np.random.rand返回[0,1）的随机数；</span></span><br><span class="line"><span class="comment"># randint返回范围内的整数</span></span><br><span class="line">theta = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        random_index = np.random.randint(m)    <span class="comment"># m个样本随机选一个样本</span></span><br><span class="line">        xi = X_b[random_index:random_index+<span class="number">1</span>]</span><br><span class="line">        yi = y[random_index:random_index+<span class="number">1</span>]</span><br><span class="line">        gradients = <span class="number">2</span> * xi.T.dot(xi.dot(theta)-yi)	<span class="comment"># 单个个体视为批量</span></span><br><span class="line">        eta = learning_schedule(epoch * m + i)    <span class="comment"># 根据迭代情况调整学习速率</span></span><br><span class="line">        theta = theta - eta * gradiens</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>theta</span><br><span class="line">array([[<span class="number">3.96100095</span>],[<span class="number">3.0580351</span> ]])</span><br></pre></td></tr></table></figure>
<p>通过使用Scikit-Learn完成<strong>线性回归的随机梯度下降，你需要使用SGDRegressor类，这个类默认优化的是均方差代价函数</strong>。下面的代码迭代了50代，其学习率eta为0.1，<strong>使用默认的learning schedule(与前面的不一样)</strong>，同时也没有添加任何正则项（penalty = None）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为这个函数需要的y是一个行向量，所以压扁;</span></span><br><span class="line"><span class="comment"># 另外，numpy.flatten() 与 numpy.ravel()将多维数组降位一维，前者会进行拷贝处理</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line">sgd_reg = SGDRregressor(n_iter=<span class="number">50</span>, penalty=<span class="keyword">None</span>, eta=<span class="number">0.1</span>)</span><br><span class="line">sgd_reg.fit(X,y.ravel())</span><br></pre></td></tr></table></figure>
<p>结果很接近正态方程的解</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_reg.intercept_, sgd_reg.coef_</span><br><span class="line">(array([<span class="number">4.18380366</span>]),array([<span class="number">2.74205299</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a>小批量梯度下降</h3><p><strong>小批量梯度下降中，它则使用一个随机的小型实例集，小批量梯度下降在参数空间上的表现比随机梯度下降要好的多，尤其在有大量的小型实例集时，主要利用了矩阵运算的硬件优化</strong></p>
<p>也看一下这个算法的应用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">theta_path_mgd = []</span><br><span class="line"></span><br><span class="line">n_iterations = <span class="number">50</span></span><br><span class="line">minibatch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">theta = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)  <span class="comment"># random initialization</span></span><br><span class="line"></span><br><span class="line">t0, t1 = <span class="number">200</span>, <span class="number">1000</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learning_schedule</span><span class="params">(t)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> t0 / (t + t1)</span><br><span class="line"></span><br><span class="line">t = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">    shuffled_indices = np.random.permutation(m)</span><br><span class="line">    X_b_shuffled = X_b[shuffled_indices]	<span class="comment"># 打乱所有样本顺序</span></span><br><span class="line">    y_shuffled = y[shuffled_indices]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, m, minibatch_size):</span><br><span class="line">        t += <span class="number">1</span></span><br><span class="line">        xi = X_b_shuffled[i:i+minibatch_size]</span><br><span class="line">        yi = y_shuffled[i:i+minibatch_size]</span><br><span class="line">        gradients = <span class="number">2</span>/minibatch_size * xi.T.dot(xi.dot(theta) - yi)</span><br><span class="line">        eta = learning_schedule(t)</span><br><span class="line">        theta = theta - eta * gradients</span><br><span class="line">        theta_path_mgd.append(theta)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/04.jpg" alt=""></p>
<h1 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h1><p>如果你的数据实际上比简单的直线更复杂呢？ 令人惊讶的是，<strong>你依然可以使用线性模型来拟合非线性数据</strong>。 <strong>一个简单的方法是对每个特征进行加权后作为新的特征，然后训练一个线性模型在这个扩展的特征集。 这种方法称为多项式回归。</strong></p>
<p>于是，<strong>我们使用Scikit-Learning的PolynomialFeatures类进行训练数据集的转换，让训练集中每个特征的平方（2次多项式）作为新特征（在这种情况下，仅存在一个特征）</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly_features = PolynomialFeatures(degree=<span class="number">2</span>,include_bias=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_poly = poly_features.fit_transform(X)    <span class="comment"># 转换特征，包含原始特征和二次项特征</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[<span class="number">0</span>]</span><br><span class="line">array([<span class="number">-0.75275929</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_poly[<span class="number">0</span>]</span><br><span class="line">array([<span class="number">-0.75275929</span>, <span class="number">0.56664654</span>])</span><br></pre></td></tr></table></figure>
<p>现在包含原始特X并加上了这个特征的平方X^2。<strong>现在你可以在这个扩展训练集上使用LinearRegression模型进行拟合</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_reg = LinearRegression()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_reg.fit(X_poly, y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_reg.intercept_, lin_reg.coef_</span><br><span class="line">(array([ <span class="number">1.78134581</span>]), array([[ <span class="number">0.93366893</span>, <span class="number">0.56456263</span>]]))</span><br><span class="line"><span class="comment"># 模型预测函数y=0.56*x_1^2+0.93*x_1+1.78</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>请注意，当存在多个特征时，多项式回归能够找出特征之间的关系（这是普通线性回归模型无法做到的）。 这是因为LinearRegression会自动添加当前阶数下特征的所有组合。例如，如果有两个特征a,b，使用3阶（degree=3）的LinearRegression时，不仅仅只有a2,a3,b2,同时也会有它们的其他组合项ab,a2b,ab2。</p>
</blockquote>
<h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>我们可以使用交叉验证来估计一个模型的泛化能力。<strong>如果一个模型在训练集上表现良好，通过交叉验证指标却得出其泛化能力很差，那么你的模型就是过拟合了。如果在这两方面都表现不好，那么它就是欠拟合了</strong>。这种方法可以告诉我们，你的模型是太复杂了还是太简单了。</p>
<p><strong>另一种方法是观察学习曲线：画出模型在训练集上的表现，同时画出以训练集规模为自变量的训练集函数。为了得到图像，需要在训练集的不同规模子集上进行多次训练</strong>。下面的代码定义了一个函数，用来画出给定训练集后的模型学习曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curves</span><span class="params">(model, X, y)</span>:</span></span><br><span class="line">    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line">    train_errors, val_errors = [], []</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(<span class="number">1</span>, len(X_train)):    <span class="comment"># 根据样本规模画出模型的表现</span></span><br><span class="line">        model.fit(X_train[:m], y_train[:m])</span><br><span class="line">        y_train_predict = model.predict(X_train[:m])</span><br><span class="line">        y_val_predict = model.predict(X_val)</span><br><span class="line">        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))</span><br><span class="line">        val_errors.append(mean_squared_error(y_val_predict, y_val))</span><br><span class="line">plt.plot(np.sqrt(train_errors), <span class="string">"r-+"</span>, linewidth=<span class="number">2</span>, label=<span class="string">"train"</span>)    <span class="comment"># 训练损失</span></span><br><span class="line">plt.plot(np.sqrt(val_errors), <span class="string">"b-"</span>, linewidth=<span class="number">3</span>, label=<span class="string">"val"</span>)    <span class="comment"># 验证损失</span></span><br></pre></td></tr></table></figure>
<p>我们一起看一下简单线性回归模型的学习曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lin_reg = LinearRegression()</span><br><span class="line">plot_learning_curves(lin_reg, X, y)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/05.jpg" alt=""></p>
<p><strong>上面的曲线表现了一个典型的欠拟合模型，两条曲线都到达高原地带并趋于稳定，并且最后两条曲线非常接近，同时误差值非常大。</strong></p>
<blockquote>
<p>如果你的模型在训练集上是欠拟合的，添加更多的样例是没用的。你需要使用一个更复杂的模型或者找到更好的特征。</p>
</blockquote>
<p>现在让我们看一个在相同数据上10阶多项式模型拟合的学习曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">polynomial_regression = Pipeline((</span><br><span class="line">    (<span class="string">"poly_features"</span>, PolynomialFeatures(degree=<span class="number">10</span>, include_bias=<span class="keyword">False</span>)),</span><br><span class="line">    (<span class="string">"sgd_reg"</span>, LinearRegression()),</span><br><span class="line">))</span><br><span class="line"></span><br><span class="line">plot_learning_curves(polynomial_regression, X, y)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/06.jpg" alt=""></p>
<ul>
<li>在训练集上，误差要比线性回归模型低的多。</li>
<li>图中的两条曲线之间有间隔，这意味模型在训练集上的表现要比验证集上好的多，这也是模型过拟合的显著特点。当然，如果你使用了更大的训练数据，这两条曲线最后会非常的接近。</li>
</ul>
<blockquote>
<p>改善模型过拟合的一种方法是提供更多的训练数据，直到训练误差和验证误差相等</p>
</blockquote>
<p>在统计和机器学习领域有个重要的理论：一个模型的泛化误差由三个不同误差的和决定：</p>
<ul>
<li>偏差：泛化误差的这部分误差是由于错误的假设决定的。例如实际是一个二次模型，你却假设了一个线性模型。一个高偏差的模型最容易出现欠拟合。</li>
<li>方差：这部分误差是由于模型对训练数据的微小变化较为敏感，一个多自由度的模型更容易有高的方差（例如一个高阶多项式模型），因此会导致模型过拟合。</li>
<li>不可约误差：这部分误差是由于数据本身的噪声决定的。降低这部分误差的唯一方法就是进行数据清洗（例如：修复数据源，修复坏的传感器，识别和剔除异常值）。</li>
</ul>
<p>下图依次为欠拟合，过拟合，较合适。</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/07.jpg" alt=""></p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>器学习中有几个常用的范数，分别是：</p>
<ul>
<li>$L_1$−范数：$\Vert x\Vert_1 =\sum_{i=1}^n\vert x_i\vert$ </li>
<li>$L_2$−范数：$\Vert x\Vert_ 2=(\sum_{i=1}^n\vert x_i^2\vert)^{\frac{1}{2}}$ </li>
<li>$L_p$−范数：$\Vert x\Vert_p =(\sum_{i=1}^n\vert x_i^p\vert)^{\frac{1}{p}}$ </li>
<li>$L_∞$−范数：$\Vert x\Vert_∞=lim_{p→∞}(\sum_{i=1}^n\vert x_i^p\vert)^{\frac{1}{p}}$</li>
</ul>
<h2 id="岭回归-Ridge"><a href="#岭回归-Ridge" class="headerlink" title="岭回归(Ridge)"></a>岭回归(Ridge)</h2><p>岭回归（也称为Tikhonov正则化）是线性回归的正则化版，是L2正则的基础，注意到这个正则项只有在训练过程中才会被加到代价函数。当得到完成训练的模型后，我们应该使用没有正则化的测量方法去评价模型的表现。</p>
<blockquote>
<p><strong>一般情况下，训练过程使用的代价函数和测试过程使用的评价函数不一样样的。除了正则化，还有一个不同：训练时的代价函数应该在优化过程中易于求导，而在测试过程中，评价函数更应该接近最后的客观表现</strong>。一个好的例子：在分类训练中我们使用对数损失（马上我们会讨论它）作为代价函数，但是我们却使用精确率/召回率来作为它的评价函数。</p>
</blockquote>
<p>岭回归代价函数:</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum\limits_{i=1}^n\theta_i^2</script><p><strong>超参数α 决定了你想正则化这个模型的强度,正则化强度越大，模型会越简单。如果α=0 那此时的岭回归便变为了线性回归。如果α 非常的大，所有的权重最后都接近与零，最后结果将是一条穿过数据平均值的水平直线</strong></p>
<p>值得注意的是偏差 $\theta_0$是没有被正则化的（累加运算的开始是 i=1而不是i=0）。如我定义<strong>$w$</strong>作为特征的权重向量($\theta_1$到$\theta_n$)，那么正则项可以简写成$\frac{1}{2} (\Vert w\Vert_2)^2$, 其中$\Vert \cdot \Vert_2$ 表示权重向量的L2范数。对于梯度下降来说仅仅在均方差梯度向量加上一项$\alpha w$ ,加上$\alpha\theta$是$1/2∗\alpha∗\theta^2$求偏导的结果</p>
<blockquote>
<p>在使用岭回归前，对<strong>数据进行放缩（可以使用StandardScaler）是非常重要的</strong>,算法对于输入特征的数值尺度（scale）非常敏感。<strong>大多数的正则化模型都是这样的</strong>。</p>
</blockquote>
<p>对线性回归来说，对于岭回归，我们可以使用封闭方程去计算，也可以使用梯度下降去处理.</p>
<p>岭回归的封闭方程的解</p>
<p>令</p>
<script type="math/tex; mode=display">
MES(\theta)=(X\theta-y)^T(X\theta-y)+\lambda \theta^T\theta</script><script type="math/tex; mode=display">
\frac{\partial }{\partial \theta}MSE(\theta) =X^TX\theta-X^Ty +\alpha\theta=0</script><p>求出</p>
<script type="math/tex; mode=display">
\hat{\theta} =({\mathbf{X}}^T\cdot\mathbf{X}+\alpha\mathbf{I})^{-1}\cdot{\mathbf{X}}^T\cdot\mathbf{y}</script><blockquote>
<p> 矩阵$I$是是一个除了左上角有一个0的n×n的<strong>单位矩阵</strong>，这个0代表偏差项。偏差$\theta_0$不被正则化的。</p>
</blockquote>
<p>下面是如何使用 Scikit-Learn 来进行封闭方程的求解（使用 Cholesky 法进行矩阵分解对上面公式进行变形）:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ridge_reg = Ridge(alpha=<span class="number">1</span>, solver=<span class="string">"cholesky"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ridge_reg.fit(X, y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ridge_reg.predict([[<span class="number">1.5</span>]])</span><br><span class="line">array([[ <span class="number">1.55071465</span>]]</span><br></pre></td></tr></table></figure>
<p>使用随机梯度法进行求解：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_reg = SGDRegressor(penalty=<span class="string">"l2"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_reg.fit(X, y.ravel())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_reg.predict([[<span class="number">1.5</span>]])</span><br><span class="line">array([[ <span class="number">1.13500145</span>]])</span><br></pre></td></tr></table></figure>
<p><code>penalty</code>参数指的是正则项的惩罚类型。指定“l2”表明你要在损失函数上添加一项：权重向量 L2范数平方的一半，这就是简单的岭回归。</p>
<h2 id="Lasso-回归"><a href="#Lasso-回归" class="headerlink" title="Lasso 回归"></a>Lasso 回归</h2><p>Lasso 回归（也称 Least Absolute Shrinkage，或者 Selection Operator Regression）是另一种正则化版的线性回归：L1正则的基础，就像岭回归那样，它也在损失函数上添加了一个正则化项，但是它使用权重向量的L1范数而不是权重向量L2范数的一半。</p>
<p>Lasso回归的代价函数:</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+\alpha\sum\limits_{i=1}^n\left|\theta_i \right|</script><blockquote>
<p><strong>Lasso回归的一个重要特征是它倾向于完全消除最不重要的特征的权重（即将它们设置为零）</strong></p>
</blockquote>
<p>下面是一个使用Lasso类的小Scikit-Learn示例。你也可以使用SGDRegressor(penalty=”l1”)来代替它</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lasso_reg = Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lasso_reg.fit(X, y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lasso_reg.predict([[<span class="number">1.5</span>]])</span><br><span class="line">array([ <span class="number">1.53788174</span>]</span><br></pre></td></tr></table></figure>
<h2 id="弹性网络-ElasticNet"><a href="#弹性网络-ElasticNet" class="headerlink" title="弹性网络(ElasticNet)"></a>弹性网络(ElasticNet)</h2><p><strong>弹性网络介于Ridge回归和Lasso回归之间。它的正则项是Ridge回归和Lasso回归正则项的简单混合，同时你可以控制它们的混合率r，当r=0时，弹性网络就是Ridge回归，当r=1时，其就是Lasso回归</strong></p>
<p>弹性网络代价函数：</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+r\alpha\sum\limits_{i=1}^n\left|\theta_i \right|+\frac{1-r}{2}\alpha\sum\limits_{i=1}^n\theta_i^2</script><p>那么我们该如何选择线性回归，岭回归，Lasso回归，弹性网络呢？一般来说有一点正则项的表现更好，因此通常你应该避免使用简单的线性回归。<strong>岭回归是一个很好的首选项，但是如果你的特征仅有少数是真正有用的，你应该选择Lasso和弹性网络</strong>。就像我们讨论的那样，它两能够将无用特征的权重降为零。<strong>一般来说，弹性网络的表现要比Lasso好，因为当特征数量比样例的数量大的时候，或者特征之间有很强的相关性时，Lasso可能会表现的不规律</strong>。下面是一个使用Scikit-Learn 弹性网络ElasticNet（l1_ratio指的就是混合率r）的简单样例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>elastic_net = ElasticNet(alpha=<span class="number">0.1</span>, l1_ratio=<span class="number">0.5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>elastic_net.fit(X, y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>elastic_net.predict([[<span class="number">1.5</span>]])</span><br><span class="line">array([ <span class="number">1.54333232</span>])</span><br></pre></td></tr></table></figure>
<h2 id="正则化的作用"><a href="#正则化的作用" class="headerlink" title="正则化的作用"></a>正则化的作用</h2><p>那为什么正则化能起作用呢？首先L0范数（元素非零个数，严格上来说不能算是范数）和L1范数都可以实现权重稀疏。<strong>L1范数和L0范数可以实现稀疏，</strong>L1范数是L0范数的最优凸近似，<strong>L1因具有比L0更好的优化求解特性而被广泛应用</strong>。L1会趋向于产生少量的特征，而其他的特征都是0，<strong>而L2会选择更多的特征，这些特征都会接近于0</strong>。</p>
<p>L1范数的主要作用的实现稀疏特征，那么L2范数可以起什么样作用呢？</p>
<p>执行 L2 正则化对模型具有以下影响</p>
<ul>
<li>使权重的平均值接近于 0，且呈正态（钟形曲线或高斯曲线）分布。</li>
</ul>
<ul>
<li>使权重值接近于 0（但并非正好为 0）</li>
</ul>
<p><strong>L2 正则化可能会导致对于某些信息缺乏的特征，模型会学到适中的权重。L2 正则化降低较大权重的程度高于降低较小权重的程度。随着权重越来越接近于 0.0，L2 将权重“推”向 0.0 的力度越来越弱。L2 正则化会使相似度高(存在噪点)两个特征的权重几乎相同。按照我自己的理解，不同的权重会有不同程度的拟合效果，权重较小，低阶的w控制曲线的整体走势，权重较大，高阶的w控制曲线的局部形态，以此类推。这样看来L2正则项的作用就很明显了，要改变预测曲线的整体细节走势肯地会造成损失函数的不满，但是把曲线的形态熨平似乎并没有什么不妥，会降低过拟合的风险。</strong></p>
<p>L2除了能防止过拟合，提升模型的泛化能力。还有另外的一点好处：优化计算。  从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。conditionnumber是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，如果一个矩阵的condition number在1附近，那么它就是well-conditioned的，如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的，它的输出结果就不要太相信了。</p>
<p>然而，如果当我们的样本X的数目比每个样本的维度还要小的时候，矩阵XTX将会不是满秩的，也就是XTX会变得不可逆，所以w*就没办法直接计算出来了。或者更确切地说，将会有无穷多个解（因为我们方程组的个数小于未知数的个数）。也就是说，我们的数据不足以确定一个解，如果我们从所有可行解里随机选一个的话，很可能并不是真正好的解，总而言之，我们过拟合了。</p>
<p>但如果加上L2规则项，就变成了下面这种情况，就可以直接求逆了：</p>
<script type="math/tex; mode=display">
\hat{\theta} =({\mathbf{X}}^T\cdot\mathbf{X}+\alpha\mathbf{I})^{-1}\cdot{\mathbf{X}}^T\cdot\mathbf{y}</script><p> 这里面，专业点的描述是：要得到这个解，我们通常并不直接求矩阵的逆，而是通过解线性方程组的方式（例如高斯消元法）来计算。考虑没有规则项的时候，也就是λ=0的情况，如果矩阵XTX的 condition number 很大的话，解线性方程组就会在数值上相当不稳定，而这个规则项的引入则可以改善condition number。</p>
<h1 id="早期停止法（Early-Stopping）"><a href="#早期停止法（Early-Stopping）" class="headerlink" title="早期停止法（Early Stopping）"></a>早期停止法（Early Stopping）</h1><p>随着训练的进行，算法一直学习，它在训练集上的预测误差（RMSE）自然而然的下降。然而一段时间后，验证误差停止下降，并开始上升。这意味着模型在训练集上开始出现过拟合。一旦验证错误达到最小值，便提早停止训练.</p>
<p>随机梯度和小批量梯度下降不是平滑曲线，你可能很难知道它是否达到最小值。 一种解决方案是，只有<strong>在验证误差高于最小值一段时间后（你确信该模型不会变得更好了），才停止</strong>，<strong>之后将模型参数回滚到验证误差最小值</strong>。</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/08.png" alt=""></p>
<p>下面是一个早期停止法的基础应用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line">sgd_reg = SGDRegressor(n_iter=<span class="number">1</span>, warm_start=<span class="keyword">True</span>, penalty=<span class="keyword">None</span>,learning_rate=<span class="string">"constant"</span>, eta0=<span class="number">0.0005</span>)</span><br><span class="line"></span><br><span class="line">minimum_val_error = float(<span class="string">"inf"</span>)</span><br><span class="line">best_epoch = <span class="keyword">None</span></span><br><span class="line">best_model = <span class="keyword">None</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sgd_reg.fit(X_train_poly_scaled, y_train)    <span class="comment"># 训练多项式的新特征，拟合非线性</span></span><br><span class="line">    y_val_predict = sgd_reg.predict(X_val_poly_scaled)</span><br><span class="line">    val_error = mean_squared_error(y_val_predict, y_val)</span><br><span class="line">    <span class="keyword">if</span> val_error &lt; minimum_val_error:</span><br><span class="line">        minimum_val_error = val_error</span><br><span class="line">        best_epoch = epoch</span><br><span class="line">        best_model = clone(sgd_reg)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：当warm_start=True时，调用fit()方法后，训练会从停下来的地方继续，而不是从头重新开始</p>
</blockquote>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p><strong>逻辑回归</strong>会生成一个<strong>介于 0 到 1 之间（不包括 0 和 1）的概率值</strong>，而不是确切地预测结果是 0 还是 1。以用于检测垃圾邮件的逻辑回归模型为例。如果此模型推断某一特定电子邮件的值为 0.932，则意味着该电子邮件是垃圾邮件的概率为 93.2%。<strong>更准确地说，这意味着在无限训练样本的极限情况下，模型预测其值为 0.932 的这组样本实际上有 93.2% 是垃圾邮件，其余的 6.8% 不是垃圾邮件。</strong></p>
<p>逻辑回归模型的概率估计（向量形式）：</p>
<script type="math/tex; mode=display">
\hat{p}=h_\theta(\mathbf{x})=\sigma(\theta^T  \cdot \mathbf{x})</script><p>Logistic函数（也称为logit），用σ() 表示，其是一个sigmoid函数（图像呈S型），它的输出是一个介于0和1之间的数字<br>逻辑函数(S函数)</p>
<script type="math/tex; mode=display">
\sigma(t)=\frac{1}{1+exp(-t)}</script><p>Logistic函数（也称为logit），用σ() 表示，其是一个sigmoid函数（图像呈S型），它的输出是一个介于0和1之间的数字<br>逻辑函数(S函数)</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/09.jpg" alt=""></p>
<p>逻辑回归预测模型(σ() 概率输出以0.5作为二分类门槛):</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/10.jpg" alt=""></p>
<p>单个样例的代价函数:</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/11.jpg" alt=""></p>
<p><strong>这个代价函数是合理的，因为当t接近0时，-log(t)变得非常大，所以如果模型估计一个正例概率接近于0，那么代价函数将会很大，同时如果模型估计一个负例的概率接近1，那么代价函数同样会很大。 另一方面，当t接近于1时， -log(t)接近0，所以如果模型估计一个正例概率接近于0，那么代价函数接近于0，同时如果模型估计一个负例的概率接近0，那么代价函数同样会接近于0， 这正是我们想的.（简单来说,y=1时，概率p越接近1损失越小；相反y=0时，概率p越接近0时损失越小）</strong></p>
<p>整个训练集的代价函数只是所有训练实例的平均值。可以用一个表达式（你可以很容易证明）来统一表示，称为对数损失</p>
<p><strong>逻辑回归的代价函数（对数损失）：</strong></p>
<script type="math/tex; mode=display">
J(\theta)=-\frac{1}{m}\sum\limits_{i=1}^m\left[y^{(i)}log\left(\hat{p}^{(i)}\right)+\left(1-y^{(i)}\right)log\left(1-\hat{p}^{(i)}\right)\right]</script><p>但是这个代价函数对于求解最小化代价函数的θ 是没有公式解的（<strong>没有等价的正态方程</strong>）。 <strong>但好消息是，这个代价函数是凸的，所以梯度下降</strong>（或任何其他优化算法）一定能够找到全局最小值（如果学习速率不是太大，并且你等待足够长的时间）。下面公式给出了代价函数关于第j个模型参数θj 的偏导数。</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/20.png" alt=""></p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/22.jpg" alt=""></p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/21.jpg" alt=""></p>
<p>逻辑回归代价函数的偏导数:</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial \theta_j}J(\theta_j)=\frac{1}{m} \sum\limits_{i=1}^m{\left(\sigma\left(\theta^T \cdot \mathbf{x}^{(i)}\right)-y^{(i)}\right)}{x_j}^{(i)}</script><p>这个公式首先计算每个样例的预测误差，然后误差项乘以第j项特征值，最后求出所有训练样例的平均值。 一旦你有了包含所有的偏导数的梯度向量，你便可以在梯度向量上使用批量梯度下降算法。 也就是说：你已经知道如何训练Logistic回归模型。 对于随机梯度下降，你当然只需要每一次使用一个实例，对于小批量梯度下降，你将每一次使用一个小型实例集。</p>
<h1 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h1><p>我们使用鸢尾花数据集来分析Logistic回归。 这是一个著名的数据集，其中包含150朵三种不同的鸢尾花的萼片和花瓣的长度和宽度。这三种鸢尾花为：Setosa，Versicolor，Virginica</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/12.png" alt=""></p>
<p>让我们尝试建立一个分类器，仅仅<strong>使用花瓣的宽度特征来**</strong>识别Virginica**，首先让我们加载数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>iris = datasets.load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(iris.keys())</span><br><span class="line">[<span class="string">'data'</span>, <span class="string">'target_names'</span>, <span class="string">'feature_names'</span>, <span class="string">'target'</span>, <span class="string">'DESCR'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = iris[<span class="string">"data"</span>][:, <span class="number">3</span>:] <span class="comment"># petal width</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = (iris[<span class="string">"target"</span>] == <span class="number">2</span>).astype(np.int)</span><br></pre></td></tr></table></figure>
<p>接下来，我们训练一个逻辑回归模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(X, y) <span class="comment"># 训练模型</span></span><br></pre></td></tr></table></figure>
<p>我们来看看模型估计的花瓣宽度从0到3厘米的概率估计</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_new = np.linspace(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1000</span>).reshape(<span class="number">-1</span>, <span class="number">1</span>)    <span class="comment"># 构造花瓣宽度从0到3厘米的所有特征</span></span><br><span class="line">y_proba = log_reg.predict_proba(X_new)    <span class="comment"># 预测概率</span></span><br><span class="line">plt.plot(X_new, y_proba[:, <span class="number">1</span>], <span class="string">"g-"</span>, label=<span class="string">"Iris-Virginica"</span>)</span><br><span class="line">plt.plot(X_new, y_proba[:, <span class="number">0</span>], <span class="string">"b--"</span>, label=<span class="string">"Not Iris-Virginica"</span></span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/13.png" alt=""></p>
<p>Virginica花的花瓣宽度（用三角形表示）在1.4厘米到2.5厘米之间，而其他种类的花（由正方形表示）通常具有较小的花瓣宽度，范围从0.1厘米到1.8厘米。注意，它们之间会有一些重叠。在大约2厘米以上时，分类器非常肯定这朵花是Virginica花（分类器此时输出一个非常高的概率值），而在1厘米以下时，它非常肯定这朵花不是Virginica花（不是Virginica花有非常高的概率）。在这两个极端之间，分类器是不确定的。但是，如果你使用它进行预测（使用predict()方法而不是predict_proba()方法），它将返回一个最可能的结果。<strong>因此，在1.6厘米左右存在一个决策边界，这时两类情况出现的概率都等于50％</strong>：如果花瓣宽度大于1.6厘米，则分类器将预测该花是Virginica，否则预测它不是（即使它有可能错了）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>log_reg.predict([[<span class="number">1.7</span>], [<span class="number">1.5</span>]])</span><br><span class="line">array([<span class="number">1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>下图的线性决策边界表示相同的数据集，<strong>但是这次使用了两个特征进行判断：花瓣的宽度和长度</strong>。 一旦训练完毕，Logistic回归分类器就可以根据这两个特征来估计一朵花是Virginica的可能性。 <strong>虚线表示这时两类情况出现的概率都等于50％：这是模型的决策边界。</strong> <strong>请注意，它是一个线性边界。每条平行线都代表一个分类标准下的两两个不同类的概率，从15％（左下角）到90％（右上角）。</strong>越过右上角分界线的点都有超过90％的概率是Virginica花</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/14.png" alt=""></p>
<p>就像其他线性模型，逻辑回归模型也可以ℓ1或者ℓ2 惩罚使用进行正则化。Scikit-Learn默认添加了ℓ2 惩罚</p>
<blockquote>
<p>在Scikit-Learn的LogisticRegression模型中控制正则化强度的超参数不是α （与其他线性模型一样），而是是它的逆：C. C的值越大，模型正则化强度越低</p>
</blockquote>
<h1 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h1><p>Logistic回归模型可以直接推广到支持多类别分类，不必组合和训练多个二分类器， 其称为Softmax回归或多类别Logistic回归.</p>
<p>这个想法很简单：<strong>当给定一个实例x 时，Softmax回归模型首先计算k类的分数sk(x) ，然后将分数应用在Softmax函数（也称为归一化指数）上，估计出每类的概率</strong>。 计算sk(x) 的公式看起来很熟悉，因为它就像线性回归预测的公式一样</p>
<blockquote>
<p>k类的Softmax得分: $s_k(x)=θ^T⋅x$</p>
</blockquote>
<p>注意，每个类都有自己独一无二的参数向量θk 。 所有这些向量通常作为行放在参数矩阵Θ 中</p>
<p><strong>一旦你计算了样例x 的每一类的得分，你便可以通过Softmax函数估计出样例属于第k类的概率p^k ：通过计算e的sk(x) 次方，然后对它们进行归一化（除以所有分子的总和）</strong>。</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/15.png" alt=""></p>
<p>和Logistic回归分类器一样，Softmax回归分类器将估计概率最高（它只是得分最高的类）的那类作为预测结果，如公式4-21所示</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/16.png" alt=""></p>
<blockquote>
<p>Softmax回归分类器一次只能预测一个类（即它是多类的，但不是多输出的），因此它只能用于判断互斥的类别，如不同类型的植物。 你不能用它来识别一张照片中的多个人。</p>
</blockquote>
<p>现在我们知道这个模型如何估计概率并进行预测，接下来将介绍如何训练。<strong>我们的目标是建立一个模型在目标类别上有着较高的概率（因此其他类别的概率较低），最小化公式4-22可以达到这个目标，其表示了当前模型的代价函数，称为交叉熵，当模型对目标类得出了一个较低的概率，其会惩罚这个模型。 交叉熵通常用于衡量待测类别与目标类别的匹配程度（我们将在后面的章节中多次使用它）</strong></p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/17.png" alt=""></p>
<h1 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h1><p>熵的本质是香农信息量$log\frac{1}{p}$的期望。<strong>信息熵</strong>代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小（猜题次数、编码长度等），就是用<strong>交叉熵</strong>来衡量的。</p>
<p>现有关于样本集的2个概率分布p和q，其中p为真实分布，q非真实分布。按照真实分布p来衡量识别一个样本的所需要的编码长度的期望(即平均编码长度)为$H(p)=\sum \limits_{i=1}^n p(i)\cdot log\frac{1}{p(i)}$ 。如果使用错误分布q来表示来自真实分布p的平均编码长度，则应该是$H(p,q)=\sum\limits_{i=1}^n p(i)\cdot log\frac{1}{q(i)}$ 。因为用q来编码的样本来自分布p，所以期望H(p,q)中概率是p(i)。<strong>H(p,q)我们称之为“交叉熵”</strong>。<strong>当q为真实分布p时，交叉熵达到最小值1，否则将会大于1</strong>。我们将由q得到的平均编码长度比由p得到的平均编码长度多出的bit数称为“<strong>相对熵</strong>”：$D(p\Vert q)=H(p,q)-H(p)=\sum\limits_{i=1}^n p(i)\cdot log\frac{p(i)}{q(i)}$  ,其又被称为KL散度(Kullback–Leibler divergence，KLD)。<strong>它表示两个概率分布的差异性</strong>：差异越大则相对熵越大，差异越小则相对熵越小，特别地，若2者相同则熵为0。</p>
<p>另外，<strong>通常“相对熵”也可称为“交叉熵”</strong>，因为真实分布p是固定的，D(p||q)由H(p,q)决定。<strong>所以他们得到的相对效果是一样程度的</strong>。当然也有特殊情况，彼时两者须区别对待。</p>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/18.png" alt=""></p>
<p><strong>上面这个公式由公式4-22求导得到，过程和逻辑回归损失函数一样，只不过将每个类别都纳入计算而已，当k=2则计算正负两类，与逻辑回归一模一样。现在你可以计算每一类的梯度向量，然后使用梯度下降（或者其他的优化算法）找到使得代价函数达到最小值的参数矩阵Θ</strong>。</p>
<p>让我们使用Softmax回归对三种鸢尾花进行分类。当你使用LogisticRregression对模型进行训练时，<strong>Scikit_Learn默认使用的是一对多模型，但是你可以设置multi_class参数为“multinomial”来把它改变为Softmax回归。你还必须指定一个支持Softmax回归的求解器，例如“lbfgs”求解器</strong>（有关更多详细信息，请参阅Scikit-Learn的文档）。<strong>其默认使用ℓ12 正则化，你可以使用超参数C控制它。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = iris[<span class="string">"data"</span>][:, (<span class="number">2</span>, <span class="number">3</span>)] <span class="comment"># petal length, petal width</span></span><br><span class="line">y = iris[<span class="string">"target"</span>]</span><br><span class="line"></span><br><span class="line">softmax_reg = LogisticRegression(multi_class=<span class="string">"multinomial"</span>,solver=<span class="string">"lbfgs"</span>, C=<span class="number">10</span>)</span><br><span class="line">softmax_reg.fit(X, y)</span><br></pre></td></tr></table></figure>
<p>所以下次你发现一个花瓣长为5厘米，宽为2厘米的鸢尾花时，你可以问你的模型你它是哪一类鸢尾花，它会回答94.2％是Virginica花（第二类），或者5.8％是其他鸢尾花</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>softmax_reg.predict([[<span class="number">5</span>, <span class="number">2</span>]])</span><br><span class="line">array([<span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>softmax_reg.predict_proba([[<span class="number">5</span>, <span class="number">2</span>]])</span><br><span class="line">array([[ <span class="number">6.33134078e-07</span>, <span class="number">5.75276067e-02</span>, <span class="number">9.42471760e-01</span>]])是</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/14/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（三）：回归/19.png" alt=""></p>
<p>图4-25用不同背景色表示了结果的决策边界。注意，任何两个类之间的决策边界是线性的。 该图的曲线表示Versicolor类的概率（例如，用0.450标记的曲线表示45％的概率边界）。注意模型也可以预测一个概率低于50％的类。 例如，在所有决策边界相遇的地方，所有类的估计概率相等，分别为33％。</p>
<h1 id="练习题"><a href="#练习题" class="headerlink" title="练习题"></a>练习题</h1><ol>
<li>如果你有一个数百万特征的训练集，你应该选择哪种线性回归训练算法？</li>
<li>假设你训练集中特征的数值尺度（scale）有着非常大的差异，哪种算法会受到影响？有多大的影响？对于这些影响你可以做什么？</li>
<li>训练 Logistic 回归模型时，梯度下降是否会陷入局部最低点？</li>
<li>在有足够的训练时间下，是否所有的梯度下降都会得到相同的模型参数？</li>
<li>假设你使用批量梯度下降法，画出每一代的验证误差。当你发现验证误差一直增大，接下来会发生什么？你怎么解决这个问题？</li>
<li>当验证误差升高时，立即停止小批量梯度下降是否是一个好主意？</li>
<li>哪个梯度下降算法（在我们讨论的那些算法中）可以最快到达解的附近？哪个的确实会收敛？怎么使其他算法也收敛？</li>
<li>假设你使用多项式回归，画出学习曲线，在图上发现学习误差和验证误差之间有着很大的间隙。这表示发生了什么？有哪三种方法可以解决这个问题？</li>
<li>假设你使用岭回归，并发现训练误差和验证误差都很高，并且几乎相等。你的模型表现是高偏差还是高方差？这时你应该增大正则化参数$\alpha$ 还是降低它？</li>
<li>你为什么要这样做：</li>
</ol>
<ul>
<li>使用岭回归代替线性回归？</li>
<li>Lasso 回归代替岭回归？</li>
<li>弹性网络代替 Lasso 回归？</li>
</ul>
<ol>
<li>假设你想判断一副图片是室内还是室外，白天还是晚上。你应该选择二个逻辑回归分类器，还是一个 Softmax 分类器？</li>
</ol>
<hr>
<p>1、如果您拥有具有数百万个功能的训练集，则可以使用随机梯度下降或小批量梯度下降，如果计算内存足够的话，则可使用批量梯度下降。 但是你不能使用正态方程，因为计算复杂度随着特征数量的增长而快速增长（超过二次方），求矩阵特征的逆非常花时间。</p>
<p>2、如果训练集中的特征具有非常不同的比例，则损失函数将具有细长碗的形状，因此梯度下降优化将花费很长时间来收敛。 要解决此问题，您应该在训练模型之前缩放数据。 另外，正态方程在没有缩放的情况下可以正常工作。</p>
<p>3、在训练Logistic回归模型时，梯度下降不会陷入在局部最小值，因为它的损失函数是凸函数的。</p>
<p>4、如果优化问题是凸函数的（例如线性回归或逻辑回归），并且假设学习速率不是太高，则所有梯度下降算法将接近全局最优并最终产生相当类似的模型。 但是，除非你逐渐降低学习率，否则随机梯度下降和小批量GD将永远不会真正收敛; 相反，他们将继续围绕全局最佳状态来回跳跃。 这意味着即使你让它们运行很长时间，这些Gradient Descent算法也会产生略微不同的模型。</p>
<p>5、如果验证误差在每个时期之后一直上升，则一种可能性是学习速率太高并且算法发散。如果训练误差也会增加，那么这显然是问题，你应该降低学习率。 但是，如果训练错误没有增加，那么您的模型将过度拟合训练集，您应该停止训练。</p>
<p>6、由于随机性，随机梯度下降和小批量梯度下降都不能保证在每次训练迭代中都取得进展。 因此，如果在验证损失增加时立即停止训练，你可能会在达到最佳值之前过早停止。 更好的选择是定期保存模型，当它长时间没有改进时（意味着它可能永远不会超过记录），你可以恢复到最佳保存模型。</p>
<p>7、随机梯度下降具有最快的训练迭代，因为它一次只考虑一个训练实例，因此它通常是第一个到达全局最优值（或具有非常小的小批量大小的Minibatch GD）附近。 但是，如果有足够的训练时间，只有批量梯度下降实际上会收敛。 如上所述，除非你逐渐降低学习速度，否则随机指标GD和小批量GD将在最佳状态下反弹。</p>
<p>8、如果验证误差远远高于训练误差，则可能是因为你的模型过度拟合了训练集。 尝试解决此问题的一种方法是降低多项式度：具有较少自由度的模型不太可能过度拟合。 你可以尝试的另一件事是加入正则项，例如，通过在成本函数中添加ℓ2惩罚（岭）或ℓ1惩罚（Lasso）。 这也会降低模型的自由度。 最后，你还可以尝试增加训练集的大小。</p>
<p>9、如果训练误差和验证误差几乎相等且相当高，则模型可能欠拟合训练集，这意味着它具有高偏差。 你应该尝试减少正则化超参数α。</p>
<p>10、</p>
<ul>
<li>具有一些正则化的模型通常比没有任何正则化的模型表现更好，因此通常应该优先选择岭回归而不是简单的线性回归。</li>
<li>Lasso回归使用ℓ1惩罚，这往往会将权重降低到恰好为零。 这导致稀疏模型，除了最重要的权重之外，所有权重都为零。 这是一种自动执行特征选择的方法，如果你怀疑只有少数特征真正重要，这是很好的。 当你不确定时，你应该更偏向岭回归。</li>
<li>弹性网络常比Lasso更受欢迎，因为Lasso在某些情况下可能表现不稳定（当有些特征强烈相关或者特征数量比训练样本数量还要多）。 但是，它确实添加了一个额外的超参数来调整。 如果你想要具有稳定行为的Lasso，你可以使用弹性网络，并设置比率r接近1。</li>
</ul>
<p>11、如果你想将图片分类为室外/室内和白天/夜晚，因为这些不是专属类别（即，所有四种组合都是可能的），你应该训练两个Logistic回归分类器。</p>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/" itemprop="url">Sklearn 与 TensorFlow 机器学习实用指南（二）：分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-11T10:57:46+08:00">
                2018-07-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Sklearn-与-TensorFlow-机器学习实用指南/" itemprop="url" rel="index">
                    <span itemprop="name">Sklearn 与 TensorFlow 机器学习实用指南</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  7,758
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  31
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="MNIST：手写数字分类数据集"><a href="#MNIST：手写数字分类数据集" class="headerlink" title="MNIST：手写数字分类数据集"></a>MNIST：手写数字分类数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_mldata</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mnist = fetch_mldata(<span class="string">'MNIST original'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mnist</span><br><span class="line">&#123;<span class="string">'COL_NAMES'</span>: [<span class="string">'label'</span>, <span class="string">'data'</span>],</span><br><span class="line"><span class="string">'DESCR'</span>: <span class="string">'mldata.org dataset: mnist-original'</span>,   <span class="comment"># DESCR键描述数据集</span></span><br><span class="line"><span class="string">'data'</span>: array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],    <span class="comment"># 数组的一行表示一个样例，一列表示一个特征</span></span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                ...,</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=uint8),</span><br><span class="line"><span class="string">'target'</span>: array([ <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, ..., <span class="number">9.</span>, <span class="number">9.</span>, <span class="number">9.</span>])&#125;    <span class="comment"># target键存放一个标签数组</span></span><br><span class="line">X, y = mnist[<span class="string">"data"</span>], mnist[<span class="string">"target"</span>] <span class="comment"># 获取样本或标签</span></span><br></pre></td></tr></table></figure>
<p>MNIST 有 70000 张图片，每张图片有 784 个特征。<strong>这是因为每个图片都是28×28像素的，并且每个像素的值介于 0~255 之间</strong>。让我们看一看数据集的某一个数字。你只需要将某个实例的特征向量，reshape为28*28的数组，然后使用 Matplotlib 的imshow函数展示出来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">some_digit = X[<span class="number">36000</span>]    </span><br><span class="line">some_digit_image = some_digit.reshape(<span class="number">28</span>, <span class="number">28</span>)    <span class="comment"># 将样本转为28大小的像素矩阵</span></span><br><span class="line"><span class="comment"># 按‘0’‘1’数值转为灰度图像 </span></span><br><span class="line"><span class="comment"># interpolation当小图像放大时,interpolation ='nearest'效果很好，否则用None。</span></span><br><span class="line">plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=<span class="string">"nearest"</span>)    </span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/01.jpg" alt=""></p>
<p>MNIST 数据集已经事先被分成了一个训练集（前 6000 张图片）和一个测试集（最后 10000 张图片）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = X[:<span class="number">60000</span>], X[<span class="number">60000</span>:], y[:<span class="number">60000</span>], y[<span class="number">60000</span>:]</span><br></pre></td></tr></table></figure>
<p>打乱数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">shuffle_index = np.random.permutation(<span class="number">60000</span>)</span><br><span class="line">X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]</span><br></pre></td></tr></table></figure>
<h2 id="训练一个二分类器"><a href="#训练一个二分类器" class="headerlink" title="训练一个二分类器"></a>训练一个二分类器</h2><p>现在我们简化一下问题，只尝试去识别一个数字，比如说，数字 5。这个“数字 5 检测器”就是一个二分类器，能够识别两类别，“是 5”和“非 5”。让我们为这个分类任务创建目标向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练和测试集上区分是否为5转为0,1标签矩阵</span></span><br><span class="line">y_train_5 = (y_train == <span class="number">5</span>) <span class="comment"># True for all 5s, False for all other digits.</span></span><br><span class="line">y_test_5 = (y_test == <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p><strong>采用随机梯度下降分类器</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)    <span class="comment">#如果你想重现结果，你应该固定参数random_state </span></span><br><span class="line">sgd_clf.fit(X_train, y_train_5)</span><br></pre></td></tr></table></figure>
<p>输出预测结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</span><br><span class="line">array([ <span class="keyword">True</span>], dtype=bool)</span><br></pre></td></tr></table></figure>
<p>分类器猜测这个数字代表 5（True）。看起来在这个例子当中，它猜对了。现在让我们评估这个模型的性能。</p>
<h2 id="使用交叉验证测量准确性"><a href="#使用交叉验证测量准确性" class="headerlink" title="使用交叉验证测量准确性"></a>使用交叉验证测量准确性</h2><p>评估一个模型的好方法是使用交叉验证，像之前提过一样。<strong>但有时为了有更好的控制权，可以写自己版本的交叉验证，以下代码粗略地做了和cross_val_score()相同的事情，并且输出相同的结果</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line">skfolds = StratifiedKFold(n_splits=<span class="number">3</span>, random_state=<span class="number">42</span>)    <span class="comment"># 三组</span></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skfolds.split(X_train, y_train_5):</span><br><span class="line">    clone_clf = clone(sgd_clf)</span><br><span class="line">    X_train_folds = X_train[train_index]</span><br><span class="line">    y_train_folds = (y_train_5[train_index])</span><br><span class="line">    X_test_fold = X_train[test_index]</span><br><span class="line">    y_test_fold = (y_train_5[test_index])</span><br><span class="line">    clone_clf.fit(X_train_folds, y_train_folds)</span><br><span class="line">    y_pred = clone_clf.predict(X_test_fold)</span><br><span class="line">    n_correct = sum(y_pred == y_test_fold)</span><br><span class="line">    print(n_correct / len(y_pred)) <span class="comment"># prints 0.9502, 0.96565 and 0.96495</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>StratifiedKFold类实现了分层采样，生成的折（fold）包含了各类相应比例的样例。在每一次迭代，上述代码生成分类器的一个克隆版本，在训练折（training folds）的克隆版本上进行训，在测试折（test folds）上进行预测。然后它计算出被正确预测的数目和输出正确预测的比例。</p>
</blockquote>
<p><strong>这里使用sklearn提供的cross_val_score()函数来评估SGDClassifier模型</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>)</span><br><span class="line">array([ <span class="number">0.9502</span> , <span class="number">0.96565</span>, <span class="number">0.96495</span>]</span><br></pre></td></tr></table></figure>
<p>有大于 95% 的精度（accuracy），特别高！但要注意这是一个有数据偏差的数据集，这是因为只有 10% 的图片是数字 5，所以你总是猜测某张图片不是 5，你也会有90%的可能性是对的。处理这类问题，要回归到之前讲的准确率和召回率和ORC曲线了。</p>
<h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><p>对分类器来说，一个好得多的性能评估指标是混淆矩阵，<strong>为了计算混淆矩阵，首先你需要有一系列的预测值，这样才能将预测值与真实值做比较</strong>。你或许想在测试集上做预测。但是我们现在先不碰它。（记住，只有当你处于项目的尾声，当你准备上线一个分类器的时候，你才应该使用测试集）。<strong>相反，你应该使用cross_val_predict()函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line">y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><strong>就像 cross_val_score()，cross_val_predict()也使用 K 折交叉验证。它不是返回一个评估分数，而是返回基于每一个测试折做出的一个预测值</strong>。这意味着，对于每一个训练集的样例，你得到一个干净的预测（“干净”是说一个模型在训练过程当中没有用到测试集的数据）。</p>
<p><strong>现在使用 confusion_matrix()函数，你将会得到一个混淆矩阵</strong>。传递目标类(y_train_5)和预测类（y_train_pred）给它。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>confusion_matrix(y_train_5, y_train_pred)</span><br><span class="line">array([[<span class="number">53272</span>, <span class="number">1307</span>],</span><br><span class="line">        [ <span class="number">1077</span>, <span class="number">4344</span>]])</span><br></pre></td></tr></table></figure>
<p><strong>混淆矩阵中的每一行表示一个实际的类, 而每一列表示一个预测的类</strong>。该矩阵的第一行认为“非 5”（反例）中的 53272 张被正确归类为 “非 5”（他们被称为真反例，true negatives）, 而其余 1307 被错误归类为”是 5” （假正例，false positives）。第二行认为“是 5” （正例）中的 1077 被错误地归类为“非 5”（假反例，false negatives），其余 4344 正确分类为 “是 5”类（真正例，true positives）。一个完美的分类器将只有真反例和真正例，所以混淆矩阵的非零值仅在其主对角线（左上至右下）。</p>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/12.png" alt=""></p>
<p>Scikit-Learn 提供了一些函数去计算分类器的指标，包括精确率和召回率（之前的文章是tensorflow，这里主要讲Scikit-Learn）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>precision_score(y_train_5, y_pred) <span class="comment"># == 4344 / (4344 + 1307)</span></span><br><span class="line"><span class="number">0.76871350203503808</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recall_score(y_train_5, y_train_pred) <span class="comment"># == 4344 / (4344 + 1077)</span></span><br><span class="line"><span class="number">0.79136690647482011</span></span><br></pre></td></tr></table></figure>
<p>通常结合精确率和召回率会更加方便，这个指标叫做“F1 值”，特别是当你需要一个简单的方法去比较两个分类器的优劣的时候。F1 值是精确率和召回率的调和平均。普通的平均值平等地看待所有的值，而调和平均会给小的值更大的权重。<strong>所以，要想分类器得到一个高的 F1 值，需要召回率和精确率</strong>。</p>
<script type="math/tex; mode=display">F1 = \frac{2}{\frac{1}{precision} + \frac{1}{recall}} = 2 * \frac{precison * recall}{precison + recall} = \frac{TP}{TP + \frac{FN + FP}{2}}</script><p>为了计算 F1 值，简单调用f1_score()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_pred)</span><br><span class="line"><span class="number">0.78468208092485547</span></span><br></pre></td></tr></table></figure>
<p>F1 支持那些有着相近精确率和召回率的分类器。这不会总是你想要的。有的场景你会绝大程度地关心精确率，而另外一些场景你会更关心召回率。不幸的是，你不能同时拥有两者。增加精确率会降低召回率，反之亦然。这叫做精确率与召回率之间的折衷<strong>.</strong>  <strong>一般来说，提高分类阈值会减少假正例，从而提高精确率。降低分类阈值会提高召回率。</strong></p>
<p><strong>Scikit-Learn 不让你直接设置阈值，但是它给你提供了设置决策分数的方法，这个决策分数可以用来产生预测。它不是调用分类器的predict()方法，而是调用decision_function()方法。这个方法返回每一个样例的分数值，然后基于这个分数值，使用你想要的任何阈值做出预测。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores</span><br><span class="line">array([ <span class="number">161855.74572176</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>threshold = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_some_digit_pred = (y_scores &gt; threshold)</span><br><span class="line">array([ <span class="keyword">True</span>], dtype=bool)</span><br></pre></td></tr></table></figure>
<p>SGDClassifier用了一个等于 0 的阈值，所以前面的代码返回了跟predict()方法一样的结果（都返回了true）。<strong>让我们提高这个阈值：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>threshold = <span class="number">200000</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_some_digit_pred = (y_scores &gt; threshold)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_some_digit_pred</span><br><span class="line">array([<span class="keyword">False</span>], dtype=bool)</span><br></pre></td></tr></table></figure>
<p>这证明了提高阈值会降调召回率。这个图片实际就是数字 5，当阈值等于 0 的时候，分类器可以探测到这是一个 5，当阈值提高到 20000 的时候，分类器将不能探测到这是数字 5。</p>
<p><strong>那么，你应该如何使用哪个阈值呢？首先，你需要再次使用cross_val_predict()得到每一个样例的分数值，但是这一次指定返回一个决策分数，而不是预测值。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, </span><br><span class="line">                            method=<span class="string">"decision_function"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>现在有了这些分数值。对于任何可能的阈值，使用precision_recall_curve(),你都可以计算精确率和召回率:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>
<p>最后，你可以使用 Matplotlib 画出精确率和召回率，这里把精确率和召回率当作是阈值的一个函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_precision_recall_vs_threshold</span><span class="params">(precisions, recalls, thresholds)</span>:</span></span><br><span class="line">    plt.plot(thresholds, precisions[:<span class="number">-1</span>], <span class="string">"b--"</span>, label=<span class="string">"Precision"</span>)</span><br><span class="line">    plt.plot(thresholds, recalls[:<span class="number">-1</span>], <span class="string">"g-"</span>, label=<span class="string">"Recall"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Threshold"</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">    plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plot_precision_recall_vs_threshold(precisions, recalls, thresholds)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/02.png" alt=""></p>
<blockquote>
<p>你也许会好奇为什么精确率曲线比召回率曲线更加起伏不平（右上部分）。原因是精确率有时候会降低，尽管当你提高阈值的时候，通常来说精确率会随之提高。另一方面，当阈值提高时候，召回率只会降低。这也就说明了为什么召回率的曲线更加平滑。</p>
</blockquote>
<p>现在你可以选择适合你任务的最佳阈值。<strong>另一个选出好的精确率/召回率折衷的方法是直接画出精确率对召回率的曲线(PR曲线)</strong>，如图所示。</p>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/03.png" alt=""></p>
<p><strong>我们假设你决定达到 90% 的准确率，在 70000 附近找到一个阈值。为了作出预测（目前为止只在训练集上预测），你可以运行以下代码，而不是运行分类器的predict()方法。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred_90 = (y_scores &gt; <span class="number">70000</span>)</span><br></pre></td></tr></table></figure>
<p>检查这些预测的准确率和召回率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>precision_score(y_train_5, y_train_pred_90)</span><br><span class="line"><span class="number">0.8998702983138781</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recall_score(y_train_5, y_train_pred_90)</span><br><span class="line"><span class="number">0.63991883416343853</span></span><br></pre></td></tr></table></figure>
<h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>受试者工作特征（ROC）曲线是另一个二分类器常用的工具。它非常类似与准确率/召回率曲线（PR曲线），但不是画出准确率对召回率的曲线，<strong>ROC 曲线是真正例率（true positive rate，另一个名字叫做召回率）对假正例率（false positive rate, FPR）的曲线</strong>。FPR 是反例被错误分成正例的比率。它等于 1 减去真反例率（true negative rate， TNR）。TNR是反例被正确分类的比率。TNR也叫做特异性。所以 ROC 曲线画出召回率对（1 减特异性）的曲线。</p>
<script type="math/tex; mode=display">TPR = \frac{TP}{P} = \frac{TP}{TP+FN}</script><script type="math/tex; mode=display">
FPR = \frac{FP}{N} = \frac{FP}{FP+TN} = 1-TNR</script><script type="math/tex; mode=display">
TNR = \frac{TN}{N} = \frac{TN}{TN+FP}</script><p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/04.png" alt=""></p>
<p><strong>为了画出 ROC 曲线，你首先需要计算各种不同阈值下的 TPR、FPR，使用roc_curve()函数：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>
<p>然后你可以使用 matplotlib，画出 FPR 对 TPR 的曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curve</span><span class="params">(fpr, tpr, label=None)</span>:</span></span><br><span class="line">    plt.plot(fpr, tpr, linewidth=<span class="number">2</span>, label=label)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'k--'</span>)</span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plot_roc_curve(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/05.png" alt=""></p>
<p>一个比较分类器之间优劣的方法是：测量ROC曲线下的面积（AUC）**。一个完美的分类器的 ROC AUC 等于 1，而一个纯随机分类器的 ROC AUC 等于 0.5。Scikit-Learn 提供了一个函数来计算 ROC AUC：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores)</span><br><span class="line"><span class="number">0.97061072797174941</span></span><br></pre></td></tr></table></figure>
<p><strong>因为 ROC 曲线跟准确率/召回率曲线（或者叫 PR）很类似，你或许会好奇如何决定使用哪一个曲线呢？一个笨拙的规则是，优先使用 PR 曲线当正例很少，或者当你关注假正例多于假反例的时候。其他情况使用 ROC 曲线</strong>。举例子，回顾前面的 ROC 曲线和 ROC AUC 数值，你或许人为这个分类器很棒。但是这几乎全是因为只有少数正例（“是 5”），而大部分是反例（“非 5”）。相反，PR 曲线清楚显示出这个分类器还有很大的改善空间（PR 曲线应该尽可能地靠近右上角）。</p>
<p>我们训练一个RandomForestClassifier，然后拿它的的ROC曲线和ROC AUC数值去跟SGDClassifier的比较。<strong>首先你需要得到训练集每个样例的数值</strong>。<strong>但是由于随机森林分类器的工作方式，RandomForestClassifier不提供decision_function()方法。相反，它提供了predict_proba()方法</strong>。Skikit-Learn分类器通常二者中的一个。<strong>predict_proba()方法返回一个数组，数组的每一行代表一个样例，每一列代表一个类。数组当中的值的意思是：给定一个样例属于给定类的概率。比如，70%的概率这幅图是数字 5。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">forest_clf = RandomForestClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=<span class="number">3</span>,</span><br><span class="line">                                    method=<span class="string">"predict_proba"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>但是要画 ROC 曲线，你需要的是样例的分数，而不是概率</strong>。一个简单的解决方法是使用正例的概率当作样例的分数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_scores_forest = y_probas_forest[:, <span class="number">1</span>] <span class="comment"># score = proba of positive class 预测为正例概率</span></span><br><span class="line">fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)</span><br></pre></td></tr></table></figure>
<p>现在你即将得到 ROC 曲线。<strong>将前面一个分类器的 ROC 曲线一并画出来是很有用的，可以清楚地进行比较</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(fpr, tpr, <span class="string">"b:"</span>, label=<span class="string">"SGD"</span>)</span><br><span class="line">plot_roc_curve(fpr_forest, tpr_forest, <span class="string">"Random Forest"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"bottom right"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/06.png" alt=""></p>
<p>如你所见，RandomForestClassifier的 ROC 曲线比SGDClassifier的好得多：<strong>它更靠近左上角。所以，它的 ROC AUC 也会更大。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores_forest)</span><br><span class="line"><span class="number">0.99312433660038291</span></span><br></pre></td></tr></table></figure>
<p>现在你知道如何训练一个二分类器，选择合适的标准，<strong>使用交叉验证去评估你的分类器，选择满足你需要的准确率/召回率折衷方案，和比较不同模型的 ROC 曲线和 ROC AUC 数值</strong>。现在让我们检测更多的数字，而不仅仅是一个数字 5。</p>
<h2 id="多类别分类"><a href="#多类别分类" class="headerlink" title="多类别分类"></a>多类别分类</h2><p><strong>一些算法（比如随机森林分类器或者朴素贝叶斯分类器）可以直接处理多类分类问题。其他一些算法（比如 SVM 分类器或者线性分类器）则是严格的二分类器。然后，有许多策略可以让你用二分类器去执行多类分类。</strong></p>
<ul>
<li>一个方法是：训练10个二分类器，每一个对应一个数字（探测器 0，探测器 1，探测器 2，以此类推）。然后当你想对某张图片进行分类的时候，让每一个分类器对这个图片进行分类，选出决策分数最高的那个分类器（One vs all 里面分数最高的One）。这叫做“一对所有”（OvA）策略</li>
<li>另一个策略是对每一对数字都训练一个二分类器：一个分类器用来处理数字 0 和数字 1，一个用来处理数字 0 和数字 2，一个用来处理数字 1 和 2，以此类推。这叫做“一对一”（OvO）策略。如果有 N 个类。你需要训练N*(N-1)/2个分类器。</li>
</ul>
<p><strong>一些算法（比如 SVM 分类器）在训练集的大小上很难扩展，所以对于这些算法，OvO 是比较好的，因为它可以在小的数据集上面可以更多地训练，较之于巨大的数据集而言。但是，对于大部分的二分类器来说，OvA 是更好的选择。Scikit-Learn 可以探测出你想使用一个二分类器去完成多分类的任务，它会自动地执行 OvA（除了 SVM 分类器，它使用 OvO）</strong>让我们试一下SGDClassifier.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.fit(X_train, y_train) <span class="comment"># y_train, not y_train_5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br></pre></td></tr></table></figure>
<p>上面的代码在训练集上训练了一个SGDClassifier。这个分类器处理原始的目标class，从 0 到 9（y_train），而不是仅仅探测是否为 5 （y_train_5）。然后它做出一个判断（在这个案例下只有一个正确的数字）。<strong>在幕后，Scikit-Learn 实际上训练了 10 个二分类器，每个分类器都产到一张图片的决策数值，选择数值最高的那个类</strong>。</p>
<p>为了证明这是真实的，<strong>你可以调用decision_function()方法。不是返回每个样例的一个数值，而是返回 10 个数值，一个数值对应于一个类</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores</span><br><span class="line">array([[<span class="number">-311402.62954431</span>, <span class="number">-363517.28355739</span>, <span class="number">-446449.5306454</span> ,</span><br><span class="line">        <span class="number">-183226.61023518</span>, <span class="number">-414337.15339485</span>, <span class="number">161855.74572176</span>,</span><br><span class="line">        <span class="number">-452576.39616343</span>, <span class="number">-471957.14962573</span>, <span class="number">-518542.33997148</span>,</span><br><span class="line">        <span class="number">-536774.63961222</span>]])</span><br></pre></td></tr></table></figure>
<p>最高数值是对应于类别 5 :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(some_digit_scores)    <span class="comment"># 找最大值的索引</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.classes_</span><br><span class="line">array([ <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>, <span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.classes[<span class="number">5</span>]    <span class="comment"># 用索引匹配类别</span></span><br><span class="line"><span class="number">5.0</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>一个分类器被训练好了之后，它会保存目标类别列表到它的属性classes_ 中去，按照值排序。在本例子当中，在classes_ 数组当中的每个类的索引方便地匹配了类本身，比如，索引为 5 的类恰好是类别 5 本身。但通常不会这么幸运。</p>
</blockquote>
<p><strong>如果你想强制 Scikit-Learn 使用 OvO 策略或者 OvA 策略，你可以使用OneVsOneClassifier类或者OneVsRestClassifier类。创建一个样例，传递一个二分类器给它的构造函数</strong>。举例子，下面的代码会创建一个多类分类器，使用 OvO 策略，基于SGDClassifier。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsOneClassifier</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=<span class="number">42</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(ovo_clf.estimators_)</span><br><span class="line"><span class="number">45</span></span><br></pre></td></tr></table></figure>
<p>训练一个RandomForestClassifier同样简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br></pre></td></tr></table></figure>
<p>这次 Scikit-Learn 没有必要去运行 OvO 或者 OvA，因为<strong>随机森林分类器能够直接将一个样例分到多个类别。你可以调用predict_proba()，得到样例对应的类别的概率值的列表</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict_proba([some_digit])</span><br><span class="line">array([[ <span class="number">0.1</span>, <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.1</span>, <span class="number">0.</span> , <span class="number">0.8</span>, <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.</span> ]])</span><br></pre></td></tr></table></figure>
<p>你可以看到这个分类器相当确信它的预测：在数组的索引 5 上的 0.8，意味着这个模型以 80% 的概率估算这张图片代表数字 5。它也认为这个图片可能是数字 0 或者数字 3，分别都是 10% 的几率。</p>
<p>现在当然你想评估这些分类器。<strong>像平常一样，你想使用交叉验证</strong>。让我们用cross_val_score()来评估SGDClassifier的精度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>)</span><br><span class="line">array([ <span class="number">0.84063187</span>, <span class="number">0.84899245</span>, <span class="number">0.86652998</span>])</span><br></pre></td></tr></table></figure>
<p>在所有测试折（test fold）上，它有 84% 的精度。如果你是用一个随机的分类器，你将会得到 10% 的正确率。所以这不是一个坏的分数，但是你可以做的更好。举例子，简单将输入正则化，将会提高精度到 90% 以上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))    <span class="comment"># 特征正则化，没说用哪种</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>)</span><br><span class="line">array([ <span class="number">0.91011798</span>, <span class="number">0.90874544</span>, <span class="number">0.906636</span> ])</span><br></pre></td></tr></table></figure>
<h2 id="误差分析："><a href="#误差分析：" class="headerlink" title="误差分析："></a>误差分析：</h2><p><strong>首先，你可以检查混淆矩阵。你需要使用cross_val_predict()做出预测，然后调用confusion_matrix()函数</strong>，像你早前做的那样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>conf_mx = confusion_matrix(y_train, y_train_pred)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>conf_mx</span><br><span class="line">array([[<span class="number">5725</span>, <span class="number">3</span>, <span class="number">24</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">49</span>, <span class="number">50</span>, <span class="number">10</span>, <span class="number">39</span>, <span class="number">4</span>],</span><br><span class="line">        [ <span class="number">2</span>, <span class="number">6493</span>, <span class="number">43</span>, <span class="number">25</span>, <span class="number">7</span>, <span class="number">40</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">109</span>, <span class="number">8</span>],</span><br><span class="line">        [ <span class="number">51</span>, <span class="number">41</span>, <span class="number">5321</span>, <span class="number">104</span>, <span class="number">89</span>, <span class="number">26</span>, <span class="number">87</span>, <span class="number">60</span>, <span class="number">166</span>, <span class="number">13</span>],</span><br><span class="line">        [ <span class="number">47</span>, <span class="number">46</span>, <span class="number">141</span>, <span class="number">5342</span>, <span class="number">1</span>, <span class="number">231</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">141</span>, <span class="number">92</span>],</span><br><span class="line">        [ <span class="number">19</span>, <span class="number">29</span>, <span class="number">41</span>, <span class="number">10</span>, <span class="number">5366</span>, <span class="number">9</span>, <span class="number">56</span>, <span class="number">37</span>, <span class="number">86</span>, <span class="number">189</span>],</span><br><span class="line">        [ <span class="number">73</span>, <span class="number">45</span>, <span class="number">36</span>, <span class="number">193</span>, <span class="number">64</span>, <span class="number">4582</span>, <span class="number">111</span>, <span class="number">30</span>, <span class="number">193</span>, <span class="number">94</span>],</span><br><span class="line">        [ <span class="number">29</span>, <span class="number">34</span>, <span class="number">44</span>, <span class="number">2</span>, <span class="number">42</span>, <span class="number">85</span>, <span class="number">5627</span>, <span class="number">10</span>, <span class="number">45</span>, <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">25</span>, <span class="number">24</span>, <span class="number">74</span>, <span class="number">32</span>, <span class="number">54</span>, <span class="number">12</span>, <span class="number">6</span>, <span class="number">5787</span>, <span class="number">15</span>, <span class="number">236</span>],</span><br><span class="line">        [ <span class="number">52</span>, <span class="number">161</span>, <span class="number">73</span>, <span class="number">156</span>, <span class="number">10</span>, <span class="number">163</span>, <span class="number">61</span>, <span class="number">25</span>, <span class="number">5027</span>, <span class="number">123</span>],</span><br><span class="line">        [ <span class="number">43</span>, <span class="number">35</span>, <span class="number">26</span>, <span class="number">92</span>, <span class="number">178</span>, <span class="number">28</span>, <span class="number">2</span>, <span class="number">223</span>, <span class="number">82</span>, <span class="number">5240</span>]])</span><br></pre></td></tr></table></figure>
<p>这里是一对数字。使用 Matplotlib 的matshow()函数，将混淆矩阵以图像的方式呈现，将会更加方便</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.matshow(conf_mx, cmap=plt.cm.gray)    <span class="comment"># #灰度图,对应位置的值越大色块越亮</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/07.png" alt=""></p>
<p>这个混淆矩阵看起来相当好，因为大多数的图片在主对角线上。在主对角线上意味着被分类正确。数字 5 对应的格子看起来比其他数字要暗淡许多。这可能是数据集当中数字 5 的图片比较少，又或者是分类器对于数字 5 的表现不如其他数字那么好。你可以验证两种情况.</p>
<p>让我们关注仅包含误差数据的图像呈现。<strong>首先你需要将混淆矩阵的每一个值除以相应类别的图片的总数目。这样子，你可以比较错误率，而不是绝对的错误数（这对大的类别不公平）</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">row_sums = conf_mx.sum(axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">norm_conf_mx = conf_mx / row_sums</span><br></pre></td></tr></table></figure>
<p><strong>现在让我们用 0 来填充对角线。这样子就只保留了被错误分类的数据</strong>。让我们画出这个结果。(此时数值为错误率)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.fill_diagonal(norm_conf_mx, <span class="number">0</span>)</span><br><span class="line">plt.matshow(norm_conf_mx, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/08.png" alt=""></p>
<p>现在你可以清楚看出分类器制造出来的各类误差。记住：行代表实际类别，列代表预测的类别。第 8、9 列相当亮，这告诉你许多图片被误分成数字 8 或者数字 9。相似的，第 8、9 行也相当亮，告诉你数字 8、数字 9 经常被误以为是其他数字。相反，一些行相当黑，比如第一行：这意味着大部分的数字 1 被正确分类（一些被误分类为数字 8 ）。留意到误差图不是严格对称的。举例子，比起将数字 8 误分类为数字 5 的数量，有更多的数字 5 被误分类为数字 8。</p>
<p><strong>分析混淆矩阵通常可以给你提供深刻的见解去改善你的分类器</strong>。回顾这幅图，看样子你应该努力改善分类器在数字 8 和数字 9 上的表现，和纠正 3/5 的混淆。举例子，你可以尝试去收集更多的数据，或者你可以构造新的、有助于分类器的特征。举例子，写一个算法去数闭合的环（比如，数字 8 有两个环，数字 6 有一个， 5 没有）。又或者你可以预处理图片（比如，使用 Scikit-Learn，Pillow， OpenCV）去构造一个模式，比如闭合的环。</p>
<p>分析独特的误差，是获得关于你的分类器是如何工作及其为什么失败的洞见的一个好途径。但是这相对难和耗时。举例子，我们可以画出数字 3 和 5 的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cl_a, cl_b = <span class="number">3</span>, <span class="number">5</span></span><br><span class="line">X_aa = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_a)]</span><br><span class="line">X_ab = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_b)]</span><br><span class="line">X_ba = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_a)]</span><br><span class="line">X_bb = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_b)]</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>); plot_digits(X_aa[:<span class="number">25</span>], ../images_per_row=<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>); plot_digits(X_ab[:<span class="number">25</span>], ../images_per_row=<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>); plot_digits(X_ba[:<span class="number">25</span>], ../images_per_row=<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>); plot_digits(X_bb[:<span class="number">25</span>], ../images_per_row=<span class="number">5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/09.png" alt=""></p>
<p>左边两个5*5的块将数字识别为 3，右边的将数字识别为 5。一些被分类器错误分类的数字（比如左下角和右上角的块）是书写地相当差，甚至让人类分类都会觉得很困难（比如第 8 行第 1 列的数字 5，看起来非常像数字 3 ）。但是，大部分被误分类的数字，在我们看来都是显而易见的错误。很难明白为什么分类器会分错。原因是我们使用的简单的SGDClassifier，这是一个线性模型。它所做的全部工作就是分配一个类权重给每一个像素，然后当它看到一张新的图片，它就将加权的像素强度相加，每个类得到一个新的值。所以，因为 3 和 5 只有一小部分的像素有差异，这个模型很容易混淆它们。</p>
<p>3 和 5 之间的主要差异是连接顶部的线和底部的线的细线的位置。如果你画一个 3，连接处稍微向左偏移，分类器很可能将它分类成 5。反之亦然。<strong>换一个说法，这个分类器对于图片的位移和旋转相当敏感。所以，减轻 3/5 混淆的一个方法是对图片进行预处理，确保它们都很好地中心化和不过度旋转。这同样很可能帮助减轻其他类型的错误</strong>。</p>
<h2 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h2><p>先看一个简单点的例子，仅仅是为了阐明的目的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">y_train_large = (y_train &gt;= <span class="number">7</span>)</span><br><span class="line">y_train_odd = (y_train % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">y_multilabel = np.c_[y_train_large, y_train_odd]</span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(X_train, y_multilabel)</span><br></pre></td></tr></table></figure>
<p><strong>这段代码创造了一个y_multilabel数组，里面包含两个目标标签。第一个标签指出这个数字是否为大数字（7，8 或者 9），第二个标签指出这个数字是否是奇数</strong>。<strong>接下来几行代码会创建一个KNeighborsClassifier样例（它支持多标签分类，但不是所有分类器都可以）</strong>，然后我们使用多目标数组来训练它。现在你可以生成一个预测，然后它输出两个标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn_clf.predict([some_digit])</span><br><span class="line">array([[<span class="keyword">False</span>, <span class="keyword">True</span>]], dtype=bool)</span><br></pre></td></tr></table></figure>
<p>它工作正确。数字 5 不是大数（False），同时是一个奇数（True）</p>
<p>有许多方法去评估一个多标签分类器，和选择正确的量度标准，这取决于你的项目。举个例子，<strong>一个方法是对每个个体标签去量度 F1 值（或者前面讨论过的其他任意的二分类器的量度标准），然后计算平均值</strong>。下面的代码计算全部标签的平均 F1 值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train, y_train_knn_pred, average=<span class="string">"macro"</span>)</span><br><span class="line"><span class="number">0.96845540180280221</span></span><br></pre></td></tr></table></figure>
<p><strong>这里假设所有标签有着同等的重要性，但可能不是这样</strong>。特别是，如果你的 Alice 的照片比 Bob 或者 Charlie 更多的时候，也许你想让分类器在 Alice 的照片上具有更大的权重。<strong>一个简单的选项是：给每一个标签的权重等于它的支持度（比如，那个标签的样例的数目）。为了做到这点，简单地在上面代码中设置average=”weighted”。</strong></p>
<h2 id="多输出分类"><a href="#多输出分类" class="headerlink" title="多输出分类"></a>多输出分类</h2><p>我们即将讨论的最后一种分类任务被叫做“多输出-多类分类”（或者简称为多输出分类）。它是多标签分类的简单泛化，在这里每一个标签可以是多类别的（比如说，它可以有多于两个可能值）。</p>
<p><strong>为了说明这点，我们建立一个系统，它可以去除图片当中的噪音。它将一张混有噪音的图片作为输入，期待它输出一张干净的数字图片，用一个像素强度的数组表示，就像 MNIST 图片那样。注意到这个分类器的输出是多标签的（一个像素一个标签）和每个标签可以有多个值（像素强度取值范围从 0 到 255）。所以它是一个多输出分类系统的例子。</strong></p>
<blockquote>
<p>分类与回归之间的界限是模糊的，比如这个例子。按理说，预测一个像素的强度更类似于一个回归任务，而不是一个分类任务。而且，多输出系统不限于分类任务。你甚至可以让你一个系统给每一个样例都输出多个标签，包括类标签和值标签。</p>
</blockquote>
<p>让我们从 MNIST 的图片创建训练集和测试集开始，然后给图片的像素强度添加噪声，这里是用 NumPy 的randint()函数。目标图像是原始图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">noise = rnd.randint(<span class="number">0</span>, <span class="number">100</span>, (len(X_train), <span class="number">784</span>))</span><br><span class="line">noise = rnd.randint(<span class="number">0</span>, <span class="number">100</span>, (len(X_test), <span class="number">784</span>))</span><br><span class="line">X_train_mod = X_train + noise</span><br><span class="line">X_test_mod = X_test + noise</span><br><span class="line">y_train_mod = X_train</span><br><span class="line">y_test_mod = X_test</span><br></pre></td></tr></table></figure>
<p>让我们看一下测试集当中的一张图片（是的，我们在窥探测试集，所以你应该马上邹眉）：</p>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/10.png" alt=""></p>
<p>左边的加噪声的输入图片。右边是干净的目标图片。现在我们训练分类器，让它清洁这张图片：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.fit(X_train_mod, y_train_mod)</span><br><span class="line">clean_digit = knn_clf.predict([X_test_mod[some_index]])</span><br><span class="line">plot_digit(clean_digit)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/07/11/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（二）：分类/11.png" alt=""></p>
<hr>
<p>到这里就讲完分类的内容了，有点混乱对不对，我们来总结梳理一下。</p>
<ul>
<li><p>要掌握自定义k折交叉验证的方法（≈cross_val_score）</p>
</li>
<li><p>cross_val_score为验证模型的一个好方法，但是只能得到准确率的评估分数</p>
</li>
<li><p>如果正反例数据偏差大，我们需要用到混淆矩阵，这个矩阵要用到预测值而不是评估分数，所以改cross_val_predict，这会返回每个测试折做出的预测值，即y_train_pred </p>
</li>
<li><p>利用预测值y_train_pred可以得到混淆矩阵，精确率，召回率，F1</p>
</li>
<li><p>有时我们需要阈值来平衡精确率，召回率，而Scikit-Learn 不让你直接设置阈值，它会调用decision_function()方法。<strong>返回样例的分数值</strong>，然后基于这个分数值，使用你想要的任何阈值做出预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores</span><br><span class="line">array([ <span class="number">161855.74572176</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>threshold = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_some_digit_pred = (y_scores &gt; threshold)</span><br><span class="line">array([ <span class="keyword">True</span>], dtype=bool)</span><br></pre></td></tr></table></figure>
</li>
<li><p>每次都设定阈值不是一个完美的方法，如何才能找到合适的阈值呢？你需要再次使用cross_val_predict()得到每一个样例的分数值，<strong>但是这一次指定返回一个决策分数</strong>，<strong>而不是预测值</strong>。(阈值相关，就要进行打分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, </span><br><span class="line">                            method=<span class="string">"decision_function"</span>)</span><br></pre></td></tr></table></figure>
<p>现在有了这些分数值。对于任何可能的阈值，使用precision_recall_curve(),你都可以计算精确率和召回率；precisions, recalls, thresholds是任何阈值的范围值，可以变化曲线和PR曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>
</li>
<li><p>与PR曲线另一个相关的是ROC曲线（TPR/FPR），为了画出 ROC 曲线，你首先需要计算各种不同阈值下的 TPR、FPR，使用roc_curve()函数（还是要打分）；跳过ROC曲线(其实相当于已经做了)，想直接计算出ROC AUC也行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">roc_auc_score(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>
<p>如果想得到RandomForestClassifier的ROC曲线，由于RandomForestClassifier不提供decision_function()方法，相反，它提供了predict_proba()方法（另外一种概率打分），返回概率值，此时用正例概率作为分值。例如70%的概率是垃圾邮件。</p>
<p>另外，<strong>因为 ROC 曲线跟准确率/召回率曲线（或者叫 PR）很类似，你或许会好奇如何决定使用哪一个曲线呢？一个笨拙的规则是，优先使用 PR 曲线当正例很少，或者当你关注假正例多于假反例的时候。其他情况使用 ROC 曲线</strong></p>
</li>
<li><p>多类别分类有一对一ovo, 一对多ova两种方法，一般svm由于在训练集的大小上很难扩展，因为它可以在小的数据集上面可以更多地训练，故用ovo，其他大部分用ova。如果Scikit-Learn嗅探出你想做一个多分类任务，它会自动使用ova，svm训练器除外</p>
</li>
<li><p>误差分析，将混淆矩阵归一化后用图片色块输出，查看哪些类别经常被错误分类。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/" itemprop="url">Sklearn 与 TensorFlow 机器学习实用指南（一）：一个完整的程序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-09T16:06:11+08:00">
                2018-07-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Sklearn-与-TensorFlow-机器学习实用指南/" itemprop="url" rel="index">
                    <span itemprop="name">Sklearn 与 TensorFlow 机器学习实用指南</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9,367
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  38
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>写在前面：这个系列打算把「Hands-On Machine Learning with Scikit-Learn and TensorFlow 」重新梳理一遍，这本书在看完机器学习基础知识之后有一个很好的算法实践，对于算法落地有很多帮助。这次写的Sklearn 与 TensorFlow 机器学习实用指南系列，目的是让自己更清楚算法的每个流程处理，加强对一些机器学习模型理解。这本书在<a href="https://github.com/apachecn/hands_on_Ml_with_Sklearn_and_TF" target="_blank" rel="noopener">github</a>有中文的翻译版本（还在更新）.</p>
<hr>
<h1 id="拆分数据集"><a href="#拆分数据集" class="headerlink" title="拆分数据集"></a>拆分数据集</h1><h2 id="训练集-测试集"><a href="#训练集-测试集" class="headerlink" title="训练集+测试集"></a>训练集+测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_test</span><span class="params">(data, test_ratio)</span>:</span></span><br><span class="line">    shuffled_indices = np.random.permutation(len(data))    <span class="comment"># 打乱序列</span></span><br><span class="line">    test_set_size = int(len(data) * test_ratio)    <span class="comment"># 拆分比例</span></span><br><span class="line">    test_indices = shuffled_indices[:test_set_size]</span><br><span class="line">    train_indices = shuffled_indices[test_set_size:]</span><br><span class="line">    <span class="keyword">return</span> data.iloc[train_indices], data.iloc[test_indices]</span><br><span class="line">    </span><br><span class="line">train_set, test_set = split_train_test(housing, <span class="number">0.2</span>)    <span class="comment"># housing数据二八拆分</span></span><br></pre></td></tr></table></figure>
<p>或者直接将整体数据打乱，然后按需取量。(california_housing_dataframe为谷歌机器学习教程提供的加州住房数据)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">california_housing_dataframe = california_housing_dataframe.reindex(	<span class="comment"># 整体打乱</span></span><br><span class="line">    np.random.permutation(california_housing_dataframe.index))</span><br><span class="line">train_set = california_housing_dataframe.head(<span class="number">12000</span>)</span><br><span class="line">test_set = california_housing_dataframe.tail(<span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>以上为训练集+测试集的拆分方式</p>
<h2 id="训练集-验证集-测试集"><a href="#训练集-验证集-测试集" class="headerlink" title="训练集+验证集+测试集"></a>训练集+验证集+测试集</h2><p><strong>这样的拆分方式主要有存在一些不足。1、程序多次运行后，测试集的数据有可能会加入到训练集当中，调参时用于改进模型超参数的测试集会造成过拟合。2、不便于新数据的加入</strong></p>
<p>更好的办法是将数据集拆分为训练集+验证集+测试集。</p>
<p><img src="/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/01.png" alt=""></p>
<p>那如何解决新加入数据的问题呢？<strong>一个通常的解决办法是使用每个实例的识别码</strong>，以判定是否这个实例是否应该放入测试集（假设实例有单一且不变的识别码）。<strong>例如，你可以计算出每个实例识别码的哈希值，只保留其最后一个字节，如果值小于等于 51（约为 256 的 20%），就将其放入测试集。这样可以保证在多次运行中，测试集保持不变，即使更新了数据集。新的测试集会包含新实例中的 20%，但不会有之前位于训练集的实例</strong>。可能很多数据没有稳定的特征，最简单的办法就是利用索引作为识别码。下面的代码根据识别码按0.7,0.2,0.1比例拆分训练集、验证集和测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数identifier为单一且不变的识别码，可以为索引id</span></span><br><span class="line"><span class="comment"># hash(np.int64(identifier)).digest()[-1]返回识别码的哈希摘要值的最后一个字节</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_set_check</span><span class="params">(identifier, validate_ratio, test_ratio, hash)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">256</span> * test_ratio &lt;= hash(np.int64(identifier)).digest()[<span class="number">-1</span>] &lt; <span class="number">256</span> *      (validate_ratio+test_ratio)  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_set_check</span><span class="params">(identifier, test_ratio, hash)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> hash(np.int64(identifier)).digest()[<span class="number">-1</span>] &lt; <span class="number">256</span> * test_ratio    <span class="comment"># 记录满足条件的索引</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_test_by_id</span><span class="params">(data, validate_ratio, test_ratio, id_column, hash=hashlib.md5)</span>:</span></span><br><span class="line">    ids = data[id_column]	<span class="comment"># 确定识别码</span></span><br><span class="line">    in_validate_set = ids.apply(<span class="keyword">lambda</span> id_: validate_set_check(id_, validate_ratio, test_ratio，hash))</span><br><span class="line">    in_test_set = ids.apply(<span class="keyword">lambda</span> id_: test_set_check(id_, test_ratio, hash))</span><br><span class="line">    combine_set = np.bitwise_or(in_validate_set, in_test_set)</span><br><span class="line">    <span class="keyword">return</span> data.loc[~combine_set], data.loc[in_validate_set], data.loc[in_test_set]			                       </span><br><span class="line">housing_with_id = housing.reset_index()   <span class="comment"># housing数据增加一个索引列，放在数据的第一列</span></span><br><span class="line">train_set, validate_set, test_set = split_train_test_by_id(housing_with_id, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="string">"index"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="分成采样"><a href="#分成采样" class="headerlink" title="分成采样"></a>分成采样</h2><p>另外一种拆分方式：<strong>分成采样</strong></p>
<p><strong>将人群分成均匀的子分组，称为分层</strong>，从每个分层去除合适数量的实例，以保证测试集对总人数有代表性。例如，美国人口的 51.3% 是女性，48.7% 是男性。所以在美国，严谨的调查需要保证样本也是这个比例：513 名女性，487 名男性作为数据样本。数据集中的每个分层都要有足够的实例位于你的数据中，这点很重要。否则，对分层重要性的评估就会有偏差。这意味着，<strong>你不能有过多的分层</strong>，<strong>且每个分层都要足够大</strong>。后面的代码通过将收入中位数除以 1.5（以限制收入分类的数量），创建了一个收入类别属性，<strong>用ceil对值舍入（以产生离散的分类），然后将所有大于 5的分类归入到分类5 </strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预处理，创建"income_cat"属性 </span></span><br><span class="line"><span class="comment"># 凡是会对原数组作出修改并返回一个新数组的，往往都有一个 inplace可选参数</span></span><br><span class="line"><span class="comment"># inplace=True,原数组名对应的内存值直接改变;inplace=False,原数组名对应的内存值并不改变，新的结果赋给一个新的数组.</span></span><br><span class="line">housing[<span class="string">"income_cat"</span>] = np.ceil(housing[<span class="string">"median_income"</span>] / <span class="number">1.5</span>)</span><br><span class="line">housing[<span class="string">"income_cat"</span>].where(housing[<span class="string">"income_cat"</span>] &lt; <span class="number">5</span>, <span class="number">5.0</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在，就可以根据收入分类，进行分层采样。你可以使用 Scikit-Learn 的StratifiedShuffleSplit类</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"></span><br><span class="line"><span class="comment"># random_state为随机种子生成器，可以得到相同的随机结果</span></span><br><span class="line"><span class="comment"># n_splits是将训练数据分成train/test对的组数，这里汇总成一组数据</span></span><br><span class="line">split = StratifiedShuffleSplit(n_splits=<span class="number">1</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> split.split(housing, housing[<span class="string">"income_cat"</span>]):</span><br><span class="line">    strat_train_set = housing.loc[train_index]</span><br><span class="line">    strat_test_set = housing.loc[test_index]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在，你需要删除income_cat属性，使数据回到初始状态：    </span></span><br><span class="line"><span class="keyword">for</span> set <span class="keyword">in</span> (strat_train_set, strat_test_set):</span><br><span class="line">    set.drop([<span class="string">"income_cat"</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="将原始数据映射到特征"><a href="#将原始数据映射到特征" class="headerlink" title="将原始数据映射到特征"></a>将原始数据映射到特征</h2><p>我们在进行机器学习的时候，采用的数据样本往往是<strong>矢量</strong>（特征矢量），而我们的<strong>原始数据</strong>并不是以矢量的形式呈现给我们的，这是便需要将数据映射到特征</p>
<h3 id="整数和浮点数映射"><a href="#整数和浮点数映射" class="headerlink" title="整数和浮点数映射"></a>整数和浮点数映射</h3><p>直接映射便ok（虽然机器学习是<strong>根据浮点值进行的训练</strong>，但是不需要将整数6转换为6.0，这个过程是默认的）</p>
<h3 id="字符串映射"><a href="#字符串映射" class="headerlink" title="字符串映射"></a>字符串映射</h3><p>好多时候，有的特征是字符串，比如此前训练的加利福尼亚房产数据集中的<strong>街区名称</strong>，机器学习是无法根据字符串来学习规律的，所以需要转换。但是存在一个问题，如果字符特征是’’一环’’ ‘’二环’’ ‘’三环’’…（代表某个城市的地理位置），那么对其进行数值转换的时候，是不可以编码为形如1，2，3，4…这样的数据的，因为其存在数据大小的问题，学习模型会把他们的大小关系作为特征而学习，所以我们需要引入<a href="https://www.cnblogs.com/king-lps/p/7846414.html" target="_blank" rel="noopener"><strong>独热编码</strong></a>,（具体解释见链接，解释的很好）.<strong>我们需要把这些文本标签转换为数字</strong>。Scikit-Learn 为这个任务提供了一个转换器LabelEncoder：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单来说 LabelEncoder 是对不连续的数字或者文本进行编号</span></span><br><span class="line"><span class="comment"># le.fit([1,5,67,100])</span></span><br><span class="line"><span class="comment"># le.transform([1,1,100,67,5])</span></span><br><span class="line"><span class="comment"># 输出： array([0,0,3,2,1])</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = LabelEncoder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat = housing[<span class="string">"ocean_proximity"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_encoded = encoder.fit_transform(housing_cat)	<span class="comment"># 装换器</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_encoded</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, ..., <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>译注:</p>
<p>在原书中使用<code>LabelEncoder</code>转换器来转换文本特征列的方式是错误的，该转换器只能用来转换标签（正如其名）。在这里使用<code>LabelEncoder</code>没有出错的原因是该数据只有一列文本特征值，在有多个文本特征列的时候就会出错。应使用<code>factorize()</code>方法来进行操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; housing_cat_encoded, housing_categories = housing_cat.factorize()</span><br><span class="line">&gt; housing_cat_encoded[:<span class="number">10</span>]</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>&gt;</p>
<p>处理离散特征这还不够，Scikit-Learn 提供了一个编码器OneHotEncoder，用于将整书分类值转变为独热向量。注意fit_transform()用于 2D 数组，而housing_cat_encoded是一个 1D 数组，所以需要将其变形：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reshape(-1,1)里面的-1代表将数据自动计算有多少行，但是列数明确设置为1</span></span><br><span class="line"><span class="comment"># reshape(-1)则是变形为1行和自动计算有多少列</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = OneHotEncoder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot</span><br><span class="line">&lt;<span class="number">16513</span>x5 sparse matrix of type <span class="string">'&lt;class '</span>numpy.float64<span class="string">'&gt;'</span></span><br><span class="line">    <span class="keyword">with</span> <span class="number">16513</span> stored elements <span class="keyword">in</span> Compressed Sparse Row format&gt;</span><br></pre></td></tr></table></figure>
<p>注意输出结果是一个 SciPy 稀疏矩阵，而不是 NumPy 数组。当类别属性有数千个分类时，这样非常有用。经过独热编码，我们得到了一个有数千列的矩阵，这个矩阵每行只有一个 1，其余都是 0。使用大量内存来存储这些 0 非常浪费，所以稀疏矩阵只存储非零元素的位置。你可以像一个 2D 数据那样进行使用，但是如果你真的想将其转变成一个（密集的）NumPy 数组，只需调用toarray()方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot.toarray()</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure>
<p>使用类LabelBinarizer，我们可以用一步执行这两个转换（从文本分类到整数分类，再从整数分类到独热向量）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = LabelBinarizer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot = encoder.fit_transform(housing_cat)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>注意默认返回的结果是一个密集 NumPy 数组。向构造器LabelBinarizer传递sparse_output=True，就可以得到一个稀疏矩阵。</p>
<blockquote>
<p>译注:</p>
<p>在原书中使用<code>LabelBinarizer</code>的方式也是错误的，该类也应用于标签列的转换。正确做法是使用sklearn即将提供的<code>CategoricalEncoder</code>类。如果在你阅读此文时sklearn中尚未提供此类，用如下方式代替：（来自<a href="https://github.com/scikit-learn/scikit-learn/pull/9151" target="_blank" rel="noopener">Pull Request #9151）</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="comment">#from sklearn.preprocessing import CategoricalEncoder # in future versions of Scikit-Learn</span></span><br><span class="line">&gt;</span><br><span class="line">&gt; cat_encoder = CategoricalEncoder()</span><br><span class="line">&gt; housing_cat_reshaped = housing_cat.values.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">&gt; housing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)</span><br><span class="line">&gt; housing_cat_1hot</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>&gt;</p>
<blockquote>
</blockquote>
<h2 id="寻找良好特征（的特点）"><a href="#寻找良好特征（的特点）" class="headerlink" title="寻找良好特征（的特点）"></a>寻找良好特征（的特点）</h2><p>当得到特征之后，还是要进行筛选的，因为有的特征没有参考价值，就像我们的在做合成特征的时候，正常的特征数据是人均几间房间，而有的人是几十间，这明显没有参考价值<br>良好特征的几点原则</p>
<ul>
<li><p>避免很少使用的离散特征值：如果只是出现了一两次的特征几乎是没有意义的</p>
</li>
<li><p>最好具有清晰明确的含义：特征的含义不仅仅是让机器学习的模型学习的，人也要知道其具体的含义，不然不利于分析数据（最好将数值很大的秒转换为天数，或者年，让人看起来直观一些）</p>
</li>
<li><p>将“神奇”的值与实际数据混为一谈：有些特征中会出现一些”神奇的数据”，当然这些数据并不是很少的特征，而是超出范围的异常值，比如特征应该是介于0——1之间的，但是因为这个数据是空缺的，而采用的默认数值-1，那么这样的数值就是”神奇”，解决办法是，将该特征转换为两个特征：</p>
<ul>
<li>一个特征只存储质正常范围的值，不含神奇值。</li>
<li>一个特征存储布尔值，表示的信息为是否为空</li>
</ul>
</li>
<li><p>考虑上游不稳定性：由经验可知，特征的定义不应随时间发生变化，代表城市名称的话，那么特征值始终都该是城市的名称，但是有的时候，上游模型将特征值处理完毕后，返还给下游模型的却变成了数值，这样是不好的，因为这种表示在未来运行其他模型时可能轻易发生变化，那么特征就乱套了</p>
<p>​</p>
</li>
</ul>
<h3 id="可视化数据寻找规律："><a href="#可视化数据寻找规律：" class="headerlink" title="可视化数据寻找规律："></a>可视化数据寻找规律：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>, alpha=<span class="number">0.4</span>,</span><br><span class="line">    s=housing[<span class="string">"population"</span>]/<span class="number">100</span>, label=<span class="string">"population"</span>,</span><br><span class="line">    c=<span class="string">"median_house_value"</span>, cmap=plt.get_cmap(<span class="string">"jet"</span>), colorbar=<span class="keyword">True</span>,</span><br><span class="line">)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p>每个圈的半径表示街区的人口（选项s），颜色代表价格（选项c）。我们用预先定义的名为jet的颜色图（选项cmap），它的范围是从蓝色（低价）到红色（高价）：</p>
<p><img src="/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/02.png" alt=""></p>
<h3 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = housing.corr()</span><br></pre></td></tr></table></figure>
<h3 id="Pandas-的scatter-matrix函数"><a href="#Pandas-的scatter-matrix函数" class="headerlink" title="Pandas 的scatter_matrix函数"></a>Pandas 的scatter_matrix函数</h3><p>另一种检测属性间相关系数的方法是使用 Pandas 的scatter_matrix函数,它能画出每个数值属性对每个其它数值属性的图。因为现在共有 11 个数值属性，你可以得到11 ** 2 = 121张图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.tools.plotting <span class="keyword">import</span> scatter_matrix</span><br><span class="line"></span><br><span class="line">attributes = [<span class="string">"median_house_value"</span>, <span class="string">"median_income"</span>, <span class="string">"total_rooms"</span>,</span><br><span class="line">              <span class="string">"housing_median_age"</span>]</span><br><span class="line">scatter_matrix(housing[attributes], figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br></pre></td></tr></table></figure>
<p>得到两个属性的散点图</p>
<p><img src="/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/03.png" alt=""></p>
<h2 id="清查数据"><a href="#清查数据" class="headerlink" title="清查数据"></a>清查数据</h2><p>截至目前，我们假定用于训练和测试的所有数据都是值得信赖的。在现实生活中，数据集中的很多样本是不可靠的，原因有以下一种或多种：</p>
<ul>
<li><strong>遗漏值。</strong> 例如，有人忘记为某个房屋的年龄输入值。(值会为-1，所以要分为两个特征，忘了的看上面)</li>
<li><strong>重复样本。</strong> 例如，服务器错误地将同一条记录上传了两次。</li>
<li><strong>不良标签。</strong> 例如，有人错误地将一颗橡树的图片标记为枫树。</li>
<li><strong>不良特征值。</strong> 例如，有人输入了多余的位数，或者温度计被遗落在太阳底下。</li>
</ul>
<p>一旦检测到存在这些问题，通常需要将相应样本从数据集中移除，从而“修正”不良样本。要检测遗漏值或重复样本，可以编写一个简单的程序。检测不良特征值或标签可能会比较棘手，可采用可视化数据的方法。</p>
<p><strong>对于处理特征丢失的问题</strong>。前面，你应该注意到了属性total_bedrooms有一些缺失值。有三个解决选项：</p>
<ul>
<li>去掉对应的街区；（数据大可用）</li>
<li>去掉整个属性；</li>
<li>进行赋值（0、平均值、中位数等等）。</li>
</ul>
<p>用DataFrame的dropna()，drop()，和fillna()方法，可以方便地实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">housing.dropna(subset=[<span class="string">"total_bedrooms"</span>])    <span class="comment"># 选项1</span></span><br><span class="line">housing.drop(<span class="string">"total_bedrooms"</span>, axis=<span class="number">1</span>)       <span class="comment"># 选项2    axis=0对行操作，axis=1对列操作</span></span><br><span class="line">median = housing[<span class="string">"total_bedrooms"</span>].median()</span><br><span class="line">housing[<span class="string">"total_bedrooms"</span>].fillna(median)     <span class="comment"># 选项3</span></span><br></pre></td></tr></table></figure>
<p>如果选择选项 3，你需要计算训练集的中位数，用中位数填充训练集的缺失值，<strong>不要忘记保存该中位数</strong>。后面用<strong>测试集</strong>评估系统时，<strong>需要替换测试集中的缺失值</strong>，也可以用来实时替换新数据中的缺失值。</p>
<p>Scikit-Learn 提供了一个方便的类来处理缺失值：Imputer。下面是其使用方法：首先，需要创建一个Imputer实例，指定用该属性的中位数替换它的每个缺失值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line">imputer = Imputer(strategy=<span class="string">"median"</span>)    <span class="comment"># 进行中位数赋值</span></span><br></pre></td></tr></table></figure>
<p><strong>因为只有数值属性才能算出中位数，我们需要创建一份不包括文本属性ocean_proximity的数据副本：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing_num = housing.drop(<span class="string">"ocean_proximity"</span>, axis=<span class="number">1</span>) <span class="comment"># 去除ocean_proximity不为数值属性的特征</span></span><br></pre></td></tr></table></figure>
<p>现在，就可以用fit()方法将imputer实例拟合到训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imputer.fit(housing_num)</span><br></pre></td></tr></table></figure>
<p>imputer计算出了每个属性的中位数，并将结果保存在了实例变量statistics_中。只有属性total_bedrooms有缺失值，但是我们<strong>确保一旦系统运行起来，新的数据中没有缺失值</strong>，所以<strong>安全的做法是将imputer应用到每个数值</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>imputer.statistics_    <span class="comment"># 实例变量statistics_和housing_num数值数据得到的中位数是一样的</span></span><br><span class="line">array([ <span class="number">-118.51</span> , <span class="number">34.26</span> , <span class="number">29.</span> , <span class="number">2119.</span> , <span class="number">433.</span> , <span class="number">1164.</span> , <span class="number">408.</span> , <span class="number">3.5414</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_num.median().values</span><br><span class="line">array([ <span class="number">-118.51</span> , <span class="number">34.26</span> , <span class="number">29.</span> , <span class="number">2119.</span> , <span class="number">433.</span> , <span class="number">1164.</span> , <span class="number">408.</span> , <span class="number">3.5414</span>])</span><br></pre></td></tr></table></figure>
<p>现在，你就可以使用这个“训练过的”imputer来对训练集进行转换，通过将缺失值替换为中位数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = imputer.transform(housing_num)</span><br></pre></td></tr></table></figure>
<p>结果是一个普通的 Numpy 数组，包含有转换后的特征。如果你想将其放回到 PandasDataFrame中，也很简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing_tr = pd.DataFrame(X, columns=housing_num.columns) <span class="comment"># 得到处理缺失值后的DF数据</span></span><br></pre></td></tr></table></figure>
<h2 id="整理数据："><a href="#整理数据：" class="headerlink" title="整理数据："></a>整理数据：</h2><h3 id="数据缩放"><a href="#数据缩放" class="headerlink" title="数据缩放"></a>数据缩放</h3><p>有两种常见的方法可以让所有的属性有相同的量度：<strong>线性函数归一化（Min-Max scaling）和标准化（standardization</strong>）。Scikit-Learn 提供了一个转换器MinMaxScaler来实现这个功能。它有一个超参数feature_range，可以让你改变范围，如果不希望范围是 0 到 1；Scikit-Learn 提供了一个转换器StandardScaler来进行标准化</p>
<p>min-max方式,对应的方法为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MinMaxScaler(self, feature_range=(<span class="number">0</span>, <span class="number">1</span>), copy=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>standardization 标准化数据,对应的方法为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">StandardScaler(self, copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>警告：与所有的转换一样，缩放器只能向训练集拟合，而不是向完整的数据集（包括测试集）。只有这样，你才能用缩放器转换训练集和测试集（和新数据）。</p>
</blockquote>
<h3 id="处理极端离群值"><a href="#处理极端离群值" class="headerlink" title="处理极端离群值"></a>处理极端离群值</h3><p>还是举加利福尼亚州住房数据集中的人均住房数的例子，有的极端值达到了50<br>对于这些极端值其实很好处理，无非几个办法</p>
<ul>
<li><strong>对数缩放</strong>  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roomsPerPerson = log((totalRooms / population) + 1)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>特征值限制到 某个上限或者下限</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roomsPerPerson = min(totalRooms / population, <span class="number">4</span>)	<span class="comment"># 大于4.0的取4.0</span></span><br></pre></td></tr></table></figure>
<h3 id="分箱"><a href="#分箱" class="headerlink" title="分箱"></a>分箱</h3><p><strong>分箱</strong>其实是一个形象化的说法，就是把数据分开来，装在一个个箱子里，这样一个箱子里的数据就是一家人了。<br>那有什么用呢？下面就举个栗子！</p>
<p><img src="/2018/07/09/Sklearn 与 TensorFlow 机器学习实用指南/Sklearn-与-TensorFlow-机器学习实用指南（一）：一个完整的程序/04.png" alt=""></p>
<p>在数据集中，<code>latitude</code> 是一个浮点值。不过，在我们的模型中将 <code>latitude</code> 表示为浮点特征没有意义。这是因为纬度和房屋价值之间不存在线性关系。例如，纬度 35 处的房屋并不比纬度 34 处的房屋贵 35/34（或更便宜）。但是，纬度或许能很好地预测房屋价值。</p>
<p>我们现在拥有 11 个不同的布尔值特征（<code>LatitudeBin1</code>、<code>LatitudeBin2</code>、…、<code>LatitudeBin11</code>），而不是一个浮点特征。拥有 11 个不同的特征有点不方便，因此我们将它们统一成一个 11 元素矢量。这样做之后，我们可以将纬度 37.4 表示为：</p>
<p>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</p>
<p>分箱之后，我们的模型现在可以为每个纬度学习完全不同的权重。（是不是觉得有点像独热编码，没错，就是的）</p>
<blockquote>
<p>为了简单起见，我们在纬度样本中使用整数作为分箱边界。如果我们需要更精细的解决方案，我们可以每隔 1/10 个纬度拆分一次分箱边界。添加更多箱可让模型从纬度 37.4 处学习和维度 37.5 处不一样的行为，但前提是每 1/10 个纬度均有充足的样本可供学习。</p>
<p>另一种方法是按<a href="https://wikipedia.org/wiki/Quantile" target="_blank" rel="noopener">分位数</a>分箱，这种方法可以确保每个桶内的样本数量是相等的。按分位数分箱完全无需担心离群值。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">分桶也称为分箱。</span></span><br><span class="line"><span class="string">例如，我们可以将 population 分为以下 3 个分桶：</span></span><br><span class="line"><span class="string">bucket_0 (&lt; 5000)：对应于人口分布较少的街区</span></span><br><span class="line"><span class="string">bucket_1 (5000 - 25000)：对应于人口分布适中的街区</span></span><br><span class="line"><span class="string">bucket_2 (&gt; 25000)：对应于人口分布较多的街区</span></span><br><span class="line"><span class="string">根据前面的分桶定义，以下 population 矢量：</span></span><br><span class="line"><span class="string">[[10001], [42004], [2500], [18000]]</span></span><br><span class="line"><span class="string">将变成以下经过分桶的特征矢量：</span></span><br><span class="line"><span class="string">[[1], [2], [0], [1]]</span></span><br><span class="line"><span class="string">这些特征值现在是分桶索引。请注意，这些索引被视为离散特征。通常情况下，这些特征将被进一步转换为上述独热表示法，但这是以透明方式实现的。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">要为分桶特征定义特征列，我们可以使用 bucketized_column（而不是使用 numeric_column），该列将数字列作为输入，并使用 boundardies 参数中指定的分桶边界将其转换为分桶特征。以下代码为 households 和 longitude 定义了分桶特征列；get_quantile_based_boundaries 函数会根据分位数计算边界，以便每个分桶包含相同数量的元素</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_quantile_based_boundaries</span><span class="params">(feature_values, num_buckets)</span>:</span></span><br><span class="line">    boundaries = np.arange(<span class="number">1.0</span>, num_buckets) / num_buckets</span><br><span class="line">    quantiles = feature_values.quantile(boundaries)</span><br><span class="line">    <span class="keyword">return</span> [quantiles[q] <span class="keyword">for</span> q <span class="keyword">in</span> quantiles.keys()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Divide households into 7 buckets.</span></span><br><span class="line">households = tf.feature_column.numeric_column(<span class="string">"households"</span>)		<span class="comment"># 定义数值特征</span></span><br><span class="line"><span class="comment"># 分桶特征bucketized_column第一个参数用数字列 numeric_column得到的households，第二个参数用上面get_quantile_based_boundaries方法得到的分桶数据，返回的bucketized_households为可使用的分桶特征</span></span><br><span class="line">bucketized_households = tf.feature_column.bucketized_column(       </span><br><span class="line">    households,boundaries=get_quantile_based_boundaries(california_housing_dataframe[<span class="string">"households"</span>], <span class="number">7</span>))</span><br></pre></td></tr></table></figure>
<h2 id="自定义转换器"><a href="#自定义转换器" class="headerlink" title="自定义转换器"></a>自定义转换器</h2><p>尽管 Scikit-Learn 提供了许多有用的转换器，你还是需要自己动手写转换器执行任务，比如自定义的清理操作，或属性组合。<strong>你需要让自制的转换器与 Scikit-Learn 组件（比如流水线）无缝衔接工作，因为 Scikit-Learn 是依赖鸭子类型的（而不是继承，忽略对象，只要行为像就行），你所需要做的是创建一个类并执行三个方法：fit()（返回self），transform()，和fit_transform()</strong>。<strong>通过添加TransformerMixin作为基类，可以很容易地得到最后一个。另外，如果你添加BaseEstimator作为基类（且构造器中避免使用args和kargs</strong>），<strong>你就能得到两个额外的方法（get_params()和set_params()），二者可以方便地进行超参数自动微调</strong>。例如，一个小转换器类添加了上面讨论的属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加一个特征组合的装换器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, household_ix = <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里的示例没有定义fit_transform()，可能是因为fit()没有做任何动作（我猜的</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CombinedAttributesAdder</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, add_bedrooms_per_room = True)</span>:</span> <span class="comment"># no *args or **kargs</span></span><br><span class="line">        self.add_bedrooms_per_room = add_bedrooms_per_room</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self  <span class="comment"># nothing else to do</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]  <span class="comment"># X[:,3]表示的是第4列所有数据</span></span><br><span class="line">        population_per_household = X[:, population_ix] / X[:, household_ix]</span><br><span class="line">        <span class="keyword">if</span> self.add_bedrooms_per_room:</span><br><span class="line">            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household, <span class="comment"># np.c_表示的是拼接数组。</span></span><br><span class="line">                         bedrooms_per_room]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household]</span><br><span class="line"></span><br><span class="line">attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=<span class="keyword">False</span>)</span><br><span class="line">housing_extra_attribs = attr_adder.transform(housing.values)    <span class="comment"># 返回一个加入新特征的数据</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，转换器有一个超参数add_bedrooms_per_room，默认设为True（提供一个合理的默认值很有帮助）。这个超参数可以让你方便地发现添加了这个属性是否对机器学习算法有帮助。更一般地，你可以为每个不能完全确保的数据准备步骤添加一个超参数。数据准备步骤越自动化，可以自动化的操作组合就越多，越容易发现更好用的组合（并能节省大量时间）。</p>
<p><strong>另外sklearn是不能直接处理DataFrames的，那么我们需要自定义一个处理的方法将之转化为numpy类型</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataFrameSelector</span><span class="params">(BaseEstimator,TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,attribute_names)</span>:</span> <span class="comment">#可以为列表</span></span><br><span class="line">        self.attribute_names = attribute_names</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self,X,y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self,X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[self.attribute_names].values <span class="comment">#返回的为numpy array</span></span><br></pre></td></tr></table></figure>
<h2 id="转换流水线"><a href="#转换流水线" class="headerlink" title="转换流水线"></a>转换流水线</h2><p>目前在数据预处理阶段，<strong>我们需要对缺失值进行处理、特征组合和特征缩放。每一步的执行都有着先后顺序，存在许多数据转换步骤，需要按一定的顺序执行。</strong>sklearn提供了Pipeline帮助顺序完成转换幸运的是，Scikit-Learn 提供了类Pipeline，来进行这一系列的转换。下面是一个数值属性的小流水线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">"median"</span>)),    <span class="comment"># 处理缺失值</span></span><br><span class="line">        (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()),    <span class="comment"># 特征组合</span></span><br><span class="line">        (<span class="string">'std_scaler'</span>, StandardScaler()),    <span class="comment"># 特征缩放</span></span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">housing_num_tr = num_pipeline.fit_transform(housing_num)</span><br></pre></td></tr></table></figure>
<p><strong>Pipeline构造器需要一个定义步骤顺序的名字/估计器对的列表。除了最后一个估计器，其余都要是转换器（即，它们都要有fit_transform()方法）</strong>。名字可以随意起。</p>
<p><strong>当你调用流水线的fit()方法，就会对所有转换器顺序调用fit_transform()方法，将每次调用的输出作为参数传递给下一个调用，一直到最后一个估计器，它只执行fit()方法。</strong></p>
<p>估计器（Estimator）：很多时候可以直接理解成分类器，主要包含两个函数：fit()和predict()<br>转换器（Transformer）：转换器用于数据预处理和数据转换，主要是三个方法：fit（）,transform()和fit_transform()</p>
<p>最后的估计器是一个StandardScaler，它是一个转换器，因此这个流水线有一个transform()方法，可以顺序对数据做所有转换（它还有一个fit_transform方法可以使用，就不必先调用fit()再进行transform()）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">num_attribs = list(housing_num) <span class="comment"># 返回的为列名[col1,col2,....]</span></span><br><span class="line">cat_attribs = [<span class="string">"ocean_proximity"</span>]</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([ <span class="comment"># 数值类型</span></span><br><span class="line">        (<span class="string">'selector'</span>, DataFrameSelector(num_attribs)),	<span class="comment"># DataFrames转为numpy array</span></span><br><span class="line">        (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">"median"</span>)),	<span class="comment"># 缺失值处理</span></span><br><span class="line">        (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()),	<span class="comment"># 特征组合</span></span><br><span class="line">        (<span class="string">'std_scaler'</span>, StandardScaler()),	<span class="comment"># 缩放</span></span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">cat_pipeline = Pipeline([ <span class="comment"># 标签类型</span></span><br><span class="line">        (<span class="string">'selector'</span>, DataFrameSelector(cat_attribs)), 	<span class="comment"># DataFrames转为numpy array</span></span><br><span class="line">        (<span class="string">'cat_encoder'</span>, CategoricalEncoder(encoding=<span class="string">"onehot-dense"</span>)),	</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<p>上面定义的为分别处理数值类型和标签类型的转换流程，housing_num为DataFrame类型，list(DataFrame)的结果返回的为列名字。上面着两个流程还可以再整合一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line">full_pipeline = FeatureUnion(transformer_list=[</span><br><span class="line">        (<span class="string">"num_pipeline"</span>, num_pipeline),</span><br><span class="line">        (<span class="string">"cat_pipeline"</span>, cat_pipeline),</span><br><span class="line">    ])</span><br><span class="line">housing_prepared = full_pipeline.fit_transform(housing) <span class="comment"># 最终的结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_prepared</span><br><span class="line">array([[ <span class="number">0.73225807</span>, <span class="number">-0.67331551</span>,  <span class="number">0.58426443</span>, ...,  <span class="number">0.</span>        ,</span><br><span class="line">         <span class="number">0.</span>        ,  <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">-0.99102923</span>,  <span class="number">1.63234656</span>, <span class="number">-0.92655887</span>, ...,  <span class="number">0.</span>        ,</span><br><span class="line">         <span class="number">0.</span>        ,  <span class="number">0.</span>        ],</span><br><span class="line">       [...]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_prepared.shape</span><br><span class="line">(<span class="number">16513</span>, <span class="number">17</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>译注:</p>
<p>如果你在上面代码中的<code>cat_pipeline</code>流水线使用<code>LabelBinarizer</code>转换器会导致执行错误，解决方案是用上文提到的<code>CategoricalEncoder</code>转换器来代替：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; cat_pipeline = Pipeline([</span><br><span class="line">&gt;         (<span class="string">'selector'</span>, DataFrameSelector(cat_attribs)),</span><br><span class="line">&gt;         (<span class="string">'cat_encoder'</span>, CategoricalEncoder(encoding=<span class="string">"onehot-dense"</span>)),</span><br><span class="line">&gt;     ])</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>&gt;</p>
<blockquote>
</blockquote>
<p><strong>每个子流水线都以一个选择转换器开始：通过选择对应的属性（数值或分类）、丢弃其它的，来转换数据，并将输出DataFrame转变成一个 NumPy 数组。Scikit-Learn 没有工具来处理 PandasDataFrame，因此我们需要写一个简单的自定义转换器来做这项工作：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataFrameSelector</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, attribute_names)</span>:</span></span><br><span class="line">        self.attribute_names = attribute_names</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[self.attribute_names].values</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>我们先来训练一个线性回归模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(housing_prepared, housing_labels)    <span class="comment"># 利用预处理好的数据进行训练模型</span></span><br></pre></td></tr></table></figure>
<p>完毕！你现在就有了一个可用的线性回归模型。用一些训练集中的实例做下验证：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_data = housing.iloc[:<span class="number">5</span>]    <span class="comment"># 前五个作为预测数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_labels = housing_labels.iloc[:<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_data_prepared = full_pipeline.transform(some_data)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"Predictions:\t"</span>, lin_reg.predict(some_data_prepared))    <span class="comment"># 预测结果</span></span><br><span class="line">Predictions:     [ <span class="number">303104.</span>   <span class="number">44800.</span>  <span class="number">308928.</span>  <span class="number">294208.</span>  <span class="number">368704.</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"Labels:\t\t"</span>, list(some_labels))</span><br><span class="line">Labels:         [<span class="number">359400.0</span>, <span class="number">69700.0</span>, <span class="number">302100.0</span>, <span class="number">301300.0</span>, <span class="number">351900.0</span>]    <span class="comment"># 实际结果</span></span><br></pre></td></tr></table></figure>
<p>行的通，尽管预测并不怎么准确（比如，第二个预测偏离了 50%！）。让我们使用 Scikit-Learn 的mean_squared_error函数，用全部训练集来计算下这个回归模型的 RMSE：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_predictions = lin_reg.predict(housing_prepared)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse = np.sqrt(lin_mse)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse</span><br><span class="line"><span class="number">68628.413493824875</span></span><br></pre></td></tr></table></figure>
<p>OK，有总比没有强，但显然结果并不好，这是一个模型欠拟合训练数据的例子。当这种情况发生时，意味着特征没有提供足够多的信息来做出一个好的预测，或者模型并不强大，修复欠拟合的主要方法是选择一个更强大的模型，给训练算法提供更好的特征，或去掉模型上的限制，你可以尝试添加更多特征（比如，人口的对数值），但是首先让我们尝试一个更为复杂的模型，看看效果。训练一个决策树模型DecisionTreeRegressor。这是一个强大的模型，可以发现数据中复杂的非线性关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg = DecisionTreeRegressor()</span><br><span class="line">tree_reg.fit(housing_prepared, housing_labels)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_predictions = tree_reg.predict(housing_prepared)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_rmse = np.sqrt(tree_mse)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_rmse</span><br><span class="line"><span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>等一下，发生了什么？没有误差？这个模型可能是绝对完美的吗？当然，更大可能性是这个模型严重过拟合数据。如何确定呢？如前所述，直到你准备运行一个具备足够信心的模型，都不要碰测试集，因此你需要使用训练集的部分数据来做训练，用一部分来做模型验证。</p>
<h2 id="用交叉验证做更佳的评估"><a href="#用交叉验证做更佳的评估" class="headerlink" title="用交叉验证做更佳的评估"></a>用交叉验证做更佳的评估</h2><p>使用 Scikit-Learn 的交叉验证功能。下面的代码采用了 <strong>K 折交叉验证（K-fold cross-validation）：它随机地将训练集分成十个不同的子集，成为“折”，然后训练评估决策树模型 10 次，每次选一个不用的折来做评估，用其它 9 个来做训练。结果是一个包含 10 个评分的数组：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">scores = cross_val_score(tree_reg, housing_prepared, housing_labels,</span><br><span class="line">                         scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">rmse_scores = np.sqrt(-scores)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>警告：Scikit-Learn 交叉验证功能期望的是效用函数（越大越好）而不是损失函数（越低越好），因此得分函数实际上与 MSE 相反（即负值），这就是为什么前面的代码在计算平方根之前先计算-scores。</p>
</blockquote>
<p>来看下结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">display_scores</span><span class="params">(scores)</span>:</span></span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Scores:"</span>, scores)</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Mean:"</span>, scores.mean())</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Standard deviation:"</span>, scores.std())</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(tree_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">74678.4916885</span>   <span class="number">64766.2398337</span>   <span class="number">69632.86942005</span>  <span class="number">69166.67693232</span></span><br><span class="line">          <span class="number">71486.76507766</span>  <span class="number">73321.65695983</span>  <span class="number">71860.04741226</span>  <span class="number">71086.32691692</span></span><br><span class="line">          <span class="number">76934.2726093</span>   <span class="number">69060.93319262</span>]</span><br><span class="line">Mean: <span class="number">71199.4280043</span></span><br><span class="line">Standard deviation: <span class="number">3202.70522793</span></span><br></pre></td></tr></table></figure>
<p>现在决策树就不像前面看起来那么好了。实际上，它看起来比线性回归模型还糟！注意到交叉验证不仅可以让你得到模型性能的评估，还能测量评估的准确性（即，它的标准差）。决策树的评分大约是 71200，通常波动有 ±3200。如果只有一个验证集，就得不到这些信息。但是交叉验证的代价是训练了模型多次，不可能总是这样。</p>
<p>让我们计算下线性回归模型的的相同分数，以做确保：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,</span><br><span class="line"><span class="meta">... </span>                             scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse_scores = np.sqrt(-lin_scores)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(lin_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">70423.5893262</span>   <span class="number">65804.84913139</span>  <span class="number">66620.84314068</span>  <span class="number">72510.11362141</span></span><br><span class="line">          <span class="number">66414.74423281</span>  <span class="number">71958.89083606</span>  <span class="number">67624.90198297</span>  <span class="number">67825.36117664</span></span><br><span class="line">          <span class="number">72512.36533141</span>  <span class="number">68028.11688067</span>]</span><br><span class="line">Mean: <span class="number">68972.377566</span></span><br><span class="line">Standard deviation: <span class="number">2493.98819069</span></span><br></pre></td></tr></table></figure>
<p>判断没错：决策树模型过拟合很严重，它的性能比线性回归模型还差</p>
<p>现在再尝试最后一个模型：RandomForestRegressor（随机森林），随机森林是通过用特征的随机子集训练许多决策树。在其它多个模型之上建立模型成为集成学习（Ensemble Learning），它是推进 ML 算法的一种好方法。我们会跳过大部分的代码，因为代码本质上和其它模型一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_reg = RandomForestRegressor()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_reg.fit(housing_prepared, housing_labels)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[...]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_rmse</span><br><span class="line"><span class="number">22542.396440343684</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(forest_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">53789.2879722</span>   <span class="number">50256.19806622</span>  <span class="number">52521.55342602</span>  <span class="number">53237.44937943</span></span><br><span class="line">          <span class="number">52428.82176158</span>  <span class="number">55854.61222549</span>  <span class="number">52158.02291609</span>  <span class="number">50093.66125649</span></span><br><span class="line">          <span class="number">53240.80406125</span>  <span class="number">52761.50852822</span>]</span><br><span class="line">Mean: <span class="number">52634.1919593</span></span><br><span class="line">Standard deviation: <span class="number">1576.20472269</span></span><br></pre></td></tr></table></figure>
<p>现在好多了：随机森林看起来很有希望。但是，训练集的评分仍然比验证集的评分低很多。解决过拟合可以通过简化模型，给模型加限制（即，正则化），或用更多的训练数据。在深入随机森林之前，你应该尝试下机器学习算法的其它类型模型（不同核心的支持向量机，神经网络，等等），不要在调节超参数上花费太多时间。目标是列出一个可能模型的列表（两到五个）。</p>
<blockquote>
<p>提示：你要保存每个试验过的模型，以便后续可以再用。要确保有超参数和训练参数，以及交叉验证评分，和实际的预测值。这可以让你比较不同类型模型的评分，还可以比较误差种类。你可以用 Python 的模块pickle，非常方便地保存 Scikit-Learn 模型，或使用sklearn.externals.joblib，后者序列化大 NumPy 数组更有效率：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line">joblib.dump(my_model, <span class="string">"my_model.pkl"</span>)</span><br><span class="line"><span class="comment"># 然后</span></span><br><span class="line">my_model_loaded = joblib.load(<span class="string">"my_model.pkl"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型微调"><a href="#模型微调" class="headerlink" title="模型微调"></a>模型微调</h2><p><strong>网格搜索</strong>：使用 Scikit-Learn 的GridSearchCV来做这项搜索工作。<strong>你所需要做的是告诉GridSearchCV要试验有哪些超参数，要试验什么值，GridSearchCV就能用交叉验证试验所有可能超参数值的组合</strong>。例如，下面的代码搜索了RandomForestRegressor超参数值的最佳组合（很费时间）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = [</span><br><span class="line">    &#123;<span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>, <span class="number">30</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;,</span><br><span class="line">    &#123;<span class="string">'bootstrap'</span>: [<span class="keyword">False</span>], <span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;,</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">forest_reg = RandomForestRegressor()</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(forest_reg, param_grid, cv=<span class="number">5</span>,</span><br><span class="line">                           scoring=<span class="string">'neg_mean_squared_error'</span>)</span><br><span class="line"></span><br><span class="line">grid_search.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当你不能确定超参数该有什么值，一个简单的方法是尝试连续的 10 的幂（如果想要一个粒度更小的搜寻，可以用更小的数，就像在这个例子中对超参数n_estimators做的）。</p>
</blockquote>
<p>param_grid告诉 Scikit-Learn 首先评估所有的列在第一个dict中的n_estimators和max_features的3 × 4 = 12种组合（不用担心这些超参数的含义，会在第 7 章中解释）。然后尝试第二个dict中超参数的2 × 3 = 6种组合，这次会将超参数bootstrap设为False而不是True（后者是该超参数的默认值）。完成后，你就能获得参数的最佳组合，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid_search.best_params_</span><br><span class="line">&#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br></pre></td></tr></table></figure>
<p>你还能直接得到最佳的估计器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid_search.best_estimator_</span><br><span class="line">RandomForestRegressor(bootstrap=<span class="keyword">True</span>, criterion=<span class="string">'mse'</span>, max_depth=<span class="keyword">None</span>,</span><br><span class="line">           max_features=<span class="number">6</span>, max_leaf_nodes=<span class="keyword">None</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">           min_samples_split=<span class="number">2</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">           n_estimators=<span class="number">30</span>, n_jobs=<span class="number">1</span>, oob_score=<span class="keyword">False</span>, random_state=<span class="keyword">None</span>,</span><br><span class="line">           verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>当然，也可以得到评估得分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cvres = grid_search.cv_results_</span><br><span class="line"><span class="meta">... </span><span class="keyword">for</span> mean_score, params <span class="keyword">in</span> zip(cvres[<span class="string">"mean_test_score"</span>], cvres[<span class="string">"params"</span>]):</span><br><span class="line"><span class="meta">... </span>    print(np.sqrt(-mean_score), params)</span><br><span class="line">...</span><br><span class="line"><span class="number">64912.0351358</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">55535.2786524</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">52940.2696165</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">60384.0908354</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52709.9199934</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">50503.5985321</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">59058.1153485</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52172.0292957</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">49958.9555932</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">59122.260006</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52441.5896087</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">50041.4899416</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">62371.1221202</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">54572.2557534</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">59634.0533132</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">3</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52456.0883904</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">3</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">58825.665239</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52012.9945396</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们通过设定超参数max_features为 6，n_estimators为 30，得到了最佳方案。对这个组合，RMSE 的值是 49959，这比之前使用默认的超参数的值（52634）要稍微好一些。祝贺你，你成功地微调了最佳模型！</p>
<p><strong>随机搜索：</strong>当探索相对较少的组合时，就像前面的例子，网格搜索还可以。但是当超参数的搜索空间很大时，最好使用RandomizedSearchCV。这个类的使用方法和类GridSearchCV很相似，但它不是尝试所有可能的组合，而是通过选择每个超参数的一个随机值的特定数量的随机组合。这个方法有两个优点：</p>
<ul>
<li>如果你让随机搜索运行，比如 1000 次，它会探索每个超参数的 1000 个不同的值（而不是像网格搜索那样，只搜索每个超参数的几个值）</li>
<li>你可以方便地通过设定搜索次数，控制超参数搜索的计算量。</li>
</ul>
<h2 id="分析最佳模型和它们的误差"><a href="#分析最佳模型和它们的误差" class="headerlink" title="分析最佳模型和它们的误差"></a>分析最佳模型和它们的误差</h2><p>通过<strong>分析最佳模型</strong>，常常可以获得对问题更深的了解。比如，RandomForestRegressor可以指出<strong>每个属性对于做出准确预测的相对重要性</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; feature_importances = grid_search.best_estimator_.feature_importances_</span><br><span class="line">&gt;&gt;&gt; feature_importances</span><br><span class="line">array([  7.14156423e-02,   6.76139189e-02,   4.44260894e-02,</span><br><span class="line">         1.66308583e-02,   1.66076861e-02,   1.82402545e-02,</span><br><span class="line">         1.63458761e-02,   3.26497987e-01,   6.04365775e-02,</span><br><span class="line">         1.13055290e-01,   7.79324766e-02,   1.12166442e-02,</span><br><span class="line">         1.53344918e-01,   8.41308969e-05,   2.68483884e-03,</span><br><span class="line">         3.46681181e-03])</span><br></pre></td></tr></table></figure>
<p>将重要性分数和属性名放到一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>extra_attribs = [<span class="string">"rooms_per_hhold"</span>, <span class="string">"pop_per_hhold"</span>, <span class="string">"bedrooms_per_room"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat_one_hot_attribs = list(encoder.classes_)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>attributes = num_attribs + extra_attribs + cat_one_hot_attribs</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sorted(zip(feature_importances,attributes), reverse=<span class="keyword">True</span>)</span><br><span class="line">[(<span class="number">0.32649798665134971</span>, <span class="string">'median_income'</span>),</span><br><span class="line"> (<span class="number">0.15334491760305854</span>, <span class="string">'INLAND'</span>),</span><br><span class="line"> (<span class="number">0.11305529021187399</span>, <span class="string">'pop_per_hhold'</span>),</span><br><span class="line"> (<span class="number">0.07793247662544775</span>, <span class="string">'bedrooms_per_room'</span>),</span><br><span class="line"> (<span class="number">0.071415642259275158</span>, <span class="string">'longitude'</span>),</span><br><span class="line"> (<span class="number">0.067613918945568688</span>, <span class="string">'latitude'</span>),</span><br><span class="line"> (<span class="number">0.060436577499703222</span>, <span class="string">'rooms_per_hhold'</span>),</span><br><span class="line"> (<span class="number">0.04442608939578685</span>, <span class="string">'housing_median_age'</span>),</span><br><span class="line"> (<span class="number">0.018240254462909437</span>, <span class="string">'population'</span>),</span><br><span class="line"> (<span class="number">0.01663085833886218</span>, <span class="string">'total_rooms'</span>),</span><br><span class="line"> (<span class="number">0.016607686091288865</span>, <span class="string">'total_bedrooms'</span>),</span><br><span class="line"> (<span class="number">0.016345876147580776</span>, <span class="string">'households'</span>),</span><br><span class="line"> (<span class="number">0.011216644219017424</span>, <span class="string">'&lt;1H OCEAN'</span>),</span><br><span class="line"> (<span class="number">0.0034668118081117387</span>, <span class="string">'NEAR OCEAN'</span>),</span><br><span class="line"> (<span class="number">0.0026848388432755429</span>, <span class="string">'NEAR BAY'</span>),</span><br><span class="line"> (<span class="number">8.4130896890070617e-05</span>, <span class="string">'ISLAND'</span>)]</span><br></pre></td></tr></table></figure>
<p>有了这个信息，你就可以丢弃一些不那么重要的特征（比如，显然只要一个分类ocean_proximity就够了，所以可以丢弃掉其它的）。你还应该看一下系统犯的误差，搞清为什么会有些误差，以及如何改正问题（添加更多的特征，或相反，去掉没有什么信息的特征，清洗异常值等等）。</p>
<h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><p>调节完系统之后，你终于有了一个性能足够好的系统。现在就可以用测试集评估最后的模型了。这个过程没有什么特殊的：从测试集得到预测值和标签，运行full_pipeline转换数据（调用transform()，而不是fit_transform()！），再用测试集评估最终模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">final_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line">X_test = strat_test_set.drop(<span class="string">"median_house_value"</span>, axis=<span class="number">1</span>)</span><br><span class="line">y_test = strat_test_set[<span class="string">"median_house_value"</span>].copy()</span><br><span class="line"></span><br><span class="line">X_test_prepared = full_pipeline.transform(X_test)</span><br><span class="line"></span><br><span class="line">final_predictions = final_model.predict(X_test_prepared)</span><br><span class="line"></span><br><span class="line">final_mse = mean_squared_error(y_test, final_predictions)</span><br><span class="line">final_rmse = np.sqrt(final_mse)   <span class="comment"># =&gt; evaluates to 48,209.6</span></span><br></pre></td></tr></table></figure>
<p>评估结果通常要比交叉验证的效果差一点，如果你之前做过很多超参数微调（因为你的系统在验证集上微调，得到了不错的性能，通常不会在未知的数据集上有同样好的效果）。这个例子不属于这种情况，但是当发生这种情况时，你一定要忍住不要调节超参数，使测试集的效果变好；这样的提升不能推广到新数据上。</p>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/04/python编程进阶/python编程进阶（13）：兼容、缓存、上下文/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/04/python编程进阶/python编程进阶（13）：兼容、缓存、上下文/" itemprop="url">python编程进阶（13）：兼容、缓存、上下文</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-04T09:14:32+08:00">
                2018-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,523
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="兼容Python2-和Python3"><a href="#兼容Python2-和Python3" class="headerlink" title="兼容Python2+和Python3+"></a>兼容Python2+和Python3+</h1><p>很多时候你可能希望你开发的程序能够同时兼容Python2+和Python3+。</p>
<p>试想你有一个非常出名的Python模块被很多开发者使用着，但并不是所有人都只使用Python2或者Python3。这时候你有两个办法。第一个办法是开发两个模块，针对Python2一个，针对Python3一个。还有一个办法就是调整你现在的代码使其同时兼容Python2和Python3。</p>
<p>本节中，我将介绍一些技巧，让你的脚本同时兼容Python2和Python3。</p>
<h2 id="Future模块导入"><a href="#Future模块导入" class="headerlink" title="Future模块导入"></a>Future模块导入</h2><p><strong>第一种也是最重要的方法，就是导入<code>__future__</code>模块。它可以帮你在Python2中导入Python3的功能</strong>。这有一组例子：</p>
<p>上下文管理器是Python2.6+引入的新特性，如果你想在Python2.5中使用它可以这样做：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> with_statement</span><br></pre></td></tr></table></figure>
<p>在Python3中<code>print</code>已经变为一个函数。如果你想在Python2中使用它可以通过<code>__future__</code>导入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line">print(<span class="keyword">print</span>)</span><br><span class="line"><span class="comment"># Output: &lt;built-in function print&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="模块重命名"><a href="#模块重命名" class="headerlink" title="模块重命名"></a>模块重命名</h2><p>首先，告诉我你是如何在你的脚本中导入模块的。大多时候我们会这样做：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> foo </span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="keyword">from</span> foo <span class="keyword">import</span> bar</span><br></pre></td></tr></table></figure>
<p>你知道么，其实你也可以这样做：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> foo <span class="keyword">as</span> foo</span><br></pre></td></tr></table></figure>
<p>这样做可以起到和上面代码同样的功能，但最重要的是它能让你的脚本同时兼容Python2和Python3。现在我们来看下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> urllib.request <span class="keyword">as</span> urllib_request  <span class="comment"># for Python 3</span></span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">import</span> urllib2 <span class="keyword">as</span> urllib_request  <span class="comment"># for Python 2</span></span><br></pre></td></tr></table></figure>
<h2 id="过期的Python2内置功能"><a href="#过期的Python2内置功能" class="headerlink" title="过期的Python2内置功能"></a>过期的Python2内置功能</h2><p>另一个需要了解的事情就是Python2中有12个内置功能在Python3中已经被移除了。要确保在Python2代码中不要出现这些功能来保证对Python3的兼容。这有一个强制让你放弃12内置功能的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> future.builtins.disabled <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<p>现在，只要你尝试在Python3中使用这些被遗弃的模块时，就会抛出一个<code>NameError</code>异常如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> future.builtins.disabled <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">apply()</span><br><span class="line"><span class="comment"># Output: NameError: obsolete Python 2 builtin apply is disabled</span></span><br></pre></td></tr></table></figure>
<p><strong>标准库向下兼容的外部支持</strong></p>
<p>有一些包在非官方的支持下为Python2提供了Python3的功能。例如，我们有：</p>
<ul>
<li>enum <code>pip install enum34</code></li>
<li>singledispatch <code>pip install singledispatch</code></li>
<li>pathlib <code>pip install pathlib</code></li>
</ul>
<p>想更多了解，在Python文档中有一个<a href="https://docs.python.org/3/howto/pyporting.html" target="_blank" rel="noopener">全面的指南</a>可以帮助你让你的代码同时兼容Python2和Python3。</p>
<h1 id="函数缓存-Function-caching"><a href="#函数缓存-Function-caching" class="headerlink" title="函数缓存 (Function caching)"></a>函数缓存 (Function caching)</h1><p><strong>函数缓存允许我们将一个函数对于给定参数的返回值缓存起来</strong>。当一个I/O密集的函数被频繁<strong>使用相同的参数调用的时候，函数缓存可以节约时间</strong>。在Python 3.2版本以前我们只有写一个自定义的实现。<strong>在Python 3.2以后版本，有个<code>lru_cache</code>的装饰器，允许我们将一个函数的返回值快速地缓存或取消缓存</strong>。</p>
<h2 id="Python-3-2及以后版本"><a href="#Python-3-2及以后版本" class="headerlink" title="Python 3.2及以后版本"></a>Python 3.2及以后版本</h2><p>我们来实现一个斐波那契计算器，并使用<code>lru_cache</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> lru_cache</span><br><span class="line"></span><br><span class="line"><span class="meta">@lru_cache(maxsize=32)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> n</span><br><span class="line">    <span class="keyword">return</span> fib(n<span class="number">-1</span>) + fib(n<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([fib(n) <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br><span class="line"><span class="comment"># Output: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]</span></span><br></pre></td></tr></table></figure>
<p>那个<code>maxsize</code>参数是告诉<code>lru_cache</code>，最多缓存最近多少个返回值。</p>
<p>我们也可以轻松地对返回值清空缓存，通过这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fib.cache_clear()</span><br></pre></td></tr></table></figure>
<h1 id="上下文管理器-Context-managers"><a href="#上下文管理器-Context-managers" class="headerlink" title="上下文管理器(Context managers)"></a>上下文管理器(Context managers)</h1><p>上下文管理器允许你在有需要的时候，精确地分配和释放资源。<strong>上下文管理器的常用于一些资源的操作，需要在资源的正确获取与释放相关的操作</strong> ，先看一个例子,我们经常会用到 try … catch … finally 语句确保一些系统资源得以正确释放。如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    f = open(<span class="string">'somefile'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        print(line)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(e)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
<p>我们经常用到上面的代码模式，用复用代码的模式来讲，并不够好。于是 with 语句出现了，通过定义一个上下文管理器来封装这个代码块:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'somefile'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        print(line)</span><br></pre></td></tr></table></figure>
<p><strong>使用上下文管理器最广泛的案例就是<code>with</code>语句了</strong>。想象下你有两个需要结对执行的相关操作，然后还要在它们中间放置一段代码。 <strong>上下文管理器就是专门让你做这种事情的。上面这段代码打开了一个文件，往里面写入了一些数据，然后关闭该文件。如果在往文件写数据时发生异常，它也会尝试去关闭文件</strong>。这就是<code>with</code>语句的主要优势，它确保我们的文件会被关闭，而不用关注嵌套代码如何退出。</p>
<p>上下文管理器的一个常见用例，是资源的加锁和解锁，以及关闭已打开的文件（就像我已经展示给你看的）。</p>
<p>实际上，我们可以同时处理多个上下文管理器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> A() <span class="keyword">as</span> a, B() <span class="keyword">as</span> b:</span><br><span class="line">    suite</span><br></pre></td></tr></table></figure>
<h2 id="上下文管理协议"><a href="#上下文管理协议" class="headerlink" title="上下文管理协议"></a>上下文管理协议</h2><p>与迭代器类似，实现了迭代协议的函数/对象即为迭代器。实现了上下文协议的函数/对象即为上下文管理器。迭代器协议是实现了<code>__iter__</code>方法。上下文管理协议则是一个类实现<code>__enter__</code> (self)和<code>__exit__</code>(self, exc_type, exc_valye, traceback)方法就可以了。实行如下结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Contextor</span>:</span></span><br><span class="line">    <span class="comment"># __enter__返回一个对象，通常是当前类的实例，也可以是其他对象。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_val, exc_tb)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">contextor = Contextor()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> contextor [<span class="keyword">as</span> var]:</span><br><span class="line">    with_body</span><br></pre></td></tr></table></figure>
<p><strong><code>Contextor</code> 实现了<code>__enter__</code>和<code>__exit__</code>这两个上下文管理器协议，当Contextor调用/实例化的时候，则创建了上下文管理器<code>contextor</code></strong></p>
<p>通过定义<code>__enter__</code>和<code>__exit__</code>方法的类（包括自己定义的类，只要加上特定的两个方法即可），我们<strong>可以在<code>with</code>语句里使用它</strong>。我们来看看在底层都发生了什么。</p>
<p><strong>执行步骤：</strong></p>
<ol>
<li>执行 contextor (实例化具有上下文协议的对象，这里也称为上下文表达式)以获取上下文管理器，上下文表达式就是 with 和 as 之间的代码。</li>
<li>加载上下文管理器对象的 <strong>exit</strong>()方法，备用。</li>
<li>调用上下文管理器的 <strong>enter</strong>() 方法</li>
<li>如果有 as var 从句，则将 <strong>enter</strong>() 方法的返回值赋给 var</li>
<li>执行子代码块 with_body</li>
<li>with语句调用上下文管理器之前暂存的 <strong>exit</strong>() 方法，如果 with_body 的退出是由异常引发的，那么该异常的 type、value 和 traceback 会作为参数传给 <strong>exit</strong>()，否则传三个 None。然后，<strong>exit</strong>()需要明确地返回 True 或 False。当返回 True 时，异常不会被向上抛出，当返回 False 时曾会向上抛出。</li>
<li>如果 with_body 的退出由异常引发，它让<strong>exit()</strong>方法来处理异常，并且 <strong>exit</strong>() 的返回值等于 False，那么这个异常将被with语句重新引发抛出一次；如果 <strong>exit</strong>() 的返回值等于 True，那么这个异常就被无视掉，继续执行后面的代码。</li>
</ol>
<h2 id="上下文管理器工具"><a href="#上下文管理器工具" class="headerlink" title="上下文管理器工具"></a>上下文管理器工具</h2><p>通过实现上下文协议定义创建上下文管理器很方便，Python为了更优雅，还专门提供了一个模块用于实现更函数式的上下文管理器用法。Python的<code>contextlib</code>模块专门用于这个目的。</p>
<p><strong>AbstractContextManager</strong> ： 此类在 Python3.6中新增，提供了默认的<strong>enter</strong>()和<strong>exit</strong>()实现。<strong>enter</strong>()返回自身，<strong>exit</strong>()返回 None。</p>
<p><strong>contextmanager： </strong>我们要实现上下文管理器，总是要写一个类。此函数则容许我们<strong>通过一个装饰一个生成器函数</strong>得到一个上下文管理器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> contextlib</span><br><span class="line"></span><br><span class="line"><span class="meta">@contextlib.contextmanager</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">database</span><span class="params">()</span>:</span></span><br><span class="line">    db = Database()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> db.connected:</span><br><span class="line">            db.connect()</span><br><span class="line">        <span class="keyword">yield</span> db	<span class="comment"># 生成器</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        db.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_query</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> database() <span class="keyword">as</span> db:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'handle ---'</span>, db.query()</span><br></pre></td></tr></table></figure>
<p>使用contextlib 定义一个上下文管理器函数，通过with语句，database调用生成一个上下文管理器，然后调用函数隐式的<code>__enter__</code>方法，并将结果通yield返回。最后退出上下文环境的时候，在exception代码块中执行了<code>__exit__</code>方法。当然我们可以手动模拟上述代码的执行的细节。注意：yield 只能返回一次，返回的对象 被绑定到 as 后的变量，不需要返回时可以直接 yield，不带返回值。退出时则从 yield 之后执行。由于contextmanager继承自ContextDecorator，所以被contextmanager装饰过的生成器也可以用作装饰器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: context = database()    <span class="comment"># 创建上下文管理器</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: context</span><br><span class="line">&lt;contextlib.GeneratorContextManager object at <span class="number">0x107188f10</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: db = context.__enter__() <span class="comment"># 进入with语句</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: db                          <span class="comment"># as语句，返回 Database实例</span></span><br><span class="line">Out[<span class="number">4</span>]: &lt;__main__.Database at <span class="number">0x107188a10</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: db.query()       </span><br><span class="line">Out[<span class="number">5</span>]: <span class="string">'query data'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: db.connected</span><br><span class="line">Out[<span class="number">6</span>]: <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: db.__exit__(<span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>)    <span class="comment"># 退出with语句</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: db</span><br><span class="line">Out[<span class="number">8</span>]: &lt;__main__.Database at <span class="number">0x107188a10</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: db.connected</span><br><span class="line">Out[<span class="number">9</span>]: <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p><strong>ContextDecorator</strong>：  我们可以实现一个上下文管理器，同时可以用作装饰器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AContext</span><span class="params">(ContextDecorator)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'Starting'</span>)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_value, traceback)</span>:</span></span><br><span class="line">        print(<span class="string">'Finishing'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 with 中使用</span></span><br><span class="line"><span class="keyword">with</span> AContext():</span><br><span class="line">    print(<span class="string">'祖国伟大'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用作装饰器</span></span><br><span class="line"><span class="meta">@AContext()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_sth</span><span class="params">(sth)</span>:</span></span><br><span class="line">    print(sth)</span><br><span class="line"></span><br><span class="line">print_sth(<span class="string">'祖国伟大'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在这两种写法中，有没有发现，第二种写法更好，因为我们减少了一次代码缩进，可读性更强</span></span><br></pre></td></tr></table></figure>
<p><strong>还有一种好处：当我们已经实现了某个上下文管理器时，只要增加一个继承类，该上下文管理器立刻编程装饰器。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> ContextDecorator</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mycontext</span><span class="params">(ContextBaseClass, ContextDecorator)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, *exc)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/03/python编程进阶/python编程进阶（12）：协程与异步IO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/03/python编程进阶/python编程进阶（12）：协程与异步IO/" itemprop="url">python编程进阶（12）：协程与异步IO</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-03T15:14:32+08:00">
                2018-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,483
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h1><p>子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。</p>
<p>子程序调用总是一个入口，一次返回，调用顺序是明确的。<strong>而协程的调用和子程序不同。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行</strong>。</p>
<p><strong>注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断</strong>。比如子程序A、B：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">A</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'1'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'2'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'3'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">B</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'x'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'y'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'z'</span></span><br></pre></td></tr></table></figure>
<p>假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line">x</span><br><span class="line">y</span><br><span class="line"><span class="number">3</span></span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<h2 id="多线程比，协程有何优势？"><a href="#多线程比，协程有何优势？" class="headerlink" title="多线程比，协程有何优势？"></a>多线程比，协程有何优势？</h2><p><strong>最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销</strong>，和多线程比，线程数量越多，协程的性能优势就越明显。</p>
<p><strong>第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突</strong>，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</p>
<p><strong>因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程</strong>，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。Python对协程的支持是通过generator实现的。</p>
<h2 id="一个例子：生产者－消费者的协程"><a href="#一个例子：生产者－消费者的协程" class="headerlink" title="一个例子：生产者－消费者的协程"></a>一个例子：生产者－消费者的协程</h2><p><strong>现在我们要让生产者发送1,2,3,4,5给消费者，消费者接受数字，返回状态给生产者，而我们的消费者只需要3,4,5就行了，当数字等于3时，会返回一个错误的状态。最终我们需要由主程序来监控生产者－消费者的过程状态，调度结束程序。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">()</span>:</span></span><br><span class="line">    status = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        n = <span class="keyword">yield</span> status</span><br><span class="line">        print(<span class="string">"我拿到了&#123;&#125;!"</span>.format(n))</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">3</span>:</span><br><span class="line">            status = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">producer</span><span class="params">(consumer)</span>:</span></span><br><span class="line">    n = <span class="number">5</span></span><br><span class="line">    <span class="keyword">while</span> n &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># yield给主程序返回消费者的状态</span></span><br><span class="line">        <span class="comment"># consumer.send(n)把n传值给c生成器，同时返回c生成器yield的结果（相当于fetch取一个放一个东西）</span></span><br><span class="line">        <span class="keyword">yield</span> consumer.send(n)	</span><br><span class="line">        n -= <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    c = consumer()	<span class="comment"># c产生一个生成器(带yield语句)</span></span><br><span class="line">    c.send(<span class="keyword">None</span>)	<span class="comment"># consumer()程序推进到yield，但yield还未被执行.send()是传值给生成器的语句</span></span><br><span class="line">    p = producer(c)	<span class="comment"># p也产生一个生成器，但传入c生成器，与p进行通信</span></span><br><span class="line">    <span class="keyword">for</span> status <span class="keyword">in</span> p:<span class="comment"># 循环获取p生成器yield回来的状态</span></span><br><span class="line">        <span class="keyword">if</span> status == <span class="keyword">False</span>:</span><br><span class="line">            print(<span class="string">"我只要3,4,5就行啦"</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">"程序结束"</span>)</span><br></pre></td></tr></table></figure>
<p>上面这个例子是典型的生产者－消费者问题，我们用协程的方式来实现它。</p>
<p>第一句<code>c = consumer()</code>，因为consumer函数中存在yield语句，python会把它当成一个generator，因此在运行这条语句后，python并不会像执行函数一样，而是返回了一个generator object。</p>
<p>第二条语句<code>c.send(None)</code>，这条语句的作用是将consumer（即变量c，它是一个generator）中的语句推进到第一个yield语句出现的位置，那么在例子中，consumer中的<code>status = True</code>和<code>while True:</code>都已经被执行了，程序停留在<code>n = yield status</code>的位置（注意：此时这条语句还没有被执行），上面说的send(None)语句十分重要，如果漏写这一句，那么程序直接报错</p>
<p>第三句<code>p = producer(c)</code>，这里则像上面一样定义了producer的生成器，注意的是这里我们传入了消费者的生成器，来让producer跟consumer通信。</p>
<p>第四句<code>for status in p:</code>，这条语句会循环地运行producer和获取它yield回来的状态。</p>
<p>现在程序流进入了producer里面，我们直接看<code>yield consumer.send(n)</code>，生产者调用了消费者的<strong>send()方法，把n发送给consumer</strong>（即c），在consumer中的<code>n = yield status</code>，n拿到的是消费者发送的数字，同时，consumer用yield的方式把状态（status）返回给消费者，注意：这时producer（即消费者）的<code>consumer.send()</code>调用返回的就是consumer中yield的status！消费者马上将status返回给调度它的主程序，主程序获取状态，判断是否错误，若错误，则终止循环，结束程序。上面看起来有点绕，<strong>其实这里面<code>generator.send(n)</code>的作用是：把n发送generator(生成器)中yield的赋值语句中，同时返回generator中yield的变量（结果）。</strong></p>
<p>于是程序便一直运作，直至consumer中获取的n的值变为3！此时consumer把status变为False，最后返回到主程序，主程序中断循环，程序结束。</p>
<h2 id="Coroutine与Generator"><a href="#Coroutine与Generator" class="headerlink" title="Coroutine与Generator"></a>Coroutine与Generator</h2><p>有些人会把生成器（generator）和协程（coroutine）的概念混淆，我以前也会这样，不过其实发现，两者的区别还是很大的。</p>
<p>直接上最重要的区别：</p>
<ul>
<li>generator总是生成值，一般是迭代的序列</li>
<li>coroutine关注的是消耗值，是数据(data)的消费者</li>
<li>coroutine不会与迭代操作关联，而generator会</li>
<li>coroutine强调协同控制程序流，generator强调保存状态和产生数据</li>
</ul>
<p>相似的是，它们都是不用return来实现重复调用的函数/对象，都用到了yield(中断/恢复)的方式来实现</p>
<h1 id="asyncio"><a href="#asyncio" class="headerlink" title="asyncio"></a>asyncio</h1><p><code>asyncio</code>是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。</p>
<p><code>asyncio</code>的编程模型就是一个消息循环。<strong>我们从<code>asyncio</code>模块中直接获取一个<code>EventLoop</code>的引用，然后把需要执行的协程扔到<code>EventLoop</code>中执行，就实现了异步IO</strong>。用<code>asyncio</code>实现<code>Hello world</code>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="comment">#@asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。</span></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Hello world!"</span>)</span><br><span class="line">    <span class="comment"># 异步调用asyncio.sleep(1):</span></span><br><span class="line">    r = <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"Hello again!"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取EventLoop:</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line"><span class="comment"># 执行coroutine</span></span><br><span class="line">loop.run_until_complete(hello())	<span class="comment"># 循环执行EventLoop里要完成的事件</span></span><br><span class="line">loop.close()</span><br></pre></td></tr></table></figure>
<p><code>hello()</code>会首先打印出<code>Hello world!</code>，然后，<strong><code>yield from</code>语法可以让我们方便地调用另一个<code>generator</code></strong>。由于<strong><code>asyncio.sleep()</code>也是一个<code>coroutine</code></strong>，<strong>所以线程不会等待<code>asyncio.sleep()</code>，而是直接中断并执行下一个消息循环</strong>。当<code>asyncio.sleep()</code>返回时，线程就可以从<code>yield from</code>拿到返回值（此处是<code>None</code>），然后接着执行下一行语句。<strong>把<code>asyncio.sleep(1)</code>看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行<code>EventLoop</code>中其他可以执行的<code>coroutine</code>了，因此可以实现并发执行</strong>。</p>
<p>我们用Task封装两个<code>coroutine</code>试试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'Hello world! (%s)'</span> % threading.currentThread())</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">'Hello again! (%s)'</span> % threading.currentThread())</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">tasks = [hello(), hello()]</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line">loop.close()</span><br></pre></td></tr></table></figure>
<p>观察执行过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hello world! (&lt;_MainThread(MainThread, started <span class="number">140735195337472</span>)&gt;)</span><br><span class="line">Hello world! (&lt;_MainThread(MainThread, started <span class="number">140735195337472</span>)&gt;)	<span class="comment"># asyncio.sleep(1)会挂起并去执行下一个hello()协程</span></span><br><span class="line">(暂停约<span class="number">1</span>秒)</span><br><span class="line">Hello again! (&lt;_MainThread(MainThread, started <span class="number">140735195337472</span>)&gt;)</span><br><span class="line">Hello again! (&lt;_MainThread(MainThread, started <span class="number">140735195337472</span>)&gt;)</span><br></pre></td></tr></table></figure>
<p>总结：</p>
<ul>
<li>asyncio<code>提供了完善的异步IO支持；</code></li>
<li><code>异步操作需要在</code>coroutine<code>中通过</code>yield from`完成；</li>
<li>多个<code>coroutine</code>可以封装成一组Task然后并发执行</li>
</ul>
<h1 id="async-await"><a href="#async-await" class="headerlink" title="async/await"></a>async/await</h1><p>用<code>asyncio</code>提供的<code>@asyncio.coroutine</code>可以把一个generator标记为coroutine类型，然后在coroutine内部用<code>yield from</code>调用另一个coroutine实现异步操作。</p>
<p>为了简化并更好地标识异步IO，从Python 3.5开始引入了新的语法<code>async</code>和<code>await</code>，可以让coroutine的代码更简洁易读。</p>
<p>请注意，<code>async</code>和<code>await</code>是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换：</p>
<ol>
<li>把<code>@asyncio.coroutine</code>替换为<code>async</code>；</li>
<li>把<code>yield from</code>替换为<code>await</code>。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    print(<span class="string">"Compute %s + %s ..."</span> % (x, y))</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">1.0</span>)</span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">print_sum</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    result = <span class="keyword">await</span> compute(x, y)</span><br><span class="line">    print(<span class="string">"%s + %s = %s"</span> % (x, y, result))</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(print_sum(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># tasks = [print_sum(1, 2), print_sum(3, 4)]</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(asyncio.wait(tasks))</span></span><br><span class="line">loop.close()</span><br></pre></td></tr></table></figure>
<p>当事件循环开始运行时，它会在Task中寻找coroutine来执行调度，因为事件循环注册了<code>print_sum()</code>，因此<code>print_sum()</code>被调用，<strong>执行<code>result = await compute(x, y)</code>这条语句（等同于<code>result = yield from compute(x, y)）</code></strong>，<strong>因为<code>compute()</code>自身就是一个coroutine</strong>，因此<code>print_sum()</code>这个协程就会暂时被挂起，<strong><code>compute()</code>被加入到事件循环中</strong>，程序流执行compute()中的print语句，打印”Compute %s + %s …”，然后执行了<code>await asyncio.sleep(1.0)</code>，因为<strong><code>asyncio.sleep()</code>也是一个coroutine，接着<code>compute()</code>就会被挂起，等待计时器读秒，在这1秒的过程中，事件循环会在队列中查询可以被调度的coroutine</strong>，而因为此前<code>print_sum()</code>与<code>compute()</code>都被挂起了，因此事件循环会停下来等待协程的调度(如果有其他协程task就会在等待时间内去执行并返回)，当计时器读秒结束后，程序流便会返回到<code>compute()</code>中执行return语句，结果会返回到<code>print_sum()</code>中的result中，最后打印result，事件队列中没有可以调度的任务了，此时<code>loop.close()</code>把事件队列关闭，程序结束。</p>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/01/python编程进阶/python编程进阶（11）：使用C扩展/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/01/python编程进阶/python编程进阶（11）：使用C扩展/" itemprop="url">python编程进阶（11）：使用C扩展</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-01T09:14:32+08:00">
                2018-07-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3,061
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="使用C扩展"><a href="#使用C扩展" class="headerlink" title="使用C扩展"></a>使用C扩展</h1><p>CPython还为开发者实现了一个有趣的特性，使用Python可以轻松调用C代码</p>
<p>开发者有三种方法可以在自己的Python代码中来调用C编写的函数-<code>ctypes</code>，<code>SWIG</code>，<code>Python/C API</code>。每种方式也都有各自的利弊。</p>
<p>首先，我们要明确为什么要在Python中调用C？</p>
<p>常见原因如下：</p>
<ul>
<li>你要提升代码的运行速度，而且你知道C要比Python快50倍以上</li>
<li>C语言中有很多传统类库，而且有些正是你想要的，但你又不想用Python去重写它们</li>
<li>想对从内存到文件接口这样的底层资源进行访问</li>
<li>不需要理由，就是想这样做</li>
</ul>
<h2 id="CTypes"><a href="#CTypes" class="headerlink" title="CTypes"></a>CTypes</h2><p>Python中的<a href="https://docs.python.org/2/library/ctypes.html" target="_blank" rel="noopener">ctypes模块</a>可能是Python调用C方法中最简单的一种。ctypes模块提供了和C语言兼容的数据类型和函数来加载dll文件，因此在调用时不需对源文件做任何的修改。也正是如此奠定了这种方法的简单性。</p>
<p>示例如下</p>
<p>实现两数求和的C代码，保存为<code>add.c</code></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//sample C file to add 2 numbers - int and floats</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add_int</span><span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">add_float</span><span class="params">(<span class="keyword">float</span>, <span class="keyword">float</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add_int</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> num1 + num2;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">add_float</span><span class="params">(<span class="keyword">float</span> num1, <span class="keyword">float</span> num2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> num1 + num2;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来将C文件编译为<code>.so</code>文件(windows下为DLL)。下面操作会生成adder.so文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#For Linux</span></span><br><span class="line">$  gcc -shared -Wl,-soname,adder -o adder.so -fPIC add.c</span><br><span class="line"></span><br><span class="line"><span class="comment">#For Mac</span></span><br><span class="line">$ gcc -shared -Wl,-install_name,adder.so -o adder.so -fPIC add.c</span><br></pre></td></tr></table></figure>
<p>现在在你的Python代码中来调用它</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#load the shared object file</span></span><br><span class="line">adder = CDLL(<span class="string">'./adder.so'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Find sum of integers</span></span><br><span class="line">res_int = adder.add_int(<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Sum of 4 and 5 = "</span> + str(res_int)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Find sum of floats</span></span><br><span class="line">a = c_float(<span class="number">5.5</span>)</span><br><span class="line">b = c_float(<span class="number">4.1</span>)</span><br><span class="line"></span><br><span class="line">add_float = adder.add_float</span><br><span class="line">add_float.restype = c_float</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Sum of 5.5 and 4.1 = "</span>, str(add_float(a, b))</span><br></pre></td></tr></table></figure>
<p>输出如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sum of <span class="number">4</span> <span class="keyword">and</span> <span class="number">5</span> = <span class="number">9</span></span><br><span class="line">Sum of <span class="number">5.5</span> <span class="keyword">and</span> <span class="number">4.1</span> =  <span class="number">9.60000038147</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，C文件是自解释的，它包含两个函数，分别实现了整形求和和浮点型求和。</p>
<p>在Python文件中，一开始先导入ctypes模块，然后使用CDLL函数来加载我们创建的库文件。这样我们就可以通过变量<code>adder</code>来使用C类库中的函数了。当<code>adder.add_int()</code>被调用时，内部将发起一个对C函数<code>add_int</code>的调用。ctypes接口允许我们在调用C函数时使用原生Python中默认的字符串型和整型。</p>
<p>而对于其他类似布尔型和浮点型这样的类型，必须要使用正确的ctype类型才可以。如向<code>adder.add_float()</code>函数传参时, 我们要先将Python中的十进制值转化为c_float类型，然后才能传送给C函数。这种方法虽然简单，清晰，但是却很受限。例如，并不能在C中对对象进行操作。</p>
<h2 id="SWIG"><a href="#SWIG" class="headerlink" title="SWIG"></a>SWIG</h2><p>SWIG是Simplified Wrapper and Interface Generator的缩写。是Python中调用C代码的另一种方法。在这个方法中，开发人员必须编写一个额外的接口文件来作为SWIG(终端工具)的入口。</p>
<p>Python开发者一般不会采用这种方法，因为大多数情况它会带来不必要的复杂。而当你有一个C/C++代码库需要被多种语言调用时，这将是个非常不错的选择。</p>
<p>示例如下(来自<a href="http://www.swig.org/tutorial.html" target="_blank" rel="noopener">SWIG官网</a>)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">​```C</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="keyword">double</span> My_variable = <span class="number">3.0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fact</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> n*fact(n<span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">my_mod</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (x%y);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">get_time</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">time_t</span> ltime;</span><br><span class="line">    time(&amp;ltime);</span><br><span class="line">    <span class="keyword">return</span> ctime(&amp;ltime);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译它</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">unix % swig -python example.i</span><br><span class="line">unix % gcc -c example.c example_wrap.c \</span><br><span class="line">    -I/usr/local/include/python2<span class="number">.1</span></span><br><span class="line">unix % ld -shared example.o example_wrap.o -o _example.so</span><br></pre></td></tr></table></figure>
<p>最后，Python的输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> example</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>example.fact(<span class="number">5</span>)</span><br><span class="line"><span class="number">120</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>example.my_mod(<span class="number">7</span>,<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>example.get_time()</span><br><span class="line"><span class="string">'Sun Feb 11 23:01:07 1996'</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，使用SWIG确实达到了同样的效果，虽然下了更多的工夫，但如果你的目标是多语言还是很值得的。</p>
<h2 id="Python-C-API"><a href="#Python-C-API" class="headerlink" title="Python/C API"></a>Python/C API</h2><p><a href="https://docs.python.org/2/c-api/" target="_blank" rel="noopener">Python/C API</a>可能是被最广泛使用的方法。它不仅简单，而且可以在C代码中操作你的Python对象。</p>
<p>这种方法需要以特定的方式来编写C代码以供Python去调用它。所有的Python对象都被表示为一种叫做PyObject的结构体，并且<code>Python.h</code>头文件中提供了各种操作它的函数。例如，如果PyObject表示为PyListType(列表类型)时，那么我们便可以使用<code>PyList_Size()</code>函数来获取该结构的长度，类似Python中的<code>len(list)</code>函数。大部分对Python原生对象的基础函数和操作在<code>Python.h</code>头文件中都能找到。</p>
<p>示例</p>
<p>编写一个C扩展，添加所有元素到一个Python列表(所有元素都是数字)</p>
<p>来看一下我们要实现的效果，这里演示了用Python调用C扩展的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Though it looks like an ordinary python import, the addList module is implemented in C</span></span><br><span class="line"><span class="keyword">import</span> addList</span><br><span class="line"></span><br><span class="line">l = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Sum of List - "</span> + str(l) + <span class="string">" = "</span> +  str(addList.add(l))</span><br></pre></td></tr></table></figure>
<p>上面的代码和普通的Python文件并没有什么分别，导入并使用了另一个叫做<code>addList</code>的Python模块。唯一差别就是这个模块(addList)并不是用Python编写的，而是C。</p>
<p>接下来我们看看如何用C编写<code>addList</code>模块，这可能看起来有点让人难以接受，但是一旦你了解了这之中的各种组成，你就可以一往无前了。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Python.h has all the required function definitions to manipulate the Python objects</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Python.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//This is the function that is called from your python code</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> PyObject* <span class="title">addList_add</span><span class="params">(PyObject* self, PyObject* args)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    PyObject * listObj;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//The input arguments come as a tuple, we parse the args to get the various variables</span></span><br><span class="line">    <span class="comment">//In this case it's only one list variable, which will now be referenced by listObj</span></span><br><span class="line">    <span class="keyword">if</span> (! PyArg_ParseTuple( args, <span class="string">"O"</span>, &amp;listObj ))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//length of the list</span></span><br><span class="line">    <span class="keyword">long</span> length = PyList_Size(listObj);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//iterate over all the elements</span></span><br><span class="line">    <span class="keyword">int</span> i, sum =<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        <span class="comment">//get an element out of the list - the element is also a python objects</span></span><br><span class="line">        PyObject* temp = PyList_GetItem(listObj, i);</span><br><span class="line">        <span class="comment">//we know that object represents an integer - so convert it into C long</span></span><br><span class="line">        <span class="keyword">long</span> elem = PyInt_AsLong(temp);</span><br><span class="line">        sum += elem;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//value returned back to python code - another python object</span></span><br><span class="line">    <span class="comment">//build value here converts the C long to a python integer</span></span><br><span class="line">    <span class="keyword">return</span> Py_BuildValue(<span class="string">"i"</span>, sum);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//This is the docstring that corresponds to our 'add' function.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> addList_docs[] =</span><br><span class="line"><span class="string">"add(  ): add all elements of the list\n"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* This table contains the relavent info mapping -</span></span><br><span class="line"><span class="comment">   &lt;function-name in python module&gt;, &lt;actual-function&gt;,</span></span><br><span class="line"><span class="comment">   &lt;type-of-args the function expects&gt;, &lt;docstring associated with the function&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef addList_funcs[] = &#123;</span><br><span class="line">    &#123;<span class="string">"add"</span>, (PyCFunction)addList_add, METH_VARARGS, addList_docs&#125;,</span><br><span class="line">    &#123;<span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   addList is the module name, and this is the initialization block of the module.</span></span><br><span class="line"><span class="comment">   &lt;desired module name&gt;, &lt;the-info-table&gt;, &lt;module's-docstring&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">initaddList</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    Py_InitModule3(<span class="string">"addList"</span>, addList_funcs,</span><br><span class="line">            <span class="string">"Add all ze lists"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>逐步解释</p>
<ul>
<li><code>Python.h</code>头文件中包含了所有需要的类型(Python对象类型的表示)和函数定义(对Python对象的操作)</li>
<li>接下来我们编写将要在Python调用的函数, 函数传统的命名方式由{模块名}_{函数名}组成，所以我们将其命名为<code>addList_add</code></li>
<li>然后填写想在模块内实现函数的相关信息表，每行一个函数，以空行作为结束</li>
<li>最后的模块初始化块签名为<code>PyMODINIT_FUNC init{模块名}</code>。</li>
</ul>
<p>函数<code>addList_add</code>接受的参数类型为PyObject类型结构(同时也表示为元组类型，因为Python中万物皆为对象，所以我们先用PyObject来定义)。传入的参数则通过<code>PyArg_ParseTuple()</code>来解析。第一个参数是被解析的参数变量。第二个参数是一个字符串，告诉我们如何去解析元组中每一个元素。字符串的第n个字母正是代表着元组中第n个参数的类型。例如，”i”代表整形，”s”代表字符串类型, “O”则代表一个Python对象。接下来的参数都是你想要通过<code>PyArg_ParseTuple()</code>函数解析并保存的元素。这样参数的数量和模块中函数期待得到的参数数量就可以保持一致，并保证了位置的完整性。例如，我们想传入一个字符串，一个整数和一个Python列表，可以这样去写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int n;</span><br><span class="line">char *s;</span><br><span class="line">PyObject* list;</span><br><span class="line">PyArg_ParseTuple(args, <span class="string">"siO"</span>, &amp;n, &amp;s, &amp;list);</span><br></pre></td></tr></table></figure>
<p>在这种情况下，我们只需要提取一个列表对象，并将它存储在<code>listObj</code>变量中。然后用列表对象中的<code>PyList_Size()</code>函数来获取它的长度。就像Python中调用<code>len(list)</code>。</p>
<p>现在我们通过循环列表，使用<code>PyList_GetItem(list, index)</code>函数来获取每个元素。这将返回一个<code>PyObject*</code>对象。既然Python对象也能表示<code>PyIntType</code>，我们只要使用<code>PyInt_AsLong(PyObj *)</code>函数便可获得我们所需要的值。我们对每个元素都这样处理，最后再得到它们的总和。</p>
<p>总和将被转化为一个Python对象并通过<code>Py_BuildValue()</code>返回给Python代码，这里的i表示我们要返回一个Python整形对象。</p>
<p>现在我们已经编写完C模块了。将下列代码保存为<code>setup.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#build the modules</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup, Extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">'addList'</span>, version=<span class="string">'1.0'</span>,  \</span><br><span class="line">      ext_modules=[Extension(<span class="string">'addList'</span>, [<span class="string">'adder.c'</span>])])</span><br></pre></td></tr></table></figure>
<p>并且运行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<p>现在应该已经将我们的C文件编译安装到我们的Python模块中了。</p>
<p>在一番辛苦后，让我们来验证下我们的模块是否有效</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#module that talks to the C code</span></span><br><span class="line"><span class="keyword">import</span> addList</span><br><span class="line"></span><br><span class="line">l = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Sum of List - "</span> + str(l) + <span class="string">" = "</span> +  str(addList.add(l))</span><br></pre></td></tr></table></figure>
<p>输出结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sum of List - [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>] = <span class="number">15</span></span><br></pre></td></tr></table></figure>
<p>如你所见，我们已经使用Python.h API成功开发出了我们第一个Python C扩展。这种方法看似复杂，但你一旦习惯，它将变的非常有效。</p>
<p>Python调用C代码的另一种方式便是使用<a href="http://cython.org/" target="_blank" rel="noopener">Cython</a>让Python编译的更快。但是Cython和传统的Python比起来可以将它理解为另一种语言，所以我们就不在这里过多描述了。</p>
<h1 id="补充两个知识点"><a href="#补充两个知识点" class="headerlink" title="补充两个知识点"></a>补充两个知识点</h1><h2 id="列表辗平"><a href="#列表辗平" class="headerlink" title="列表辗平"></a>列表辗平</h2><p>可以通过使用<code>itertools</code>包中的<code>itertools.chain.from_iterable</code>轻松快速的辗平一个列表。下面是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a_list = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">print(list(itertools.chain.from_iterable(a_list)))</span><br><span class="line"><span class="comment"># Output: [1, 2, 3, 4, 5, 6]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">print(list(itertools.chain(*a_list)))</span><br><span class="line"><span class="comment"># Output: [1, 2, 3, 4, 5, 6]</span></span><br></pre></td></tr></table></figure>
<h2 id="for-else从句"><a href="#for-else从句" class="headerlink" title="for-else从句"></a>for-else从句</h2><p><code>for</code>循环还有一个<code>else</code>从句，我们大多数人并不熟悉。<strong>这个<code>else</code>从句会在循环正常结束时执行。这意味着，循环没有遇到任何break。若循环被某些因素打破，则不会执行else语句</strong>. 一旦你掌握了何时何地使用它，它真的会非常有用。我自己对它真是相见恨晚。</p>
<p>有个常见的构造是跑一个循环，并查找一个元素。如果这个元素被找到了，我们使用<code>break</code>来中断这个循环。有两个场景会让循环停下来。</p>
<ul>
<li>第一个是当一个元素被找到，<code>break</code>被触发。</li>
<li>第二个场景是循环结束。</li>
</ul>
<p>现在我们也许想知道其中哪一个，才是导致循环完成的原因。一个方法是先设置一个标记，然后在循环结束时打上标记。另一个是使用<code>else</code>从句。</p>
<p>这就是<code>for/else</code>循环的基本结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> container:</span><br><span class="line">    <span class="keyword">if</span> search_something(item):</span><br><span class="line">        <span class="comment"># Found it!</span></span><br><span class="line">        process(item)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># Didn't find anything..</span></span><br><span class="line">    not_found_in_container()</span><br></pre></td></tr></table></figure>
<p>考虑下这个简单的案例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>, n):</span><br><span class="line">        <span class="keyword">if</span> n % x == <span class="number">0</span>:</span><br><span class="line">            print(n, <span class="string">'equals'</span>, x, <span class="string">'*'</span>, n / x)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>它会找出2到10之间的数字的因子。现在是趣味环节了。我们可以加上一个附加的else语句块，来抓住质数，并且告诉我们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>, n):</span><br><span class="line">        <span class="keyword">if</span> n % x == <span class="number">0</span>:</span><br><span class="line">            print(n, <span class="string">'equals'</span>, x, <span class="string">'*'</span>, n / x)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:	<span class="comment"># 输出没有循环结束仍未找到因子的质数</span></span><br><span class="line">        <span class="comment"># loop fell through without finding a factor</span></span><br><span class="line">        print(n, <span class="string">'is a prime number'</span>)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/30/python编程进阶/python编程进阶（10）：sort、lambda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/30/python编程进阶/python编程进阶（10）：sort、lambda/" itemprop="url">python编程进阶（10）：sort、lambda</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-30T22:14:32+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,461
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="sort与sorted区别"><a href="#sort与sorted区别" class="headerlink" title="sort与sorted区别"></a>sort与sorted区别</h1><p>我们需要对List进行排序，Python提供了两个方法对给定的List L进行排序，</p>
<ul>
<li>方法1.用List的成员函数sort进行排序</li>
<li>方法2.用built-in函数sorted进行排序</li>
</ul>
<p>list.sort()与sorted()的不同在于，list.sort是在原位重新排列列表，而sorted()是产生一个新的列表。python中列表的内置函数list.sort（）只可以对列表中的元素进行排序，而全局性的sorted（）函数则对所有可迭代的对象都是适用的；并且list.sort（）函数是内置函数，会改变当前对象，而sorted（）函数只会返回一个排序后的当前对象的副本，而不会改变当前对象。</p>
<blockquote>
<p>原型：sort（fun，key，reverse=False）</p>
<p>sorted(itrearble, cmp=None, key=None,reverse=False)</p>
</blockquote>
<h2 id="内置函数sort（）"><a href="#内置函数sort（）" class="headerlink" title="内置函数sort（）"></a>内置函数sort（）</h2><p>参数fun是表明此sort函数是基于何种算法进行排序的，一般默认情况下python中用的是归并排序，并且一般情况下我们是不会重写此参数的，所以基本可以忽略；</p>
<p>参数key用来指定一个函数，此函数在每次元素比较时被调用，此函数代表排序的规则，也就是你按照什么规则对你的序列进行排序；</p>
<p>参数reverse是用来表明是否逆序，默认的False情况下是按照升序的规则进行排序的，当reverse=True时，便会按照降序进行排序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> attrgetter,itemgetter</span><br><span class="line"> </span><br><span class="line">list1 = [(<span class="number">2</span>,<span class="string">'huan'</span>,<span class="number">23</span>),(<span class="number">12</span>,<span class="string">'the'</span>,<span class="number">14</span>),(<span class="number">23</span>,<span class="string">'liu'</span>,<span class="number">90</span>)]</span><br><span class="line"> </span><br><span class="line"><span class="comment">#使用默认参数进行排序，即按照元组中第一个元素进行排序</span></span><br><span class="line">list1.sort()</span><br><span class="line"><span class="keyword">print</span> list1</span><br><span class="line"><span class="comment">#输出结果为[(2, 'huan', 23), (12, 'the', 14), (23, 'liu', 90)]</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#使用匿名表达式重写key所代表的函数,按照元组的第二个元素（下标为1）进行排序</span></span><br><span class="line">list1.sort(key=<span class="keyword">lambda</span> x:(x[<span class="number">1</span>]))</span><br><span class="line"><span class="keyword">print</span> list1</span><br><span class="line"><span class="comment">#[(2, 'huan', 23), (23, 'liu', 90), (12, 'the', 14)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用匿名函数重写key所代表的函数，先按照元组中下标为2的进行排序，</span></span><br><span class="line"><span class="comment"># 对于下标2处元素相同的，则按下标为0处的元素进行排序</span></span><br><span class="line">list1.sort(key=<span class="keyword">lambda</span> x:(x[<span class="number">2</span>],x[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> list1</span><br><span class="line"><span class="comment">#[(12, 'the', 14), (2, 'huan', 23), (23, 'liu', 90)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用operator模块中的itemgetter函数进行重写key所代表的函数，按照下标为1处的元素(第二个)进行排序</span></span><br><span class="line">list1.sort(key=itemgetter(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">print</span> list1</span><br><span class="line"><span class="comment">#[(2, 'huan', 23), (23, 'liu', 90), (12, 'the', 14)]</span></span><br></pre></td></tr></table></figure>
<h2 id="全局函数sorted（）"><a href="#全局函数sorted（）" class="headerlink" title="全局函数sorted（）"></a>全局函数sorted（）</h2><p>对于sorted（）函数中key的重写，和sort（）函数中是一样的，所以刚刚对于sort（）中讲解的方法，都是适用于sorted（）函数中。sorted（）最后会将排序的结果放到一个新的列表中，而不是对iterable本身进行修改。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sorted(<span class="string">'123456'</span>)  <span class="comment"># 字符串</span></span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>, <span class="string">'4'</span>, <span class="string">'5'</span>, <span class="string">'6'</span>]</span><br><span class="line"></span><br><span class="line">sorted([<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>])  <span class="comment"># 列表</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">sorted(&#123;<span class="number">1</span>:<span class="string">'q'</span>,<span class="number">3</span>:<span class="string">'c'</span>,<span class="number">2</span>:<span class="string">'g'</span>&#125;) <span class="comment"># 字典， 默认对字典的键进行排序</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">sorted(&#123;<span class="number">1</span>:<span class="string">'q'</span>,<span class="number">3</span>:<span class="string">'c'</span>,<span class="number">2</span>:<span class="string">'g'</span>&#125;.keys())  <span class="comment"># 对字典的键</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">sorted(&#123;<span class="number">1</span>:<span class="string">'q'</span>,<span class="number">3</span>:<span class="string">'c'</span>,<span class="number">2</span>:<span class="string">'g'</span>&#125;.values())  <span class="comment"># 对字典的值</span></span><br><span class="line">[<span class="string">'c'</span>, <span class="string">'g'</span>, <span class="string">'q'</span>]</span><br><span class="line"></span><br><span class="line">sorted(&#123;<span class="number">1</span>:<span class="string">'q'</span>,<span class="number">3</span>:<span class="string">'c'</span>,<span class="number">2</span>:<span class="string">'g'</span>&#125;.items())  <span class="comment"># 对键值对组成的元组的列表</span></span><br><span class="line">[(<span class="number">1</span>, <span class="string">'q'</span>), (<span class="number">2</span>, <span class="string">'g'</span>), (<span class="number">3</span>, <span class="string">'c'</span>)]</span><br></pre></td></tr></table></figure>
<p>对元素指定的某一部分进行排序,关键字排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 想要按照-后的数字的大小升序排序。要用到key</span></span><br><span class="line">s =[<span class="string">'Chr1-10.txt'</span>,<span class="string">'Chr1-1.txt'</span>,<span class="string">'Chr1-2.txt'</span>,<span class="string">'Chr1-14.txt'</span>,<span class="string">'Chr1-3.txt'</span>,<span class="string">'Chr1-20.txt'</span>,<span class="string">'Chr1-5.txt'</span>]</span><br><span class="line"></span><br><span class="line">sorted(s, key=<span class="keyword">lambda</span> d :int(d.split(<span class="string">'-'</span>)[<span class="number">-1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出 ['Chr1-1.txt', 'Chr1-2.txt', 'Chr1-3.txt','Chr1-5.txt', 'Chr1-10.txt', 'Chr1-14.txt', 'Chr1-20.txt']</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这就是key的功能，制定排序的关键字，通常都是一个lambda函数，当然你也可以事先定义好这个函数。如果不讲这个关键字转化为整型，结果是这样的：</span></span><br><span class="line">sorted(s, key=<span class="keyword">lambda</span> d : d.split(<span class="string">'-'</span>)[<span class="number">-1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出 ['Chr1-1.txt', 'Chr1-10.txt','Chr1-14.txt', 'Chr1-2.txt', 'Chr1-20.txt', 'Chr1-3.txt', 'Chr1-5.txt']</span></span><br></pre></td></tr></table></figure>
<p>这相当于把这个关键字当做字符串了，很显然，在python中，’2’ &gt; ‘10’。cmp不怎么用，因为key和reverse比单独一个cmp效率要高。</p>
<h1 id="lambda的各种用法"><a href="#lambda的各种用法" class="headerlink" title="lambda的各种用法"></a>lambda的各种用法</h1><p>1， 用在过滤函数中，指定过滤列表元素的条件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filter(<span class="keyword">lambda</span> x: x % <span class="number">3</span> == <span class="number">0</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"> &gt; [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<p>2， 用在排序函数中，指定对列表中所有元素进行排序的准则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sorted([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], key=<span class="keyword">lambda</span> x: abs(<span class="number">5</span>-x))</span><br><span class="line">&gt; [<span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<p>3， 用在reduce函数中，指定列表中两两相邻元素的结合条件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reduce(<span class="keyword">lambda</span> a, b: <span class="string">'&#123;&#125;, &#123;&#125;'</span>.format(a, b), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">&gt; <span class="string">'1, 2, 3, 4, 5, 6, 7, 8, 9'</span></span><br></pre></td></tr></table></figure>
<p>4， 用在map函数中，指定对列表中每一个元素的共同操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">map(<span class="keyword">lambda</span> x: x+<span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">&gt; [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>5， 从另一函数中返回一个函数，常用来实现函数装饰器(Wrapper)，例如python的function decorators</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(n)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">lambda</span> x: x + n</span><br><span class="line">f = transform(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> f(<span class="number">3</span>)</span><br><span class="line">&gt; <span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>6，列表排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">9</span>, <span class="number">10</span>), (<span class="number">13</span>, <span class="number">-3</span>)]</span><br><span class="line">a.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># Output: [(13, -3), (4, 1), (1, 2), (9, 10)]</span></span><br></pre></td></tr></table></figure>
<p>7，列表并行排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = zip(list1, list2)</span><br><span class="line">data = sorted(data)</span><br><span class="line">list1, list2 = map(<span class="keyword">lambda</span> t: list(t), zip(*data))</span><br><span class="line"><span class="comment"># zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表。</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/30/python编程进阶/python编程进阶（9）：枚举、自省、推导式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/30/python编程进阶/python编程进阶（9）：枚举、自省、推导式/" itemprop="url">python编程进阶（9）：枚举、自省、推导式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-30T19:54:32+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,470
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h1><p>枚举(<code>enumerate</code>)是Python内置函数。它的用处很难在简单的一行中说明，但是大多数的新人，甚至一些高级程序员都没有意识到它。</p>
<p>它允许我们遍历数据并自动计数，</p>
<p>下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> counter, value <span class="keyword">in</span> enumerate(some_list):</span><br><span class="line">    print(counter, value)</span><br></pre></td></tr></table></figure>
<p>不只如此，<code>enumerate</code>也接受一些可选参数，这使它更有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">my_list = [<span class="string">'apple'</span>, <span class="string">'banana'</span>, <span class="string">'grapes'</span>, <span class="string">'pear'</span>]</span><br><span class="line"><span class="keyword">for</span> c, value <span class="keyword">in</span> enumerate(my_list, <span class="number">1</span>):</span><br><span class="line">    print(c, value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出:</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">'apple'</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="string">'banana'</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="string">'grapes'</span>)</span><br><span class="line">(<span class="number">4</span>, <span class="string">'pear'</span>)</span><br></pre></td></tr></table></figure>
<p>上面这个可选参数允许我们定制从哪个数字开始枚举。<br>你还可以用来创建包含索引的元组列表， 例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_list = [<span class="string">'apple'</span>, <span class="string">'banana'</span>, <span class="string">'grapes'</span>, <span class="string">'pear'</span>]</span><br><span class="line">counter_list = list(enumerate(my_list, <span class="number">1</span>))</span><br><span class="line">print(counter_list)</span><br><span class="line"><span class="comment"># 输出: [(1, 'apple'), (2, 'banana'), (3, 'grapes'), (4, 'pear')]</span></span><br></pre></td></tr></table></figure>
<h1 id="对象自省"><a href="#对象自省" class="headerlink" title="对象自省"></a>对象自省</h1><p>自省(introspection)，在计算机编程领域里，是指在运行时来判断一个对象的类型的能力。它是Python的强项之一。Python中所有一切都是一个对象，而且我们可以仔细勘察那些对象。Python还包含了许多内置函数和模块来帮助我们。</p>
<h2 id="dir"><a href="#dir" class="headerlink" title="dir"></a>dir</h2><p>在这个小节里我们会学习到<code>dir</code>以及它在自省方面如何给我们提供便利。</p>
<p>它是用于自省的最重要的函数之一。<strong>它返回一个列表，列出了一个对象所拥有的属性和方法</strong>。这里是一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">my_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">dir(my_list)</span><br><span class="line"><span class="comment"># Output: ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__',</span></span><br><span class="line"><span class="comment"># '__delslice__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__',</span></span><br><span class="line"><span class="comment"># '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__',</span></span><br><span class="line"><span class="comment"># '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__',</span></span><br><span class="line"><span class="comment"># '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__',</span></span><br><span class="line"><span class="comment"># '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__',</span></span><br><span class="line"><span class="comment"># '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop',</span></span><br><span class="line"><span class="comment"># 'remove', 'reverse', 'sort']</span></span><br></pre></td></tr></table></figure>
<p>上面的自省给了我们一个列表对象的所有方法的名字。当你没法回忆起一个方法的名字，这会非常有帮助。如果我们运行<code>dir()</code>而不传入参数，那么它会返回当前作用域的所有名字。</p>
<h2 id="type和id"><a href="#type和id" class="headerlink" title="type和id"></a>type和id</h2><p><code>type</code>函数返回一个对象的类型。举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="string">''</span>))</span><br><span class="line"><span class="comment"># Output: &lt;type 'str'&gt;</span></span><br><span class="line"></span><br><span class="line">print(type([]))</span><br><span class="line"><span class="comment"># Output: &lt;type 'list'&gt;</span></span><br><span class="line"></span><br><span class="line">print(type(&#123;&#125;))</span><br><span class="line"><span class="comment"># Output: &lt;type 'dict'&gt;</span></span><br><span class="line"></span><br><span class="line">print(type(dict))</span><br><span class="line"><span class="comment"># Output: &lt;type 'type'&gt;</span></span><br><span class="line"></span><br><span class="line">print(type(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># Output: &lt;type 'int'&gt;</span></span><br></pre></td></tr></table></figure>
<p><code>id()</code>函数返回任意不同种类对象的唯一ID内存地址，举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">"Yasoob"</span></span><br><span class="line">print(id(name))</span><br><span class="line"><span class="comment"># Output: 139972439030304</span></span><br></pre></td></tr></table></figure>
<h2 id="inspect模块"><a href="#inspect模块" class="headerlink" title="inspect模块"></a>inspect模块</h2><p><code>inspect</code>模块也提供了许多有用的函数，来获取活跃对象的信息。比方说，你可以查看一个对象的成员，只需运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line">print(inspect.getmembers(str))</span><br><span class="line"><span class="comment"># Output: [('__add__', &lt;slot wrapper '__add__' of ... ...</span></span><br></pre></td></tr></table></figure>
<p>还有好多个其他方法也能有助于自省。如果你愿意，你可以去探索它们。</p>
<p>inspect.ismodule(object)： 是否为模块<br>inspect.isclass(object)：是否为类<br>inspect.ismethod(object)：是否为方法（bound method written in python）<br>inspect.isfunction(object)：是否为函数(python function, including lambda expression)<br>inspect.isgeneratorfunction(object)：是否为python生成器函数<br>inspect.isgenerator(object):是否为生成器<br>inspect.istraceback(object)： 是否为traceback<br>inspect.isframe(object)：是否为frame<br>inspect.iscode(object)：是否为code<br>inspect.isbuiltin(object)：是否为built-in函数或built-in方法<br>inspect.isroutine(object)：是否为用户自定义或者built-in函数或方法<br>inspect.isabstract(object)：是否为抽象基类<br>inspect.ismethoddescriptor(object)：是否为方法标识符<br>inspect.isdatadescriptor(object)：是否为数字标识符，数字标识符有<code>__get__</code> 和<code>__set__属性； 通常也有__name__和__doc__属性</code><br>inspect.isgetsetdescriptor(object)：是否为getset descriptor<br>inspect.ismemberdescriptor(object)：是否为member descriptor</p>
<h1 id="各种推导式-comprehensions"><a href="#各种推导式-comprehensions" class="headerlink" title="各种推导式(comprehensions)"></a>各种推导式(comprehensions)</h1><p>推导式（又称解析式）是Python的一种独有特性，如果我被迫离开了它，我会非常想念。推导式是可以从一个数据序列构建另一个新的数据序列的结构体。 共有三种推导，在Python2和3中都有支持：</p>
<ul>
<li>列表(<code>list</code>)推导式</li>
<li>字典(<code>dict</code>)推导式</li>
<li>集合(<code>set</code>)推导式</li>
</ul>
<p>我们将一一进行讨论。一旦你知道了使用列表推导式的诀窍，你就能轻易使用任意一种推导式了。</p>
<h2 id="列表推导式（list-comprehensions）"><a href="#列表推导式（list-comprehensions）" class="headerlink" title="列表推导式（list comprehensions）"></a>列表推导式（list comprehensions）</h2><p>列表推导式（又称列表解析式）提供了一种简明扼要的方法来创建列表。<br>它的结构是在一个中括号里包含一个表达式，然后是一个<code>for</code>语句，然后是0个或多个<code>for</code>或者<code>if</code>语句。那个表达式可以是任意的，意思是你可以在列表中放入任意类型的对象。返回结果将是一个新的列表，在这个以<code>if</code>和<code>for</code>语句为上下文的表达式运行完成之后产生。</p>
<h3 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">variable = [out_exp <span class="keyword">for</span> out_exp <span class="keyword">in</span> input_list <span class="keyword">if</span> out_exp == <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h2 id="字典推导式（dict-comprehensions）"><a href="#字典推导式（dict-comprehensions）" class="headerlink" title="字典推导式（dict comprehensions）"></a>字典推导式（dict comprehensions）</h2><p><strong>字典推导和列表推导的使用方法是类似的,只不中括号该改成大括号，毕竟字典本身用的就是大括号。</strong>这里有个我最近发现的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mcase = &#123;<span class="string">'a'</span>: <span class="number">10</span>, <span class="string">'b'</span>: <span class="number">34</span>, <span class="string">'A'</span>: <span class="number">7</span>, <span class="string">'Z'</span>: <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">mcase_frequency = &#123;</span><br><span class="line">    k.lower(): mcase.get(k.lower(), <span class="number">0</span>) + mcase.get(k.upper(), <span class="number">0</span>)	<span class="comment"># 执行函数，k为每个字典的关键字</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> mcase.keys()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># mcase_frequency == &#123;'a': 17, 'z': 3, 'b': 34&#125;</span></span><br></pre></td></tr></table></figure>
<p>在上面的例子中我们把同一个字母但不同大小写的值合并起来了。</p>
<p>就我个人来说没有大量使用字典推导式。</p>
<p>你还可以快速对换一个字典的键和值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> some_dict.items()&#125;</span><br></pre></td></tr></table></figure>
<h2 id="集合推导式（set-comprehensions）"><a href="#集合推导式（set-comprehensions）" class="headerlink" title="集合推导式（set comprehensions）"></a>集合推导式（set comprehensions）</h2><p><strong>集合推导式跟列表推导式差不多，都是对一个列表的元素全部执行相同的操作，但集合是一种无重复无序的序列</strong><br><strong>区别：跟列表推到式的区别在于：1.不使用中括号，使用大括号；2.结果中无重复；3.结果是一个set()集合，集合里面是一个序列：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">squared = &#123;x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;</span><br><span class="line">print(squared)</span><br><span class="line"><span class="comment"># Output: &#123;1, 4&#125;</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/30/python编程进阶/python编程进阶（8）：容器Collections/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/30/python编程进阶/python编程进阶（8）：容器Collections/" itemprop="url">python编程进阶（8）：容器Collections</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-30T16:14:32+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,945
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="容器-Collections"><a href="#容器-Collections" class="headerlink" title="容器(Collections)"></a>容器(Collections)</h1><p>Python附带一个模块，它包含许多容器数据类型，名字叫作<code>collections</code>。我们将讨论它的作用和用法。</p>
<p>我们将讨论的是：</p>
<ul>
<li>defaultdict</li>
<li>counter</li>
<li>deque</li>
<li>namedtuple</li>
<li>enum.Enum (包含在Python 3.4以上)</li>
</ul>
<h2 id="defaultdict"><a href="#defaultdict" class="headerlink" title="defaultdict"></a>defaultdict</h2><p>众所周知，在Python中如果访问字典中不存在的键，会引发KeyError异常（JavaScript中如果对象中不存在某个属性，则返回undefined）。<strong>但是有时候，字典中的每个键都存在默认值是非常方便的</strong>。例如下面的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strings = (<span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>, <span class="string">'puppy'</span>,</span><br><span class="line">           <span class="string">'weasel'</span>, <span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>)</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kw <span class="keyword">in</span> strings:</span><br><span class="line">    counts[kw] += <span class="number">1</span>	<span class="comment"># 第一次统计时没有键对应的默认值</span></span><br></pre></td></tr></table></figure>
<p>该例子统计strings中某个单词出现的次数，并在counts字典中作记录。单词每出现一次，在counts相对应的键所存的值数字加1。<strong>但是事实上，运行这段代码会抛出KeyError异常，出现的时机是每个单词第一次统计的时候，因为Python的dict中不存在默认值的说法</strong>，可以在Python命令行中验证：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>counts = dict()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>counts</span><br><span class="line">&#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>counts[<span class="string">'puppy'</span>] += <span class="number">1</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">KeyError: <span class="string">'puppy'</span></span><br></pre></td></tr></table></figure>
<h3 id="使用判断语句检查"><a href="#使用判断语句检查" class="headerlink" title="使用判断语句检查"></a>使用判断语句检查</h3><p>既然如此，首先可能想到的方法是在单词第一次统计的时候，<strong>在counts中相应的键存下默认值1</strong>。这需要在处理的时候添加一个判断语句：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">strings = (<span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>, <span class="string">'puppy'</span>,</span><br><span class="line">           <span class="string">'weasel'</span>, <span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>)</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kw <span class="keyword">in</span> strings:</span><br><span class="line">    <span class="keyword">if</span> kw <span class="keyword">not</span> <span class="keyword">in</span> counts:</span><br><span class="line">        counts[kw] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        counts[kw] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># counts:</span></span><br><span class="line"><span class="comment"># &#123;'puppy': 5, 'weasel': 1, 'kitten': 2&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="使用dict-setdefault-方法"><a href="#使用dict-setdefault-方法" class="headerlink" title="使用dict.setdefault()方法"></a>使用<code>dict.setdefault()</code>方法</h3><p>也可以通过<code>dict.setdefault()</code>方法来设置默认值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">strings = (<span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>, <span class="string">'puppy'</span>,</span><br><span class="line">           <span class="string">'weasel'</span>, <span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>)</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kw <span class="keyword">in</span> strings:</span><br><span class="line">    counts.setdefault(kw, <span class="number">0</span>)</span><br><span class="line">    counts[kw] += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><strong><code>dict.setdefault()</code>方法接收两个参数，第一个参数是健的名称，第二个参数是默认值。假如字典中不存在给定的键，则返回参数中提供的默认值；反之，则返回字典中保存的值</strong>。利用<code>dict.setdefault()</code>方法的返回值可以重写for循环中的代码，使其更加简洁：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strings = (<span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>, <span class="string">'puppy'</span>,</span><br><span class="line">           <span class="string">'weasel'</span>, <span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>)</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kw <span class="keyword">in</span> strings:</span><br><span class="line">    counts[kw] = counts.setdefault(kw, <span class="number">0</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="使用collections-defaultdict类"><a href="#使用collections-defaultdict类" class="headerlink" title="使用collections.defaultdict类"></a>使用<code>collections.defaultdict</code>类</h3><p>以上的方法虽然在一定程度上解决了dict中不存在默认值的问题，但是这时候我们会想，有没有一种字典它本身提供了默认值的功能呢？答案是肯定的，那就是<code>collections.defaultdict</code>。</p>
<p><strong>defaultdict类就好像是一个dict，但是它是使用一个类型来初始化的</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd = defaultdict(list)	<span class="comment"># 接受一个list类型作为初始化参数</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">defaultdict(&lt;type <span class="string">'list'</span>&gt;, &#123;&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>defaultdict类的初始化函数接受一个类型作为参数，当所访问的键不存在的时候，可以实例化一个值作为默认值：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">'foo'</span>]</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">defaultdict(&lt;type <span class="string">'list'</span>&gt;, &#123;<span class="string">'foo'</span>: []&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">'bar'</span>].append(<span class="string">'quux'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">defaultdict(&lt;type <span class="string">'list'</span>&gt;, &#123;<span class="string">'foo'</span>: [], <span class="string">'bar'</span>: [<span class="string">'quux'</span>]&#125;)</span><br></pre></td></tr></table></figure>
<p>需<strong>要注意的是，这种形式的默认值只有在通过<code>dict[key]</code>或者<code>dict.__getitem__(key)</code>访问的时候才有效</strong>，这其中的原因在下文会介绍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd = defaultdict(list)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'something'</span> <span class="keyword">in</span> dd</span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd.pop(<span class="string">'something'</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">KeyError: <span class="string">'pop(): dictionary is empty'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd.get(<span class="string">'something'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">'something'</span>]</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<p><strong>该类除了接受类型名称作为初始化函数的参数之外，还可以使用任何不带参数的可调用函数，到时该函数的返回结果作为默认值</strong>，这样使得默认值的取值更加灵活。下面用一个例子来说明，如何用自定义的不带参数的函数zero()作为初始化函数的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">zero</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd = defaultdict(zero)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">defaultdict(&lt;function zero at <span class="number">0xb7ed2684</span>&gt;, &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">'foo'</span>]</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">defaultdict(&lt;function zero at <span class="number">0xb7ed2684</span>&gt;, &#123;<span class="string">'foo'</span>: <span class="number">0</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>利用<code>collections.defaultdict</code>来解决最初的单词统计问题，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">strings = (<span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>, <span class="string">'puppy'</span>,</span><br><span class="line">           <span class="string">'weasel'</span>, <span class="string">'puppy'</span>, <span class="string">'kitten'</span>, <span class="string">'puppy'</span>)</span><br><span class="line">counts = defaultdict(<span class="keyword">lambda</span>: <span class="number">0</span>)  <span class="comment"># 使用lambda来定义简单的函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> strings:</span><br><span class="line">    counts[s] += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="defaultdict-类是如何实现的"><a href="#defaultdict-类是如何实现的" class="headerlink" title="defaultdict 类是如何实现的"></a>defaultdict 类是如何实现的</h3><p>通过上面的内容，想必大家已经了解了defaultdict类的用法，那么在defaultdict类中又是如何来实现默认值的功能呢？<strong>这其中的关键是使用了看<code>__missing__()</code>这个方法</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> defaultdict.__missing__.__doc__</span><br><span class="line">__missing__(key) <span class="comment"># Called by __getitem__ for missing key; pseudo-code:</span></span><br><span class="line">  <span class="keyword">if</span> self.default_factory <span class="keyword">is</span> <span class="keyword">None</span>: <span class="keyword">raise</span> KeyError(key)</span><br><span class="line">  self[key] = value = self.default_factory()</span><br><span class="line">  <span class="keyword">return</span> value</span><br></pre></td></tr></table></figure>
<p><strong>通过查看<code>__missing__()</code>方法的docstring，可以看出当使用<code>__getitem__()</code>方法访问一个不存在的键时(dict[key]这种形式实际上是<code>__getitem__()</code>方法的简化形式)，会调用<code>__missing__()</code>方法获取默认值，并将该键添加到字典中去</strong>。</p>
<h2 id="counter"><a href="#counter" class="headerlink" title="counter"></a>counter</h2><p>Counter是一个计数器，它可以帮助我们针对某项数据进行计数。比如它可以用来计算每个人喜欢多少种颜色：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">colours = (</span><br><span class="line">    (<span class="string">'Yasoob'</span>, <span class="string">'Yellow'</span>),</span><br><span class="line">    (<span class="string">'Ali'</span>, <span class="string">'Blue'</span>),</span><br><span class="line">    (<span class="string">'Arham'</span>, <span class="string">'Green'</span>),</span><br><span class="line">    (<span class="string">'Ali'</span>, <span class="string">'Black'</span>),</span><br><span class="line">    (<span class="string">'Yasoob'</span>, <span class="string">'Red'</span>),</span><br><span class="line">    (<span class="string">'Ahmed'</span>, <span class="string">'Silver'</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">favs = Counter(name <span class="keyword">for</span> name, colour <span class="keyword">in</span> colours)</span><br><span class="line">print(favs)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出:</span></span><br><span class="line"><span class="comment">## Counter(&#123;</span></span><br><span class="line"><span class="comment">##     'Yasoob': 2,</span></span><br><span class="line"><span class="comment">##     'Ali': 2,</span></span><br><span class="line"><span class="comment">##     'Arham': 1,</span></span><br><span class="line"><span class="comment">##     'Ahmed': 1</span></span><br><span class="line"><span class="comment">##  &#125;)</span></span><br></pre></td></tr></table></figure>
<p>我们也可以在利用它统计一个文件，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'filename'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    line_count = Counter(f)</span><br><span class="line">print(line_count)</span><br></pre></td></tr></table></figure>
<p>还有</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = Counter()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> ch <span class="keyword">in</span> <span class="string">'programming'</span>:</span><br><span class="line"><span class="meta">... </span>    c[ch] = c[ch] + <span class="number">1</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">Counter(&#123;<span class="string">'g'</span>: <span class="number">2</span>, <span class="string">'m'</span>: <span class="number">2</span>, <span class="string">'r'</span>: <span class="number">2</span>, <span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'i'</span>: <span class="number">1</span>, <span class="string">'o'</span>: <span class="number">1</span>, <span class="string">'n'</span>: <span class="number">1</span>, <span class="string">'p'</span>: <span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="deque"><a href="#deque" class="headerlink" title="deque"></a>deque</h2><p>deque提供了一个双端队列，你可以从头/尾两端添加或删除元素。要想使用它，首先我们要从<code>collections</code>中导入<code>deque</code>模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br></pre></td></tr></table></figure>
<p>现在，你可以创建一个<code>deque</code>对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = deque()</span><br></pre></td></tr></table></figure>
<p>它的用法就像python的<code>list</code>，并且提供了类似的方法，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">d = deque()</span><br><span class="line">d.append(<span class="string">'1'</span>)</span><br><span class="line">d.append(<span class="string">'2'</span>)</span><br><span class="line">d.append(<span class="string">'3'</span>)</span><br><span class="line"></span><br><span class="line">print(len(d))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: 3</span></span><br><span class="line"></span><br><span class="line">print(d[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: '1'</span></span><br><span class="line"></span><br><span class="line">print(d[<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: '3'</span></span><br></pre></td></tr></table></figure>
<p>你可以从两端取出(pop)数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">d = deque(range(<span class="number">5</span>))</span><br><span class="line">print(len(d))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: 5</span></span><br><span class="line"></span><br><span class="line">d.popleft()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: 0</span></span><br><span class="line"></span><br><span class="line">d.pop()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: 4</span></span><br><span class="line"></span><br><span class="line">print(d)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: deque([1, 2, 3])</span></span><br></pre></td></tr></table></figure>
<p>我们也可以限制这个列表的大小，当超出你设定的限制时，数据会从对队列另一端被挤出去(pop)。<br>最好的解释是给出一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = deque(maxlen=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>
<p>现在当你插入30条数据时，最左边一端的数据将从队列中删除。</p>
<p>你还可以从任一端扩展这个队列中的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d = deque([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">d.extendleft([<span class="number">0</span>])</span><br><span class="line">d.extend([<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line">print(d)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: deque([0, 1, 2, 3, 4, 5, 6, 7, 8])</span></span><br></pre></td></tr></table></figure>
<h2 id="namedtuple"><a href="#namedtuple" class="headerlink" title="namedtuple"></a>namedtuple</h2><p>您可能已经熟悉元组。<br>一个元组是一个不可变的列表，你可以存储一个数据的序列，它和命名元组(<code>namedtuples</code>)非常像，但有几个关键的不同。<br><strong>主要相似点是都不像列表，你不能修改元组中的数据。为了获取元组中的数据，你需要使用整数作为索引</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">man = (<span class="string">'Ali'</span>, <span class="number">30</span>)</span><br><span class="line">print(man[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: Ali</span></span><br></pre></td></tr></table></figure>
<p><strong>嗯，那<code>namedtuples</code>是什么呢？它把元组变成一个针对简单任务的容器。你不必使用整数索引来访问一个<code>namedtuples</code>的数据。你可以像字典(<code>dict</code>)一样访问<code>namedtuples</code>，但<code>namedtuples</code>是不可变的</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">Animal = namedtuple(<span class="string">'Animal'</span>, <span class="string">'name age type'</span>)</span><br><span class="line">perry = Animal(name=<span class="string">"perry"</span>, age=<span class="number">31</span>, type=<span class="string">"cat"</span>)</span><br><span class="line"></span><br><span class="line">print(perry)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: Animal(name='perry', age=31, type='cat')</span></span><br><span class="line"></span><br><span class="line">print(perry.name)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: 'perry'</span></span><br></pre></td></tr></table></figure>
<p>现在你可以看到，我们可以用名字来访问<code>namedtuple</code>中的数据。我们再继续分析它。<strong>一个命名元组(<code>namedtuple</code>)有两个必需的参数。它们是元组名称和字段名称。</strong></p>
<p><strong>在上面的例子中，我们的元组名称是<code>Animal</code>，字段名称是’name’，’age’和’type’。</strong><br><code>namedtuple</code>让你的元组变得<strong>自文档</strong>了。你只要看一眼就很容易理解代码是做什么的。<br><strong>你也不必使用整数索引来访问一个命名元组，这让你的代码更易于维护</strong>。<br>而且，<strong>namedtuple的每个实例没有对象字典</strong>，<strong>所以它们很轻量</strong>，与普通的元组比，并不需要更多的内存。这使得它们比字典更快。</p>
<p><strong>然而，要记住它是一个元组，属性值在<code>namedtuple</code>中是不可变的，所以下面的代码不能工作</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">Animal = namedtuple(<span class="string">'Animal'</span>, <span class="string">'name age type'</span>)</span><br><span class="line">perry = Animal(name=<span class="string">"perry"</span>, age=<span class="number">31</span>, type=<span class="string">"cat"</span>)</span><br><span class="line">perry.age = <span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出:</span></span><br><span class="line"><span class="comment">## Traceback (most recent call last):</span></span><br><span class="line"><span class="comment">##     File "", line 1, in</span></span><br><span class="line"><span class="comment">## AttributeError: can't set attribute</span></span><br></pre></td></tr></table></figure>
<p>你应该使用命名元组来让代码<strong>自文档</strong>，<strong>它们向后兼容于普通的元组</strong>，<strong>这意味着你可以既使用整数索引，也可以使用名称来访问<code>namedtuple</code>：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">Animal = namedtuple(<span class="string">'Animal'</span>, <span class="string">'name age type'</span>)</span><br><span class="line">perry = Animal(name=<span class="string">"perry"</span>, age=<span class="number">31</span>, type=<span class="string">"cat"</span>)</span><br><span class="line">print(perry[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: perry</span></span><br></pre></td></tr></table></figure>
<p>最后，你可以将一个命名元组转换为字典，方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">Animal = namedtuple(<span class="string">'Animal'</span>, <span class="string">'name age type'</span>)</span><br><span class="line">perry = Animal(name=<span class="string">"Perry"</span>, age=<span class="number">31</span>, type=<span class="string">"cat"</span>)</span><br><span class="line">print(perry._asdict())</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出: OrderedDict([('name', 'Perry'), ('age', 31), ...</span></span><br></pre></td></tr></table></figure>
<h2 id="enum-Enum-Python-3-4"><a href="#enum-Enum-Python-3-4" class="headerlink" title="enum.Enum (Python 3.4+)"></a>enum.Enum (Python 3.4+)</h2><p>另一个有用的容器是枚举对象，它属于<code>enum</code>模块，存在于Python 3.4以上版本中（同时作为一个独立的PyPI包<code>enum34</code>供老版本使用）。Enums(枚举类型)基本上是一种组织各种东西的方式。</p>
<p>让我们回顾一下上一个’Animal’命名元组的例子。它有一个type字段，问题是，type是一个字符串。那么问题来了，万一程序员输入了<code>Cat</code>，因为他按到了Shift键，或者输入了’CAT’，甚至’kitten’？解决的方法是为这样的枚举类型定义一个class类型，然后，<strong>每个常量都是class的一个唯一实例</strong>。Python提供了<code>Enum</code>类来实现这个功能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"></span><br><span class="line">Month = Enum(<span class="string">'Month'</span>, (<span class="string">'Jan'</span>, <span class="string">'Feb'</span>, <span class="string">'Mar'</span>, <span class="string">'Apr'</span>, <span class="string">'May'</span>, <span class="string">'Jun'</span>, <span class="string">'Jul'</span>, <span class="string">'Aug'</span>, <span class="string">'Sep'</span>, <span class="string">'Oct'</span>, <span class="string">'Nov'</span>, <span class="string">'Dec'</span>))</span><br></pre></td></tr></table></figure>
<p>这样我们就获得了<code>Month</code>类型的枚举类，可以直接使用<code>Month.Jan</code>来引用一个常量，或者枚举它的所有成员：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, member <span class="keyword">in</span> Month.__members__.items():</span><br><span class="line">    print(name, <span class="string">'=&gt;'</span>, member, <span class="string">','</span>, member.value)</span><br></pre></td></tr></table></figure>
<p><code>value</code>属性则是自动赋给成员的<code>int</code>常量，默认从<code>1</code>开始计数。</p>
<p>如果需要更精确地控制枚举类型，可以从<code>Enum</code>派生出自定义类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"></span><br><span class="line"><span class="meta">@unique		# @unique装饰器可以帮助我们检查保证没有重复值。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Species</span><span class="params">(Enum)</span>:</span></span><br><span class="line">    cat = <span class="number">1</span></span><br><span class="line">    dog = <span class="number">2</span></span><br><span class="line">    horse = <span class="number">3</span></span><br><span class="line">    aardvark = <span class="number">4</span></span><br><span class="line">    butterfly = <span class="number">5</span></span><br><span class="line">    owl = <span class="number">6</span></span><br><span class="line">    platypus = <span class="number">7</span></span><br><span class="line">    dragon = <span class="number">8</span></span><br><span class="line">    unicorn = <span class="number">9</span></span><br><span class="line">    <span class="comment"># 依次类推</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 但我们并不想关心同一物种的年龄，所以我们可以使用一个别名</span></span><br><span class="line">    kitten = <span class="number">1</span>  <span class="comment"># (译者注：幼小的猫咪)</span></span><br><span class="line">    puppy = <span class="number">2</span>   <span class="comment"># (译者注：幼小的狗狗)</span></span><br><span class="line"></span><br><span class="line">Animal = namedtuple(<span class="string">'Animal'</span>, <span class="string">'name age type'</span>)</span><br><span class="line">perry = Animal(name=<span class="string">"Perry"</span>, age=<span class="number">31</span>, type=Species.cat)</span><br><span class="line">drogon = Animal(name=<span class="string">"Drogon"</span>, age=<span class="number">4</span>, type=Species.dragon)</span><br><span class="line">tom = Animal(name=<span class="string">"Tom"</span>, age=<span class="number">75</span>, type=Species.cat)</span><br><span class="line">charlie = Animal(name=<span class="string">"Charlie"</span>, age=<span class="number">2</span>, type=Species.kitten)</span><br></pre></td></tr></table></figure>
<p>现在，我们进行一些测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>charlie.type == tom.type</span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>charlie.type</span><br><span class="line">&lt;Species.cat: <span class="number">1</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>这样就没那么容易错误，我们必须更明确，而且我们应该只使用定义后的枚举类型</strong>。</p>
<p>有三种方法访问枚举数据，例如以下方法都可以获取到’cat’的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Species(<span class="number">1</span>)</span><br><span class="line">Species[<span class="string">'cat'</span>]</span><br><span class="line">Species.cat</span><br></pre></td></tr></table></figure>
<p>参考资料</p>
<p>【1】：<a href="http://kodango.com/understand-defaultdict-in-python" target="_blank" rel="noopener">http://kodango.com/understand-defaultdict-in-python</a></p>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/30/python编程进阶/python编程进阶（7）：可变对象和slots/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mosbyllc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mosbyllc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/30/python编程进阶/python编程进阶（7）：可变对象和slots/" itemprop="url">python编程进阶（7）：可变对象和slots</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-30T10:46:27+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python编程进阶/" itemprop="url" rel="index">
                    <span itemprop="name">python编程进阶</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,567
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="对象变动-Mutation"><a href="#对象变动-Mutation" class="headerlink" title="对象变动(Mutation)"></a>对象变动(Mutation)</h1><p>当你将一个变量赋值为另一个可变类型的变量时，<strong>对这个数据的任意改动会同时反映到这两个变量上去。新变量只不过是老变量的一个别名而已。对象可变与不可变性，是对内存地址而言的</strong>。现在讲述的这个情况只是针对可变数据类型。</p>
<h2 id="不可变对象（需要复制到新内存）"><a href="#不可变对象（需要复制到新内存）" class="headerlink" title="不可变对象（需要复制到新内存）"></a>不可变对象（需要复制到新内存）</h2><blockquote>
<p>常见不可变对象类型：int，string，float，tuple，bool ，frozenset，bytes</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">int_test</span><span class="params">()</span>:</span> </span><br><span class="line">    i = <span class="number">77</span></span><br><span class="line">    j = <span class="number">77</span></span><br><span class="line">    print(id(<span class="number">77</span>))                  <span class="comment">#140396579590760</span></span><br><span class="line">    print(<span class="string">'i id:'</span> + str(id(i)))      <span class="comment">#i id:140396579590760</span></span><br><span class="line">    print(<span class="string">'j id:'</span> + str(id(j)))      <span class="comment">#j id:140396579590760</span></span><br><span class="line">    <span class="keyword">print</span> i <span class="keyword">is</span> j                    <span class="comment">#True</span></span><br><span class="line">    j = j + <span class="number">1</span></span><br><span class="line">    print(<span class="string">'new i id:'</span> + str(id(i)))  <span class="comment">#new i id:140396579590760</span></span><br><span class="line">    print(<span class="string">'new j id:'</span> + str(id(j)))  <span class="comment">#new j id:140396579590736</span></span><br><span class="line">    <span class="keyword">print</span> i <span class="keyword">is</span> j                    <span class="comment">#False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    int_test()</span><br></pre></td></tr></table></figure>
<p>首先i和j都指向77这个内存块。然后我们修改j的值，按道理j修改之后应该i的值也发生改变的，因为它们都是指向的同一块内存，但结果是并没有。<strong>因为int类型是不可变类型，所有其实是j复制了一份到新的内存地址然后+1，然后j又指向了新的地址。所以j的内存id发生了变化。</strong></p>
<p>内存变化如下：</p>
<p><img src="/2018/06/30/python编程进阶/python编程进阶（7）：可变对象和slots/02.png" alt=""></p>
<h2 id="可变对象（在原内存上修改）"><a href="#可变对象（在原内存上修改）" class="headerlink" title="可变对象（在原内存上修改）"></a>可变对象（在原内存上修改）</h2><blockquote>
<p>常见可变对象类型：list，dict，set，user-defined classes(unless specifically made immutable)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dict_test</span><span class="params">()</span>:</span></span><br><span class="line">    a = &#123;&#125;	</span><br><span class="line">    b = a</span><br><span class="line">    print(id(a))	<span class="comment"># 140367329543360</span></span><br><span class="line">    a[<span class="string">'a'</span>] = <span class="string">'hhhh'</span></span><br><span class="line">    print(<span class="string">'id a:'</span> + str(id(a)))	<span class="comment"># id a:140367329543360</span></span><br><span class="line">    print(<span class="string">'a:'</span> + str(a))	<span class="comment"># a:&#123;'a': 'hhhh'&#125;</span></span><br><span class="line">    print(<span class="string">'id b:'</span> + str(id(b)))	<span class="comment"># id b:140367329543360</span></span><br><span class="line">    print(<span class="string">'b:'</span> + str(b))	<span class="comment"># b:&#123;'a': 'hhhh'&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dict_test()</span><br></pre></td></tr></table></figure>
<p>可以看到a最早的内存地址id是<code>140367329543360</code> 然后把a赋值给b其实就是让变量b的也指向a所指向的内存空间。然后我们发现当a发生变化后，b也跟着发生变化了。<strong>因为list是可变类型，所以并不会复制一份再改变，而是直接在a所指向的内存空间修改数据，而b也是指向该内存空间的，自然b也就跟着改变了。</strong></p>
<p><img src="/2018/06/30/python编程进阶/python编程进阶（7）：可变对象和slots/03.png" alt=""></p>
<p>对于列表，首地址是不可变的，而对于列表内的所有元素进行修改，会改变单个元素的地址（指向不同的引用）。所以说对于列表中的单个元素而言是不可变的，对于整体列表而言是可变的，如下图所示</p>
<p><img src="/2018/06/30/python编程进阶/python编程进阶（7）：可变对象和slots/04.jpg" alt=""></p>
<h2 id="python函数的参数传递"><a href="#python函数的参数传递" class="headerlink" title="python函数的参数传递"></a>python函数的参数传递</h2><p>由于<strong>python规定参数传递都是传递引用，也就是传递给函数的是原变量实际所指向的内存空间，修改的时候就会根据该引用的指向去修改该内存中的内容</strong>，所以按道理说我们在函数内改变了传递过来的参数的值的话，原来外部的变量也应该受到影响。但是上面我们说到了python中有可变类型和不可变类型，这样的话，<strong>当传过来的是可变类型(list,dict)时，我们在函数内部修改就会影响函数外部的变量。而传入的是不可变类型时在函数内部修改改变量并不会影响函数外部的变量，因为修改的时候会先复制一份再修改</strong>。下面通过代码证明一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(a_int, b_list)</span>:</span></span><br><span class="line">    a_int = a_int + <span class="number">1</span></span><br><span class="line">    b_list.append(<span class="string">'13'</span>)</span><br><span class="line">    print(<span class="string">'inner a_int:'</span> + str(a_int))</span><br><span class="line">    print(<span class="string">'inner b_list:'</span> + str(b_list))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    a_int = <span class="number">5</span></span><br><span class="line">    b_list = [<span class="number">10</span>, <span class="number">11</span>]</span><br><span class="line"></span><br><span class="line">    test(a_int, b_list)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'outer a_int:'</span> + str(a_int))</span><br><span class="line">    print(<span class="string">'outer b_list:'</span> + str(b_list))</span><br></pre></td></tr></table></figure>
<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inner a_int:<span class="number">6</span></span><br><span class="line"></span><br><span class="line">inner b_list:[<span class="number">10</span>, <span class="number">11</span>, <span class="string">'13'</span>]</span><br><span class="line"></span><br><span class="line">outer a_int:<span class="number">5</span></span><br><span class="line"></span><br><span class="line">outer b_list:[<span class="number">10</span>, <span class="number">11</span>, <span class="string">'13'</span>]</span><br></pre></td></tr></table></figure>
<p>好啦！答案显而易见啦，经过<code>test()</code>方法修改后，传递过来的int类型外部变量没有发生改变，而list这种可变类型则因为<code>test()</code>方法的影响导致内容发生了改变。</p>
<p>在很多的其他语言中在传递参数的时候允许程序员选择值传递还是引用传递(比如c语言加上<em>号传递指针就是引用传递，而直接传递变量名就是值传递)，<em>*而python只允许使用引用传递，但是它加上了可变类型和不可变类型，听说python只允许引用传递是为方便内存管理，因为python使用的内存回收机制是计数器回收，就是每块内存上有一个计数器，表示当前有多少个对象指向该内存。每当一个变量不再使用时，就让该计数器-1，有新对象指向该内存时就让计数器+1，当计时器为0时，就可以收回这块内存了。</em></em></p>
<h1 id="slots-魔法"><a href="#slots-魔法" class="headerlink" title="__slots__魔法"></a>__slots__魔法</h1><p><strong>在Python中，每个类都有实例属性。默认情况下Python用一个字典来保存一个对象的实例属性。这非常有用，因为它允许我们在运行时去设置任意的新属性。</strong></p>
<p>然而，对于有着已知属性的小类来说，它可能是个瓶颈。这个字典浪费了很多内存。<strong>Python不能在对象创建时直接分配一个固定量的内存来保存所有的属性。因此如果你创建许多对象（我指的是成千上万个），它会消耗掉很多内存</strong>。<br>不过还是有一个方法来规避这个问题。<strong>这个方法需要使用<code>__slots__</code>来告诉Python不要使用字典，而且只给一个固定集合的属性分配空间。</strong></p>
<p>这里是一个使用与不使用<code>__slots__</code>的例子：</p>
<ul>
<li><p>不使用 <code>__slots__</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, identifier)</span>:</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.identifier = identifier</span><br><span class="line">      self.set_up()</span><br><span class="line">  <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>使用 <code>__slots__</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span></span><br><span class="line">  __slots__ = [<span class="string">'name'</span>, <span class="string">'identifier'</span>]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, identifier)</span>:</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.identifier = identifier</span><br><span class="line">      self.set_up()</span><br><span class="line">  <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>第二段代码会为你的内存减轻负担。通过这个技巧，有些人已经看到内存占用率几乎40%~50%的减少。</p>
<p>稍微备注一下，你也许需要试一下PyPy。它已经默认地做了所有这些优化。</p>
<p>参考资料：</p>
<p>【1】python可变和不可变对象：<a href="https://www.jianshu.com/p/c5582e23b26c" target="_blank" rel="noopener">https://www.jianshu.com/p/c5582e23b26c</a></p>

          
        
      
    </div>
    
    
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Mosbyllc" />
            
              <p class="site-author-name" itemprop="name">Mosbyllc</p>
              <p class="site-description motion-element" itemprop="description">Sometimes thing have to fall apart to make way for better things.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">73</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/kugua233" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://weibo.com/Mosbyllc" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://segmentfault.com/u/kugua233" target="_blank" title="SegmentFault">
                      
                        <i class="fa fa-fw fa-strikethrough"></i>SegmentFault</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:1499913789@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Recommended reading
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://plushunter.github.io/" title="Free Will" target="_blank">Free Will</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-star"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mosbyllc</span>

  
</div>











        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
